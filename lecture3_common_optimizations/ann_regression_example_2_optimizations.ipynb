{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN for regression, example 2, house market data (how to handle categorical variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Version 2: using some common optimization approaches (see also the first optimization examples, more explanations there)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports / modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikit-learn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# pip install tensorflow\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "df = pd.read_csv(\"Housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnishingstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13300000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12250000</td>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12250000</td>\n",
       "      <td>9960</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>semi-furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12215000</td>\n",
       "      <td>7500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11410000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n",
       "0  13300000  7420         4          2        3      yes        no       no   \n",
       "1  12250000  8960         4          4        4      yes        no       no   \n",
       "2  12250000  9960         3          2        2      yes        no      yes   \n",
       "3  12215000  7500         4          2        2      yes        no      yes   \n",
       "4  11410000  7420         4          1        2      yes       yes      yes   \n",
       "\n",
       "  hotwaterheating airconditioning  parking prefarea furnishingstatus  \n",
       "0              no             yes        2      yes        furnished  \n",
       "1              no             yes        3       no        furnished  \n",
       "2              no              no        2      yes   semi-furnished  \n",
       "3              no             yes        3      yes        furnished  \n",
       "4              no             yes        2       no        furnished  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see the first 5 rows \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "furnishingstatus\n",
       "semi-furnished    227\n",
       "unfurnished       178\n",
       "furnished         140\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['furnishingstatus'].value_counts()\n",
    "\n",
    "# usually we are only interested if the house\n",
    "# is furnished AT ALL or completely unfurnished\n",
    "# what if we combine semi-furnished with furnished?\n",
    "# (there's no way knowing if this works, it's more about trying creative\n",
    "# approaches in order to simplify/optimize the dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WE HAVE SOME BOOLEAN CATEGORIES\n",
    "# => change them to 0 and 1\n",
    "\n",
    "# this just converts the value of column to 0 or 1\n",
    "# factorize in pandas works too, but only one column at a time\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "variables = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']\n",
    "encoder = LabelEncoder()\n",
    "df[variables] = df[variables].apply(encoder.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnishingstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13300000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12250000</td>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12250000</td>\n",
       "      <td>9960</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>semi-furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12215000</td>\n",
       "      <td>7500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11410000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  area  bedrooms  bathrooms  stories  mainroad  guestroom  \\\n",
       "0  13300000  7420         4          2        3         1          0   \n",
       "1  12250000  8960         4          4        4         1          0   \n",
       "2  12250000  9960         3          2        2         1          0   \n",
       "3  12215000  7500         4          2        2         1          0   \n",
       "4  11410000  7420         4          1        2         1          1   \n",
       "\n",
       "   basement  hotwaterheating  airconditioning  parking  prefarea  \\\n",
       "0         0                0                1        2         1   \n",
       "1         0                0                1        3         0   \n",
       "2         1                0                0        2         1   \n",
       "3         1                0                1        3         1   \n",
       "4         1                0                1        2         0   \n",
       "\n",
       "  furnishingstatus  \n",
       "0        furnished  \n",
       "1        furnished  \n",
       "2   semi-furnished  \n",
       "3        furnished  \n",
       "4        furnished  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see how our dataset now changed\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert text categories with multiple choices into multiple variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SINCE WE ARE GOING TO MODIFY THE furnishingstatus from three options\n",
    "# to two options, we no longer need OneHotEncoder, since this is now \n",
    "# goint to be a boolean/binary variable\n",
    "\n",
    "# # this makes multiple columns with the variable (Separate for yes/no)\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# variables = ['furnishingstatus']\n",
    "\n",
    "# # use encoder\n",
    "# encoder = OneHotEncoder(sparse_output=False).set_output(transform=\"pandas\")\n",
    "# one_hot_encoded = encoder.fit_transform(df[variables]).astype(int)\n",
    "# df = pd.concat([df,one_hot_encoded],axis=1).drop(columns=variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is an example where you can use your own ideas and creativity in order to optimize, modify or simplify the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a helper function for pandas and replace\n",
    "# the different furnishingstatus values into either 0 or 1\n",
    "def modify_furnishing(row):\n",
    "    if row['furnishingstatus'] == 'unfurnished':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "# create a new boolean/binary furnished status \n",
    "# 0 => not furnished\n",
    "# 1 => either fully or partially furnished\n",
    "df['furnished'] = df.apply(modify_furnishing, axis=1)\n",
    "\n",
    "# drop the original 3-option furnishing status\n",
    "df = df.drop(\"furnishingstatus\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no longer needed, since we don't use OneHotEncoder anymore for this\n",
    "# # we can alwasy remove EXACTLY ONE option per variable when we use OneHotEncoder\n",
    "# df = df.drop(\"furnishingstatus_unfurnished\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13300000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12250000</td>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12250000</td>\n",
       "      <td>9960</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12215000</td>\n",
       "      <td>7500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11410000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10850000</td>\n",
       "      <td>7500</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10150000</td>\n",
       "      <td>8580</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10150000</td>\n",
       "      <td>16200</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9870000</td>\n",
       "      <td>8100</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9800000</td>\n",
       "      <td>5750</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price   area  bedrooms  bathrooms  stories  mainroad  guestroom  \\\n",
       "0  13300000   7420         4          2        3         1          0   \n",
       "1  12250000   8960         4          4        4         1          0   \n",
       "2  12250000   9960         3          2        2         1          0   \n",
       "3  12215000   7500         4          2        2         1          0   \n",
       "4  11410000   7420         4          1        2         1          1   \n",
       "5  10850000   7500         3          3        1         1          0   \n",
       "6  10150000   8580         4          3        4         1          0   \n",
       "7  10150000  16200         5          3        2         1          0   \n",
       "8   9870000   8100         4          1        2         1          1   \n",
       "9   9800000   5750         3          2        4         1          1   \n",
       "\n",
       "   basement  hotwaterheating  airconditioning  parking  prefarea  furnished  \n",
       "0         0                0                1        2         1          1  \n",
       "1         0                0                1        3         0          1  \n",
       "2         1                0                0        2         1          1  \n",
       "3         1                0                1        3         1          1  \n",
       "4         1                0                1        2         0          1  \n",
       "5         1                0                1        2         1          1  \n",
       "6         0                0                1        2         1          1  \n",
       "7         0                0                0        0         0          0  \n",
       "8         1                0                1        2         1          1  \n",
       "9         0                0                1        1         1          0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see what happened to our dataset\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usually the most straight-forward / quick&dirty -solution is to use\n",
    "# scipy and z-score\n",
    "\n",
    "# version 1, SciPy, extreme outliers that go under -3 or over +3 in normal distribution\n",
    "# from scipy import stats\n",
    "# df = df[(np.abs(stats.zscore(df)) < 3).all(axis=1)]\n",
    "\n",
    "# see also the quantile -based removal in Moodle, you have more control\n",
    "# over what is removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can also get as fancy you wish with outlier detection and removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\n"
     ]
    }
   ],
   "source": [
    "# let's try a fancier example for outlier removal\n",
    "# this code is originally from:\n",
    "# https://stackoverflow.com/questions/69248118/detect-outliers-across-all-columns-of-pandas-dataframe\n",
    "\n",
    "def find_outliers(col):\n",
    "    q1 = col.quantile(.15)\n",
    "    q3 = col.quantile(.85)\n",
    "    IQR = q3 - q1\n",
    "    ll = q1 - (1.5*IQR)\n",
    "    ul = q3 + (1.5*IQR)\n",
    "    upper_outliers = col[col > ul].index.tolist()\n",
    "    lower_outliers = col[col < ll].index.tolist()\n",
    "    bad_indices = list(set(upper_outliers + lower_outliers))\n",
    "    return(bad_indices)\n",
    "\n",
    "# get indexes of all outliers into a list\n",
    "bad_indexes = []\n",
    "for col in df.columns:\n",
    "    if df[col].dtype in [\"int64\",\"float64\"]:\n",
    "        bad_indexes.append(find_outliers(df[col]))\n",
    "\n",
    "\n",
    "# modify the list so that we can drop these rows from the DataFrame\n",
    "\n",
    "bad_indexes = set(list(np.concatenate(bad_indexes).flat))\n",
    "\n",
    "print(len(bad_indexes))\n",
    "\n",
    "# drop the outliers\n",
    "df = df.drop(bad_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# it seems many of the more expensive houses were dropped off\n",
    "# we still have slightly skewed distribution due to expensive houses\n",
    "\n",
    "# unfortunately we don't have much data, so we can't really afford\n",
    "# removing more outliers this time...\n",
    "\n",
    "# remember, getting more and better data is always the best option to improve data!\n",
    "df['price'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X/y -split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform X/y -split\n",
    "# if you  have more than one independent variable, list them all here\n",
    "# leave out the target variable! (dependent variable)\n",
    "\n",
    "# this is a nice and common trick => everything EXCEPT target variable => support variable\n",
    "X = df.drop(\"price\", axis=1)\n",
    "\n",
    "# have only the target variable here (dependent variable)\n",
    "y = df[\"price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the different tools to figure out which variables are important and which are not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.473069</td>\n",
       "      <td>0.359088</td>\n",
       "      <td>0.448919</td>\n",
       "      <td>0.197588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.328968</td>\n",
       "      <td>0.278424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.454708</td>\n",
       "      <td>0.284935</td>\n",
       "      <td>0.351732</td>\n",
       "      <td>0.307927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area</th>\n",
       "      <td>0.473069</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.111222</td>\n",
       "      <td>0.126659</td>\n",
       "      <td>-0.110831</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.168028</td>\n",
       "      <td>0.066453</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.182536</td>\n",
       "      <td>0.303068</td>\n",
       "      <td>0.221741</td>\n",
       "      <td>0.152440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>0.359088</td>\n",
       "      <td>0.111222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.330146</td>\n",
       "      <td>0.436622</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.097721</td>\n",
       "      <td>0.131260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.152619</td>\n",
       "      <td>0.107960</td>\n",
       "      <td>0.126326</td>\n",
       "      <td>0.145228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms</th>\n",
       "      <td>0.448919</td>\n",
       "      <td>0.126659</td>\n",
       "      <td>0.330146</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.160032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.113472</td>\n",
       "      <td>0.168793</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.145580</td>\n",
       "      <td>0.130359</td>\n",
       "      <td>0.074666</td>\n",
       "      <td>0.152133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stories</th>\n",
       "      <td>0.197588</td>\n",
       "      <td>-0.110831</td>\n",
       "      <td>0.436622</td>\n",
       "      <td>0.160032</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001267</td>\n",
       "      <td>-0.112666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.135208</td>\n",
       "      <td>-0.122925</td>\n",
       "      <td>0.046513</td>\n",
       "      <td>0.057485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mainroad</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guestroom</th>\n",
       "      <td>0.328968</td>\n",
       "      <td>0.168028</td>\n",
       "      <td>0.097721</td>\n",
       "      <td>0.113472</td>\n",
       "      <td>0.001267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.433041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.135729</td>\n",
       "      <td>0.055286</td>\n",
       "      <td>0.191861</td>\n",
       "      <td>0.118929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basement</th>\n",
       "      <td>0.278424</td>\n",
       "      <td>0.066453</td>\n",
       "      <td>0.131260</td>\n",
       "      <td>0.168793</td>\n",
       "      <td>-0.112666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.433041</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.099762</td>\n",
       "      <td>0.067917</td>\n",
       "      <td>0.245653</td>\n",
       "      <td>0.108538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hotwaterheating</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airconditioning</th>\n",
       "      <td>0.454708</td>\n",
       "      <td>0.182536</td>\n",
       "      <td>0.152619</td>\n",
       "      <td>0.145580</td>\n",
       "      <td>0.135208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.135729</td>\n",
       "      <td>0.099762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.130278</td>\n",
       "      <td>0.101346</td>\n",
       "      <td>0.099891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parking</th>\n",
       "      <td>0.284935</td>\n",
       "      <td>0.303068</td>\n",
       "      <td>0.107960</td>\n",
       "      <td>0.130359</td>\n",
       "      <td>-0.122925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.055286</td>\n",
       "      <td>0.067917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.130278</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070880</td>\n",
       "      <td>0.149893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prefarea</th>\n",
       "      <td>0.351732</td>\n",
       "      <td>0.221741</td>\n",
       "      <td>0.126326</td>\n",
       "      <td>0.074666</td>\n",
       "      <td>0.046513</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.191861</td>\n",
       "      <td>0.245653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.101346</td>\n",
       "      <td>0.070880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.080154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>furnished</th>\n",
       "      <td>0.307927</td>\n",
       "      <td>0.152440</td>\n",
       "      <td>0.145228</td>\n",
       "      <td>0.152133</td>\n",
       "      <td>0.057485</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.118929</td>\n",
       "      <td>0.108538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.099891</td>\n",
       "      <td>0.149893</td>\n",
       "      <td>0.080154</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    price      area  bedrooms  bathrooms   stories  mainroad  \\\n",
       "price            1.000000  0.473069  0.359088   0.448919  0.197588       NaN   \n",
       "area             0.473069  1.000000  0.111222   0.126659 -0.110831       NaN   \n",
       "bedrooms         0.359088  0.111222  1.000000   0.330146  0.436622       NaN   \n",
       "bathrooms        0.448919  0.126659  0.330146   1.000000  0.160032       NaN   \n",
       "stories          0.197588 -0.110831  0.436622   0.160032  1.000000       NaN   \n",
       "mainroad              NaN       NaN       NaN        NaN       NaN       NaN   \n",
       "guestroom        0.328968  0.168028  0.097721   0.113472  0.001267       NaN   \n",
       "basement         0.278424  0.066453  0.131260   0.168793 -0.112666       NaN   \n",
       "hotwaterheating       NaN       NaN       NaN        NaN       NaN       NaN   \n",
       "airconditioning  0.454708  0.182536  0.152619   0.145580  0.135208       NaN   \n",
       "parking          0.284935  0.303068  0.107960   0.130359 -0.122925       NaN   \n",
       "prefarea         0.351732  0.221741  0.126326   0.074666  0.046513       NaN   \n",
       "furnished        0.307927  0.152440  0.145228   0.152133  0.057485       NaN   \n",
       "\n",
       "                 guestroom  basement  hotwaterheating  airconditioning  \\\n",
       "price             0.328968  0.278424              NaN         0.454708   \n",
       "area              0.168028  0.066453              NaN         0.182536   \n",
       "bedrooms          0.097721  0.131260              NaN         0.152619   \n",
       "bathrooms         0.113472  0.168793              NaN         0.145580   \n",
       "stories           0.001267 -0.112666              NaN         0.135208   \n",
       "mainroad               NaN       NaN              NaN              NaN   \n",
       "guestroom         1.000000  0.433041              NaN         0.135729   \n",
       "basement          0.433041  1.000000              NaN         0.099762   \n",
       "hotwaterheating        NaN       NaN              NaN              NaN   \n",
       "airconditioning   0.135729  0.099762              NaN         1.000000   \n",
       "parking           0.055286  0.067917              NaN         0.130278   \n",
       "prefarea          0.191861  0.245653              NaN         0.101346   \n",
       "furnished         0.118929  0.108538              NaN         0.099891   \n",
       "\n",
       "                  parking  prefarea  furnished  \n",
       "price            0.284935  0.351732   0.307927  \n",
       "area             0.303068  0.221741   0.152440  \n",
       "bedrooms         0.107960  0.126326   0.145228  \n",
       "bathrooms        0.130359  0.074666   0.152133  \n",
       "stories         -0.122925  0.046513   0.057485  \n",
       "mainroad              NaN       NaN        NaN  \n",
       "guestroom        0.055286  0.191861   0.118929  \n",
       "basement         0.067917  0.245653   0.108538  \n",
       "hotwaterheating       NaN       NaN        NaN  \n",
       "airconditioning  0.130278  0.101346   0.099891  \n",
       "parking          1.000000  0.070880   0.149893  \n",
       "prefarea         0.070880  1.000000   0.080154  \n",
       "furnished        0.149893  0.080154   1.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the most basic tool of them all => correlations\n",
    "correlations = df.corr(numeric_only=True)\n",
    "correlations\n",
    "\n",
    "# based on this, pretty much everything correlates with price\n",
    "# so we don't have unusable variables\n",
    "# for some reason, mainroad and hotwaterheating show as NaN (not a number)\n",
    "# probably not enough data or variance to show a correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fisher score to important variables in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pip install skfeature-chappers\n",
    "from skfeature.function.similarity_based import fisher_score\n",
    "\n",
    "# get the fisher's score rankings \n",
    "ranks = fisher_score.fisher_score(X.values, y.values)\n",
    "\n",
    "# create a pandas DataFrame for easier interpretation\n",
    "feat_importances = pd.Series(ranks, X.columns)\n",
    "feat_importances.plot(kind='barh')\n",
    "\n",
    "# how to interpret -> low score means the effect of this field is not large in the dataset\n",
    "# => typically means other columns in the dataset have similar correlations, \n",
    "# therefore making this particular column not so useful since other columns \n",
    "# already fill this role for this correlation\n",
    "\n",
    "# Fisher's score studies the variance of the data -> statistical significance'\n",
    "\n",
    "# based on Fisher's score:\n",
    "# num_rooms is not important at all, and num_people has minor importance in this data\n",
    "# but ave_monthly_income is quite powerful based on Fisher's score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SelectKBest to see important variables in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>area</td>\n",
       "      <td>167273.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>parking</td>\n",
       "      <td>196.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>guestroom</td>\n",
       "      <td>184.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>prefarea</td>\n",
       "      <td>157.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>airconditioning</td>\n",
       "      <td>153.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>basement</td>\n",
       "      <td>127.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>furnished</td>\n",
       "      <td>72.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stories</td>\n",
       "      <td>42.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bathrooms</td>\n",
       "      <td>41.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bedrooms</td>\n",
       "      <td>35.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mainroad</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hotwaterheating</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Features     Score\n",
       "0              area 167273.94\n",
       "9           parking    196.22\n",
       "5         guestroom    184.47\n",
       "10         prefarea    157.98\n",
       "8   airconditioning    153.88\n",
       "6          basement    127.87\n",
       "11        furnished     72.54\n",
       "3           stories     42.91\n",
       "2         bathrooms     41.10\n",
       "1          bedrooms     35.33\n",
       "4          mainroad      0.00\n",
       "7   hotwaterheating       NaN"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# convert all continuous variables to integer,\n",
    "# and convert all negative numbers to 0\n",
    "X_cat = X.astype(int)\n",
    "X_cat = X_cat.clip(lower=0)\n",
    "\n",
    "# initialize chi2 and SelectKBest\n",
    "# Note: chi2 -test is a very common test\n",
    "# in statistics and quantitative analysis\n",
    "# basically it studies the data whether variables are related\n",
    "# or independent of each other\n",
    "chi_2_features = SelectKBest(chi2, k=len(X_cat.columns))\n",
    "\n",
    "# fit our data to the SelectKBest\n",
    "best_features = chi_2_features.fit(X_cat,y.astype(int))\n",
    "\n",
    "# use decimal format in table print later\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "# wrap it up, and show the results\n",
    "# the higher the score, the more effect that column has on target variable\n",
    "df_features = pd.DataFrame(best_features.scores_)\n",
    "df_columns = pd.DataFrame(X_cat.columns)\n",
    "f_scores = pd.concat([df_columns,df_features],axis=1)\n",
    "f_scores.columns = ['Features','Score']\n",
    "f_scores.sort_values(by='Score',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VIF-test -> detect variables that are too similar (redundancy/multicollinearity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            feature   VIF\n",
      "0              area  1.24\n",
      "1          bedrooms  1.44\n",
      "2         bathrooms  1.18\n",
      "3           stories  1.39\n",
      "4          mainroad 26.07\n",
      "5         guestroom  1.28\n",
      "6          basement  1.37\n",
      "7   hotwaterheating   NaN\n",
      "8   airconditioning  1.10\n",
      "9           parking  1.16\n",
      "10         prefarea  1.13\n",
      "11        furnished  1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tuomas.valtanen\\DL2025lecturenotes2\\DeepLearning2025\\.venv\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n"
     ]
    }
   ],
   "source": [
    "# pip install statsmodels\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor \n",
    "\n",
    "# VIF dataframe \n",
    "# VIF = Variance Inflation Factor\n",
    "vif_data = pd.DataFrame() \n",
    "vif_data[\"feature\"] = X.columns \n",
    "  \n",
    "# calculating VIF for each feature \n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) \n",
    "                          for i in range(len(X.columns))] \n",
    "  \n",
    "\n",
    "# variables with high VIF-value \n",
    "# can mean multlicollinearity (variables providing same linear\n",
    "# relationships in the data, potentially confusing the ML algorithm\n",
    "# this might be good info when deciding if some variable needs to be removed\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test/validation -split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in Classic ML, we only had train/test -split\n",
    "# in deep learning, we usually use validation-data also, for better\n",
    "# optimization possibilities and better metrics\n",
    "\n",
    "# unfortunately the scikit-learn's train_test_split doesn't support validation\n",
    "# set split in itself.\n",
    "\n",
    "# if you want to split the test set into two for a validation set too, try this trick:\n",
    "\n",
    "# step 1, split the data into 70% (training data) and 30% (temporary data)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# step 2, split the temporary data in HALF (0.5) => 15% test and 15% validation\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a neural network structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizations in place again, see the first optimization example for more explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tuomas.valtanen\\DL2025lecturenotes2\\DeepLearning2025\\.venv\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:142: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │            \u001b[38;5;34m48\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │           \u001b[38;5;34m792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,673</span> (6.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,673\u001b[0m (6.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,649</span> (6.44 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,649\u001b[0m (6.44 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> (96.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m24\u001b[0m (96.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create neural network\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# save the amount of support variables into a helper variable\n",
    "# so we don't have to update the input_shape all the time\n",
    "variable_amount = len(X.columns)\n",
    "\n",
    "# create callbacks and place them into a parameter list\n",
    "# NOTE! if you get PermissionError while training the model,\n",
    "# just try training it again\n",
    "mc = ModelCheckpoint('best_model_regression2_housing.keras', monitor='val_loss', mode='min', save_best_only=True)\n",
    "\n",
    "# if you use multiple callbacks (EarlyStoppin, ReduceLROnPlateau etc.)\n",
    "# add them to this same list\n",
    "callback_list = [mc]\n",
    "\n",
    "# Define Sequential neural network model\n",
    "# input shape has to match the amount of SUPPORT VARIABLES\n",
    "# in other words => amount of columns in X \n",
    "\n",
    "# Tip: have at least the same number of nodes as in the input shape\n",
    "\n",
    "# since we have 13 support variables this time => 16 nodes in first layer\n",
    "\n",
    "# different regularization in use this time!\n",
    "\n",
    "# output layer in regression is always 1 node without activation function\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.BatchNormalization(input_shape=(variable_amount,)),\n",
    "        layers.Dense(32, activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=0.1, l2=0.1)),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(24, activation=\"relu\"),\n",
    "        layers.Dense(16, activation=\"relu\"),\n",
    "        layers.Dense(1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# select the optimizer and loss function\n",
    "# you can try rmsprop also as optimizer, or stochastic gradient descent\n",
    "# model.compile(optimizer='adam', loss='mse')\n",
    "# model.compile(optimizer=keras.optimizers.RMSprop(0.00085), loss=keras.losses.Huber())\n",
    "# model.compile(optimizer=keras.optimizers.SGD(0.001), loss=\"mse\")\n",
    "# an example where we alter the learning rate of Adam-optimizer\n",
    "\n",
    "# we can adjust the hyperparameters for our optimizers and loss-functionts too, for example:\n",
    "# see also commented code examples above ()\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.00125), loss='mse')\n",
    "\n",
    "# common tips on how to change neural network structure if your metrics are not good:\n",
    "\n",
    "# make wider (or narrower) layers (for example, 64 or 128 nodes)\n",
    "# make a longer or shorter network (add or remove layers)\n",
    "# use Dropout -layers (e.g. layers.Dropout(0.1))\n",
    "\n",
    "# remember: there's no process or mathematical formula\n",
    "# in order to figure out the optimal neural network structure\n",
    "# it's mostly all about trial and error => EXPERIMENTATION!\n",
    "\n",
    "# remember to have enough \"decision-space\" for your data!\n",
    "# it's highly unlikely a dataset with 20 different variables is going\n",
    "# to work well with only 8 nodes in each layer etc.\n",
    "\n",
    "# print out the summary of your model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the neural network, connect callbacks (ModelCheckpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 24742717292544.0000 - val_loss: 23262625005568.0000\n",
      "Epoch 2/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24742711001088.0000 - val_loss: 23262616616960.0000\n",
      "Epoch 3/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24742706806784.0000 - val_loss: 23262612422656.0000\n",
      "Epoch 4/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24742700515328.0000 - val_loss: 23262608228352.0000\n",
      "Epoch 5/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24742692126720.0000 - val_loss: 23262597742592.0000\n",
      "Epoch 6/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 24742675349504.0000 - val_loss: 23262583062528.0000\n",
      "Epoch 7/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24742660669440.0000 - val_loss: 23262562091008.0000\n",
      "Epoch 8/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 24742627115008.0000 - val_loss: 23262536925184.0000\n",
      "Epoch 9/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 24742583074816.0000 - val_loss: 23262488690688.0000\n",
      "Epoch 10/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24742520160256.0000 - val_loss: 23262427873280.0000\n",
      "Epoch 11/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 24742423691264.0000 - val_loss: 23262337695744.0000\n",
      "Epoch 12/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 24742287376384.0000 - val_loss: 23262209769472.0000\n",
      "Epoch 13/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24742098632704.0000 - val_loss: 23262025220096.0000\n",
      "Epoch 14/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 24741844877312.0000 - val_loss: 23261765173248.0000\n",
      "Epoch 15/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 24741492555776.0000 - val_loss: 23261412851712.0000\n",
      "Epoch 16/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 24741018599424.0000 - val_loss: 23260920020992.0000\n",
      "Epoch 17/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 24740351705088.0000 - val_loss: 23260263612416.0000\n",
      "Epoch 18/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 24739460415488.0000 - val_loss: 23259372322816.0000\n",
      "Epoch 19/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 24738244067328.0000 - val_loss: 23258210500608.0000\n",
      "Epoch 20/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 24736740409344.0000 - val_loss: 23256671191040.0000\n",
      "Epoch 21/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24734800543744.0000 - val_loss: 23254685188096.0000\n",
      "Epoch 22/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 24732091023360.0000 - val_loss: 23252103593984.0000\n",
      "Epoch 23/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24728936906752.0000 - val_loss: 23248781705216.0000\n",
      "Epoch 24/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24724706951168.0000 - val_loss: 23244555943936.0000\n",
      "Epoch 25/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 24719510208512.0000 - val_loss: 23239208206336.0000\n",
      "Epoch 26/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 24712719630336.0000 - val_loss: 23232488931328.0000\n",
      "Epoch 27/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24703632670720.0000 - val_loss: 23224142266368.0000\n",
      "Epoch 28/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 24692675051520.0000 - val_loss: 23213782335488.0000\n",
      "Epoch 29/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 24680094236672.0000 - val_loss: 23200983416832.0000\n",
      "Epoch 30/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 24663921000448.0000 - val_loss: 23185409966080.0000\n",
      "Epoch 31/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24645069701120.0000 - val_loss: 23166726438912.0000\n",
      "Epoch 32/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24623762636800.0000 - val_loss: 23144104460288.0000\n",
      "Epoch 33/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 24593666408448.0000 - val_loss: 23116887621632.0000\n",
      "Epoch 34/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 24564666990592.0000 - val_loss: 23085010911232.0000\n",
      "Epoch 35/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 24523151769600.0000 - val_loss: 23046909853696.0000\n",
      "Epoch 36/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24483597385728.0000 - val_loss: 23002345373696.0000\n",
      "Epoch 37/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 24431084699648.0000 - val_loss: 22950640091136.0000\n",
      "Epoch 38/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24369862541312.0000 - val_loss: 22890846093312.0000\n",
      "Epoch 39/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 24298527916032.0000 - val_loss: 22821671534592.0000\n",
      "Epoch 40/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 24221931536384.0000 - val_loss: 22742288039936.0000\n",
      "Epoch 41/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24131722543104.0000 - val_loss: 22653089873920.0000\n",
      "Epoch 42/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 24024535007232.0000 - val_loss: 22552093130752.0000\n",
      "Epoch 43/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 23921439014912.0000 - val_loss: 22438775619584.0000\n",
      "Epoch 44/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 23789448462336.0000 - val_loss: 22311543504896.0000\n",
      "Epoch 45/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 23655767605248.0000 - val_loss: 22170424049664.0000\n",
      "Epoch 46/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 23490291826688.0000 - val_loss: 22013515137024.0000\n",
      "Epoch 47/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 23310008057856.0000 - val_loss: 21839852077056.0000\n",
      "Epoch 48/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 23109203656704.0000 - val_loss: 21647671164928.0000\n",
      "Epoch 49/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 22900799176704.0000 - val_loss: 21438352326656.0000\n",
      "Epoch 50/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 22700093341696.0000 - val_loss: 21208493981696.0000\n",
      "Epoch 51/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 22459373846528.0000 - val_loss: 20960509952000.0000\n",
      "Epoch 52/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 22169847332864.0000 - val_loss: 20692772847616.0000\n",
      "Epoch 53/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 21867677089792.0000 - val_loss: 20401394548736.0000\n",
      "Epoch 54/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 21507126329344.0000 - val_loss: 20085037072384.0000\n",
      "Epoch 55/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 21206986129408.0000 - val_loss: 19746579808256.0000\n",
      "Epoch 56/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 20826134937600.0000 - val_loss: 19383906729984.0000\n",
      "Epoch 57/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 20475528871936.0000 - val_loss: 18992907419648.0000\n",
      "Epoch 58/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 19994593198080.0000 - val_loss: 18580296957952.0000\n",
      "Epoch 59/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 19573921284096.0000 - val_loss: 18146643673088.0000\n",
      "Epoch 60/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 19133915725824.0000 - val_loss: 17684508966912.0000\n",
      "Epoch 61/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 18658824814592.0000 - val_loss: 17200791420928.0000\n",
      "Epoch 62/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 18037285584896.0000 - val_loss: 16689113595904.0000\n",
      "Epoch 63/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 17558545629184.0000 - val_loss: 16158201741312.0000\n",
      "Epoch 64/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 16942894153728.0000 - val_loss: 15597918224384.0000\n",
      "Epoch 65/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 16425896902656.0000 - val_loss: 15026906726400.0000\n",
      "Epoch 66/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 15699510558720.0000 - val_loss: 14432291782656.0000\n",
      "Epoch 67/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 15120152395776.0000 - val_loss: 13822657036288.0000\n",
      "Epoch 68/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 14574396899328.0000 - val_loss: 13196012290048.0000\n",
      "Epoch 69/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 13904123002880.0000 - val_loss: 12556631539712.0000\n",
      "Epoch 70/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 13196315328512.0000 - val_loss: 11909176754176.0000\n",
      "Epoch 71/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 12591333113856.0000 - val_loss: 11259377352704.0000\n",
      "Epoch 72/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 11960941805568.0000 - val_loss: 10611311247360.0000\n",
      "Epoch 73/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 11133832396800.0000 - val_loss: 9946805567488.0000\n",
      "Epoch 74/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 10474214129664.0000 - val_loss: 9305028820992.0000\n",
      "Epoch 75/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 9808994369536.0000 - val_loss: 8651897569280.0000\n",
      "Epoch 76/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9128066940928.0000 - val_loss: 8021900525568.0000\n",
      "Epoch 77/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8520393555968.0000 - val_loss: 7406800601088.0000\n",
      "Epoch 78/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7779491250176.0000 - val_loss: 6809582043136.0000\n",
      "Epoch 79/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 7311485042688.0000 - val_loss: 6229366145024.0000\n",
      "Epoch 80/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6463420366848.0000 - val_loss: 5687124951040.0000\n",
      "Epoch 81/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5989281562624.0000 - val_loss: 5166205501440.0000\n",
      "Epoch 82/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 5409247068160.0000 - val_loss: 4674900459520.0000\n",
      "Epoch 83/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4999598833664.0000 - val_loss: 4216706826240.0000\n",
      "Epoch 84/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4651990646784.0000 - val_loss: 3792889446400.0000\n",
      "Epoch 85/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4224132841472.0000 - val_loss: 3409881071616.0000\n",
      "Epoch 86/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3750314639360.0000 - val_loss: 3075946053632.0000\n",
      "Epoch 87/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3432088862720.0000 - val_loss: 2776261722112.0000\n",
      "Epoch 88/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3189188067328.0000 - val_loss: 2508531695616.0000\n",
      "Epoch 89/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2817933705216.0000 - val_loss: 2273942700032.0000\n",
      "Epoch 90/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2596742889472.0000 - val_loss: 2071411818496.0000\n",
      "Epoch 91/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2421823373312.0000 - val_loss: 1894140215296.0000\n",
      "Epoch 92/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2141622370304.0000 - val_loss: 1749719318528.0000\n",
      "Epoch 93/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1918737580032.0000 - val_loss: 1630079287296.0000\n",
      "Epoch 94/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1971204259840.0000 - val_loss: 1529459376128.0000\n",
      "Epoch 95/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1802402660352.0000 - val_loss: 1458822447104.0000\n",
      "Epoch 96/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1930477830144.0000 - val_loss: 1393553702912.0000\n",
      "Epoch 97/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1733328109568.0000 - val_loss: 1344898596864.0000\n",
      "Epoch 98/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1776687906816.0000 - val_loss: 1307070562304.0000\n",
      "Epoch 99/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1527629086720.0000 - val_loss: 1280403570688.0000\n",
      "Epoch 100/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1585028399104.0000 - val_loss: 1255565426688.0000\n",
      "Epoch 101/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1538986344448.0000 - val_loss: 1235735805952.0000\n",
      "Epoch 102/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1530118537216.0000 - val_loss: 1222272221184.0000\n",
      "Epoch 103/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1469057728512.0000 - val_loss: 1210908540928.0000\n",
      "Epoch 104/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1457053630464.0000 - val_loss: 1201477910528.0000\n",
      "Epoch 105/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1542941835264.0000 - val_loss: 1194461102080.0000\n",
      "Epoch 106/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1433460015104.0000 - val_loss: 1188167417856.0000\n",
      "Epoch 107/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1479512293376.0000 - val_loss: 1182634082304.0000\n",
      "Epoch 108/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1539377594368.0000 - val_loss: 1178462846976.0000\n",
      "Epoch 109/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1472345800704.0000 - val_loss: 1174172729344.0000\n",
      "Epoch 110/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1463084646400.0000 - val_loss: 1170865520640.0000\n",
      "Epoch 111/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1427884474368.0000 - val_loss: 1167889924096.0000\n",
      "Epoch 112/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1463728865280.0000 - val_loss: 1165086162944.0000\n",
      "Epoch 113/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1572159356928.0000 - val_loss: 1162194190336.0000\n",
      "Epoch 114/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1555177013248.0000 - val_loss: 1159305232384.0000\n",
      "Epoch 115/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1480816459776.0000 - val_loss: 1155474784256.0000\n",
      "Epoch 116/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1535217369088.0000 - val_loss: 1152382271488.0000\n",
      "Epoch 117/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1482261004288.0000 - val_loss: 1148970074112.0000\n",
      "Epoch 118/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1309001515008.0000 - val_loss: 1146663731200.0000\n",
      "Epoch 119/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1419808342016.0000 - val_loss: 1143959322624.0000\n",
      "Epoch 120/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1317152227328.0000 - val_loss: 1140992901120.0000\n",
      "Epoch 121/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1551472787456.0000 - val_loss: 1138926551040.0000\n",
      "Epoch 122/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1383191150592.0000 - val_loss: 1135965634560.0000\n",
      "Epoch 123/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1355264425984.0000 - val_loss: 1133883686912.0000\n",
      "Epoch 124/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1543929593856.0000 - val_loss: 1131366055936.0000\n",
      "Epoch 125/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1338106445824.0000 - val_loss: 1128046002176.0000\n",
      "Epoch 126/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1466286342144.0000 - val_loss: 1125241585664.0000\n",
      "Epoch 127/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1390839857152.0000 - val_loss: 1123417325568.0000\n",
      "Epoch 128/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1341124771840.0000 - val_loss: 1121795309568.0000\n",
      "Epoch 129/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1450746970112.0000 - val_loss: 1118207606784.0000\n",
      "Epoch 130/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1351702282240.0000 - val_loss: 1115331100672.0000\n",
      "Epoch 131/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1343153897472.0000 - val_loss: 1113259769856.0000\n",
      "Epoch 132/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1532378349568.0000 - val_loss: 1111134961664.0000\n",
      "Epoch 133/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1444403347456.0000 - val_loss: 1107728924672.0000\n",
      "Epoch 134/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1377024212992.0000 - val_loss: 1105840439296.0000\n",
      "Epoch 135/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1323621023744.0000 - val_loss: 1103757836288.0000\n",
      "Epoch 136/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1365235990528.0000 - val_loss: 1102799831040.0000\n",
      "Epoch 137/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1301825454080.0000 - val_loss: 1100358746112.0000\n",
      "Epoch 138/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1410613379072.0000 - val_loss: 1097705652224.0000\n",
      "Epoch 139/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1327893970944.0000 - val_loss: 1096413085696.0000\n",
      "Epoch 140/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1304265752576.0000 - val_loss: 1094495240192.0000\n",
      "Epoch 141/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1307593146368.0000 - val_loss: 1092689002496.0000\n",
      "Epoch 142/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1310631002112.0000 - val_loss: 1090689695744.0000\n",
      "Epoch 143/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1221029789696.0000 - val_loss: 1088968851456.0000\n",
      "Epoch 144/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1380392239104.0000 - val_loss: 1086984224768.0000\n",
      "Epoch 145/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1557679964160.0000 - val_loss: 1084894674944.0000\n",
      "Epoch 146/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1291379802112.0000 - val_loss: 1082550321152.0000\n",
      "Epoch 147/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1197354254336.0000 - val_loss: 1080413782016.0000\n",
      "Epoch 148/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1327405596672.0000 - val_loss: 1078703685632.0000\n",
      "Epoch 149/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1308623765504.0000 - val_loss: 1077614149632.0000\n",
      "Epoch 150/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1405562519552.0000 - val_loss: 1075457032192.0000\n",
      "Epoch 151/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1285615124480.0000 - val_loss: 1074630033408.0000\n",
      "Epoch 152/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1231013937152.0000 - val_loss: 1072810688512.0000\n",
      "Epoch 153/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1496136286208.0000 - val_loss: 1069863600128.0000\n",
      "Epoch 154/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1204458094592.0000 - val_loss: 1068746407936.0000\n",
      "Epoch 155/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1289179103232.0000 - val_loss: 1067339612160.0000\n",
      "Epoch 156/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1483620876288.0000 - val_loss: 1067473305600.0000\n",
      "Epoch 157/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1299435880448.0000 - val_loss: 1065005023232.0000\n",
      "Epoch 158/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1257116008448.0000 - val_loss: 1062297272320.0000\n",
      "Epoch 159/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1305969164288.0000 - val_loss: 1060046831616.0000\n",
      "Epoch 160/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1259668766720.0000 - val_loss: 1058819080192.0000\n",
      "Epoch 161/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1284955176960.0000 - val_loss: 1056889110528.0000\n",
      "Epoch 162/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1408887816192.0000 - val_loss: 1055703105536.0000\n",
      "Epoch 163/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1354514432000.0000 - val_loss: 1054499864576.0000\n",
      "Epoch 164/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1385338241024.0000 - val_loss: 1053467672576.0000\n",
      "Epoch 165/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1398300082176.0000 - val_loss: 1052994568192.0000\n",
      "Epoch 166/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1431837868032.0000 - val_loss: 1052041871360.0000\n",
      "Epoch 167/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1343347359744.0000 - val_loss: 1049239683072.0000\n",
      "Epoch 168/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1233703141376.0000 - val_loss: 1046632988672.0000\n",
      "Epoch 169/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1353883975680.0000 - val_loss: 1045534408704.0000\n",
      "Epoch 170/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1444152999936.0000 - val_loss: 1042829934592.0000\n",
      "Epoch 171/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1340428517376.0000 - val_loss: 1042349555712.0000\n",
      "Epoch 172/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1292123111424.0000 - val_loss: 1040617570304.0000\n",
      "Epoch 173/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1145464684544.0000 - val_loss: 1040055861248.0000\n",
      "Epoch 174/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1274771275776.0000 - val_loss: 1038415691776.0000\n",
      "Epoch 175/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1378838642688.0000 - val_loss: 1037301907456.0000\n",
      "Epoch 176/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1199831777280.0000 - val_loss: 1035323179008.0000\n",
      "Epoch 177/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1260735823872.0000 - val_loss: 1033843572736.0000\n",
      "Epoch 178/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1386184835072.0000 - val_loss: 1032856993792.0000\n",
      "Epoch 179/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1331017809920.0000 - val_loss: 1032737914880.0000\n",
      "Epoch 180/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1378217230336.0000 - val_loss: 1030633226240.0000\n",
      "Epoch 181/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1287804289024.0000 - val_loss: 1028260429824.0000\n",
      "Epoch 182/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1207038902272.0000 - val_loss: 1026067660800.0000\n",
      "Epoch 183/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1196705710080.0000 - val_loss: 1024432668672.0000\n",
      "Epoch 184/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1322400350208.0000 - val_loss: 1023114149888.0000\n",
      "Epoch 185/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1216888176640.0000 - val_loss: 1022413242368.0000\n",
      "Epoch 186/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1158640435200.0000 - val_loss: 1021430595584.0000\n",
      "Epoch 187/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1345964343296.0000 - val_loss: 1021147938816.0000\n",
      "Epoch 188/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1238700654592.0000 - val_loss: 1019755626496.0000\n",
      "Epoch 189/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1306964525056.0000 - val_loss: 1019055112192.0000\n",
      "Epoch 190/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1316282695680.0000 - val_loss: 1019221049344.0000\n",
      "Epoch 191/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1171644481536.0000 - val_loss: 1016957042688.0000\n",
      "Epoch 192/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1391768371200.0000 - val_loss: 1016178868224.0000\n",
      "Epoch 193/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1271494606848.0000 - val_loss: 1015257300992.0000\n",
      "Epoch 194/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1270069460992.0000 - val_loss: 1013926461440.0000\n",
      "Epoch 195/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1418769858560.0000 - val_loss: 1012716077056.0000\n",
      "Epoch 196/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1183701401600.0000 - val_loss: 1012060782592.0000\n",
      "Epoch 197/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1434901938176.0000 - val_loss: 1011170213888.0000\n",
      "Epoch 198/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1277331898368.0000 - val_loss: 1010418319360.0000\n",
      "Epoch 199/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1242956431360.0000 - val_loss: 1009815584768.0000\n",
      "Epoch 200/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1240433426432.0000 - val_loss: 1009639161856.0000\n",
      "Epoch 201/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1269370454016.0000 - val_loss: 1008010657792.0000\n",
      "Epoch 202/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1317555404800.0000 - val_loss: 1005934280704.0000\n",
      "Epoch 203/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1296969760768.0000 - val_loss: 1005242155008.0000\n",
      "Epoch 204/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1292247629824.0000 - val_loss: 1004728614912.0000\n",
      "Epoch 205/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1258206265344.0000 - val_loss: 1002654793728.0000\n",
      "Epoch 206/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1358287732736.0000 - val_loss: 1002466115584.0000\n",
      "Epoch 207/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1314702229504.0000 - val_loss: 1000682946560.0000\n",
      "Epoch 208/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1246900912128.0000 - val_loss: 999552647168.0000\n",
      "Epoch 209/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1217290305536.0000 - val_loss: 998698450944.0000\n",
      "Epoch 210/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1218178187264.0000 - val_loss: 997902385152.0000\n",
      "Epoch 211/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1375363530752.0000 - val_loss: 997013716992.0000\n",
      "Epoch 212/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1328301211648.0000 - val_loss: 997594234880.0000\n",
      "Epoch 213/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1134147534848.0000 - val_loss: 997849235456.0000\n",
      "Epoch 214/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1330896437248.0000 - val_loss: 998067732480.0000\n",
      "Epoch 215/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1280537788416.0000 - val_loss: 995957342208.0000\n",
      "Epoch 216/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1209091227648.0000 - val_loss: 995818668032.0000\n",
      "Epoch 217/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1216098598912.0000 - val_loss: 994435530752.0000\n",
      "Epoch 218/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1285561384960.0000 - val_loss: 994251440128.0000\n",
      "Epoch 219/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1228783222784.0000 - val_loss: 991841288192.0000\n",
      "Epoch 220/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1271099031552.0000 - val_loss: 989984129024.0000\n",
      "Epoch 221/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1229524434944.0000 - val_loss: 988912680960.0000\n",
      "Epoch 222/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1256462614528.0000 - val_loss: 988556558336.0000\n",
      "Epoch 223/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1192063139840.0000 - val_loss: 989487497216.0000\n",
      "Epoch 224/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1313803599872.0000 - val_loss: 989370908672.0000\n",
      "Epoch 225/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1178038042624.0000 - val_loss: 988269314048.0000\n",
      "Epoch 226/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1178459701248.0000 - val_loss: 987200880640.0000\n",
      "Epoch 227/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1175321706496.0000 - val_loss: 985637060608.0000\n",
      "Epoch 228/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1297380933632.0000 - val_loss: 986180550656.0000\n",
      "Epoch 229/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1251917692928.0000 - val_loss: 985154322432.0000\n",
      "Epoch 230/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1274231521280.0000 - val_loss: 984384667648.0000\n",
      "Epoch 231/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1146866499584.0000 - val_loss: 982891954176.0000\n",
      "Epoch 232/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1141147303936.0000 - val_loss: 982935011328.0000\n",
      "Epoch 233/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1175252893696.0000 - val_loss: 981807726592.0000\n",
      "Epoch 234/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1237522710528.0000 - val_loss: 980906999808.0000\n",
      "Epoch 235/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1236331397120.0000 - val_loss: 979773358080.0000\n",
      "Epoch 236/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1119230492672.0000 - val_loss: 978965626880.0000\n",
      "Epoch 237/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1156509990912.0000 - val_loss: 978505236480.0000\n",
      "Epoch 238/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1205433270272.0000 - val_loss: 978405949440.0000\n",
      "Epoch 239/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1273385320448.0000 - val_loss: 978852773888.0000\n",
      "Epoch 240/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1150085103616.0000 - val_loss: 977793056768.0000\n",
      "Epoch 241/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1198411218944.0000 - val_loss: 976758636544.0000\n",
      "Epoch 242/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1291041505280.0000 - val_loss: 975798206464.0000\n",
      "Epoch 243/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1182334058496.0000 - val_loss: 973850673152.0000\n",
      "Epoch 244/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1335264804864.0000 - val_loss: 974115504128.0000\n",
      "Epoch 245/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1261298909184.0000 - val_loss: 974653358080.0000\n",
      "Epoch 246/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1212022652928.0000 - val_loss: 973918765056.0000\n",
      "Epoch 247/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1152597229568.0000 - val_loss: 973095698432.0000\n",
      "Epoch 248/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1158208946176.0000 - val_loss: 972944900096.0000\n",
      "Epoch 249/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1074536710144.0000 - val_loss: 974058815488.0000\n",
      "Epoch 250/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1058527051776.0000 - val_loss: 971914018816.0000\n",
      "Epoch 251/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1177068371968.0000 - val_loss: 971330355200.0000\n",
      "Epoch 252/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1237415493632.0000 - val_loss: 969528311808.0000\n",
      "Epoch 253/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1178606370816.0000 - val_loss: 969153642496.0000\n",
      "Epoch 254/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1351520747520.0000 - val_loss: 968666841088.0000\n",
      "Epoch 255/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1231778349056.0000 - val_loss: 966413516800.0000\n",
      "Epoch 256/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1154330918912.0000 - val_loss: 964937252864.0000\n",
      "Epoch 257/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1119125110784.0000 - val_loss: 963786637312.0000\n",
      "Epoch 258/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1175879811072.0000 - val_loss: 964208951296.0000\n",
      "Epoch 259/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1214917378048.0000 - val_loss: 962022604800.0000\n",
      "Epoch 260/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1295366881280.0000 - val_loss: 961305378816.0000\n",
      "Epoch 261/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1112752390144.0000 - val_loss: 961599897600.0000\n",
      "Epoch 262/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1264504930304.0000 - val_loss: 960488931328.0000\n",
      "Epoch 263/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1333694693376.0000 - val_loss: 960956399616.0000\n",
      "Epoch 264/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1249591689216.0000 - val_loss: 960498106368.0000\n",
      "Epoch 265/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1223026802688.0000 - val_loss: 959186272256.0000\n",
      "Epoch 266/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1167908536320.0000 - val_loss: 958496768000.0000\n",
      "Epoch 267/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1305028067328.0000 - val_loss: 957859758080.0000\n",
      "Epoch 268/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1104957276160.0000 - val_loss: 957137747968.0000\n",
      "Epoch 269/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1380399448064.0000 - val_loss: 958185144320.0000\n",
      "Epoch 270/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1176589959168.0000 - val_loss: 956123185152.0000\n",
      "Epoch 271/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1179485077504.0000 - val_loss: 954807418880.0000\n",
      "Epoch 272/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1200326311936.0000 - val_loss: 954503921664.0000\n",
      "Epoch 273/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1171942801408.0000 - val_loss: 952962056192.0000\n",
      "Epoch 274/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1146264748032.0000 - val_loss: 952251318272.0000\n",
      "Epoch 275/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1249625243648.0000 - val_loss: 953125371904.0000\n",
      "Epoch 276/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1173895643136.0000 - val_loss: 953483001856.0000\n",
      "Epoch 277/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1147294711808.0000 - val_loss: 951403085824.0000\n",
      "Epoch 278/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1266103353344.0000 - val_loss: 951231512576.0000\n",
      "Epoch 279/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1407680774144.0000 - val_loss: 950229467136.0000\n",
      "Epoch 280/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1199194505216.0000 - val_loss: 950558588928.0000\n",
      "Epoch 281/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1294512422912.0000 - val_loss: 952011915264.0000\n",
      "Epoch 282/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1272368332800.0000 - val_loss: 951567646720.0000\n",
      "Epoch 283/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1236983480320.0000 - val_loss: 953016320000.0000\n",
      "Epoch 284/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1105455742976.0000 - val_loss: 952207867904.0000\n",
      "Epoch 285/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1301871460352.0000 - val_loss: 949935734784.0000\n",
      "Epoch 286/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1176036048896.0000 - val_loss: 950955409408.0000\n",
      "Epoch 287/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1127846248448.0000 - val_loss: 949843329024.0000\n",
      "Epoch 288/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1161479847936.0000 - val_loss: 949526003712.0000\n",
      "Epoch 289/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1175608623104.0000 - val_loss: 950168846336.0000\n",
      "Epoch 290/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1359694397440.0000 - val_loss: 949599141888.0000\n",
      "Epoch 291/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1287971012608.0000 - val_loss: 948268957696.0000\n",
      "Epoch 292/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1207139696640.0000 - val_loss: 944867770368.0000\n",
      "Epoch 293/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1170949668864.0000 - val_loss: 944245768192.0000\n",
      "Epoch 294/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1285296488448.0000 - val_loss: 943658369024.0000\n",
      "Epoch 295/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1268774076416.0000 - val_loss: 943265021952.0000\n",
      "Epoch 296/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1113742901248.0000 - val_loss: 944407117824.0000\n",
      "Epoch 297/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1207832543232.0000 - val_loss: 945409490944.0000\n",
      "Epoch 298/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1295225585664.0000 - val_loss: 946995134464.0000\n",
      "Epoch 299/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1192256864256.0000 - val_loss: 947158777856.0000\n",
      "Epoch 300/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1205251604480.0000 - val_loss: 945006313472.0000\n",
      "Epoch 301/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1202403409920.0000 - val_loss: 944166731776.0000\n",
      "Epoch 302/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1243296694272.0000 - val_loss: 942416723968.0000\n",
      "Epoch 303/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1140860780544.0000 - val_loss: 942458601472.0000\n",
      "Epoch 304/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1228304023552.0000 - val_loss: 944774381568.0000\n",
      "Epoch 305/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1235732398080.0000 - val_loss: 942110998528.0000\n",
      "Epoch 306/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1133940965376.0000 - val_loss: 942408400896.0000\n",
      "Epoch 307/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1195975376896.0000 - val_loss: 942846115840.0000\n",
      "Epoch 308/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1145235439616.0000 - val_loss: 941555122176.0000\n",
      "Epoch 309/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1171279839232.0000 - val_loss: 940255346688.0000\n",
      "Epoch 310/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1193045131264.0000 - val_loss: 939569250304.0000\n",
      "Epoch 311/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1225969631232.0000 - val_loss: 938868670464.0000\n",
      "Epoch 312/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1233356849152.0000 - val_loss: 940325339136.0000\n",
      "Epoch 313/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1161918283776.0000 - val_loss: 939206377472.0000\n",
      "Epoch 314/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1135246966784.0000 - val_loss: 938805231616.0000\n",
      "Epoch 315/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1157861867520.0000 - val_loss: 938599317504.0000\n",
      "Epoch 316/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1210799357952.0000 - val_loss: 939114430464.0000\n",
      "Epoch 317/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1081575079936.0000 - val_loss: 938356572160.0000\n",
      "Epoch 318/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1152092078080.0000 - val_loss: 937348890624.0000\n",
      "Epoch 319/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1287443316736.0000 - val_loss: 938006151168.0000\n",
      "Epoch 320/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1241797492736.0000 - val_loss: 938913366016.0000\n",
      "Epoch 321/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1239539122176.0000 - val_loss: 938464837632.0000\n",
      "Epoch 322/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1241758957568.0000 - val_loss: 937944612864.0000\n",
      "Epoch 323/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1188826316800.0000 - val_loss: 938216587264.0000\n",
      "Epoch 324/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1180361687040.0000 - val_loss: 937175744512.0000\n",
      "Epoch 325/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1242239467520.0000 - val_loss: 937083142144.0000\n",
      "Epoch 326/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1186203041792.0000 - val_loss: 935779041280.0000\n",
      "Epoch 327/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1196627197952.0000 - val_loss: 936429289472.0000\n",
      "Epoch 328/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1128196079616.0000 - val_loss: 935639777280.0000\n",
      "Epoch 329/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1255651672064.0000 - val_loss: 936284979200.0000\n",
      "Epoch 330/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1202617057280.0000 - val_loss: 934058852352.0000\n",
      "Epoch 331/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1082931216384.0000 - val_loss: 933902483456.0000\n",
      "Epoch 332/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1150450139136.0000 - val_loss: 934710673408.0000\n",
      "Epoch 333/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1094470926336.0000 - val_loss: 933988270080.0000\n",
      "Epoch 334/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1187554263040.0000 - val_loss: 933339922432.0000\n",
      "Epoch 335/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1209118359552.0000 - val_loss: 933925486592.0000\n",
      "Epoch 336/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1318251659264.0000 - val_loss: 932981309440.0000\n",
      "Epoch 337/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1337509675008.0000 - val_loss: 933521784832.0000\n",
      "Epoch 338/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1196286410752.0000 - val_loss: 933702008832.0000\n",
      "Epoch 339/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1108939243520.0000 - val_loss: 933660917760.0000\n",
      "Epoch 340/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1304739184640.0000 - val_loss: 933261017088.0000\n",
      "Epoch 341/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1143486152704.0000 - val_loss: 932962500608.0000\n",
      "Epoch 342/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1166880407552.0000 - val_loss: 933367250944.0000\n",
      "Epoch 343/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1270447734784.0000 - val_loss: 935854276608.0000\n",
      "Epoch 344/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1217163427840.0000 - val_loss: 933428789248.0000\n",
      "Epoch 345/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1173254701056.0000 - val_loss: 932528848896.0000\n",
      "Epoch 346/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1281929773056.0000 - val_loss: 932155490304.0000\n",
      "Epoch 347/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1233972101120.0000 - val_loss: 932124295168.0000\n",
      "Epoch 348/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1154168782848.0000 - val_loss: 933682806784.0000\n",
      "Epoch 349/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1273893617664.0000 - val_loss: 934821560320.0000\n",
      "Epoch 350/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1262499266560.0000 - val_loss: 934328467456.0000\n",
      "Epoch 351/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1201069490176.0000 - val_loss: 935683096576.0000\n",
      "Epoch 352/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1126174818304.0000 - val_loss: 934386335744.0000\n",
      "Epoch 353/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1361727324160.0000 - val_loss: 930555166720.0000\n",
      "Epoch 354/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1248887439360.0000 - val_loss: 930643116032.0000\n",
      "Epoch 355/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1159898726400.0000 - val_loss: 932050829312.0000\n",
      "Epoch 356/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1204257161216.0000 - val_loss: 932233019392.0000\n",
      "Epoch 357/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1243510079488.0000 - val_loss: 931656302592.0000\n",
      "Epoch 358/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1307429568512.0000 - val_loss: 930627059712.0000\n",
      "Epoch 359/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1199150858240.0000 - val_loss: 932082417664.0000\n",
      "Epoch 360/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1128030666752.0000 - val_loss: 932719820800.0000\n",
      "Epoch 361/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1138739773440.0000 - val_loss: 933242929152.0000\n",
      "Epoch 362/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1269776777216.0000 - val_loss: 931993354240.0000\n",
      "Epoch 363/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1279066636288.0000 - val_loss: 934839910400.0000\n",
      "Epoch 364/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1175167696896.0000 - val_loss: 932542939136.0000\n",
      "Epoch 365/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1271168892928.0000 - val_loss: 930497822720.0000\n",
      "Epoch 366/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1213381083136.0000 - val_loss: 930162737152.0000\n",
      "Epoch 367/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1173376073728.0000 - val_loss: 930684731392.0000\n",
      "Epoch 368/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1067167776768.0000 - val_loss: 930845687808.0000\n",
      "Epoch 369/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1185919270912.0000 - val_loss: 931760570368.0000\n",
      "Epoch 370/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1272810569728.0000 - val_loss: 932835033088.0000\n",
      "Epoch 371/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1193126395904.0000 - val_loss: 933699977216.0000\n",
      "Epoch 372/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1084448571392.0000 - val_loss: 932701798400.0000\n",
      "Epoch 373/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1172799356928.0000 - val_loss: 931157966848.0000\n",
      "Epoch 374/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1131786797056.0000 - val_loss: 931413753856.0000\n",
      "Epoch 375/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1156820762624.0000 - val_loss: 930367537152.0000\n",
      "Epoch 376/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1256645984256.0000 - val_loss: 930884681728.0000\n",
      "Epoch 377/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1153449197568.0000 - val_loss: 928897695744.0000\n",
      "Epoch 378/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1184076791808.0000 - val_loss: 928539475968.0000\n",
      "Epoch 379/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1079081893888.0000 - val_loss: 929067761664.0000\n",
      "Epoch 380/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1259533500416.0000 - val_loss: 928868466688.0000\n",
      "Epoch 381/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1269160083456.0000 - val_loss: 929681113088.0000\n",
      "Epoch 382/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1095929430016.0000 - val_loss: 930276048896.0000\n",
      "Epoch 383/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1426005819392.0000 - val_loss: 928000311296.0000\n",
      "Epoch 384/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1051464302592.0000 - val_loss: 926922113024.0000\n",
      "Epoch 385/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1389420347392.0000 - val_loss: 927674466304.0000\n",
      "Epoch 386/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1152002031616.0000 - val_loss: 928621395968.0000\n",
      "Epoch 387/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1197408911360.0000 - val_loss: 929661321216.0000\n",
      "Epoch 388/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1193445031936.0000 - val_loss: 928097501184.0000\n",
      "Epoch 389/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1165102809088.0000 - val_loss: 929357692928.0000\n",
      "Epoch 390/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1229860241408.0000 - val_loss: 930013380608.0000\n",
      "Epoch 391/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1209481691136.0000 - val_loss: 929145880576.0000\n",
      "Epoch 392/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1154604859392.0000 - val_loss: 927943622656.0000\n",
      "Epoch 393/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1354033790976.0000 - val_loss: 931979264000.0000\n",
      "Epoch 394/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1171422445568.0000 - val_loss: 929993392128.0000\n",
      "Epoch 395/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1287794196480.0000 - val_loss: 928059228160.0000\n",
      "Epoch 396/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1225979461632.0000 - val_loss: 930674573312.0000\n",
      "Epoch 397/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1114464976896.0000 - val_loss: 928477216768.0000\n",
      "Epoch 398/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1173495087104.0000 - val_loss: 927109414912.0000\n",
      "Epoch 399/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1144692670464.0000 - val_loss: 927359827968.0000\n",
      "Epoch 400/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1298740150272.0000 - val_loss: 928115326976.0000\n",
      "Epoch 401/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1069585989632.0000 - val_loss: 927509643264.0000\n",
      "Epoch 402/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1367346774016.0000 - val_loss: 926073421824.0000\n",
      "Epoch 403/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1119569707008.0000 - val_loss: 924968615936.0000\n",
      "Epoch 404/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1190069796864.0000 - val_loss: 924345565184.0000\n",
      "Epoch 405/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1197210206208.0000 - val_loss: 924331474944.0000\n",
      "Epoch 406/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1220936204288.0000 - val_loss: 925201989632.0000\n",
      "Epoch 407/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1143443423232.0000 - val_loss: 925975248896.0000\n",
      "Epoch 408/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1151695060992.0000 - val_loss: 927534940160.0000\n",
      "Epoch 409/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1266188025856.0000 - val_loss: 926600265728.0000\n",
      "Epoch 410/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1102754480128.0000 - val_loss: 928186040320.0000\n",
      "Epoch 411/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1251060219904.0000 - val_loss: 926876893184.0000\n",
      "Epoch 412/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1221485527040.0000 - val_loss: 926834098176.0000\n",
      "Epoch 413/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1264502439936.0000 - val_loss: 925056565248.0000\n",
      "Epoch 414/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1268309819392.0000 - val_loss: 923117813760.0000\n",
      "Epoch 415/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1255432650752.0000 - val_loss: 923441889280.0000\n",
      "Epoch 416/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1217464762368.0000 - val_loss: 923473739776.0000\n",
      "Epoch 417/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1080627298304.0000 - val_loss: 922915504128.0000\n",
      "Epoch 418/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1223884406784.0000 - val_loss: 922936868864.0000\n",
      "Epoch 419/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1263125135360.0000 - val_loss: 923033796608.0000\n",
      "Epoch 420/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1203774291968.0000 - val_loss: 923519746048.0000\n",
      "Epoch 421/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1159113211904.0000 - val_loss: 923766685696.0000\n",
      "Epoch 422/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1146218479616.0000 - val_loss: 926635196416.0000\n",
      "Epoch 423/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1201850023936.0000 - val_loss: 927589597184.0000\n",
      "Epoch 424/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1234753552384.0000 - val_loss: 926630084608.0000\n",
      "Epoch 425/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1187590963200.0000 - val_loss: 924114616320.0000\n",
      "Epoch 426/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1179131969536.0000 - val_loss: 923859550208.0000\n",
      "Epoch 427/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1129368125440.0000 - val_loss: 924572516352.0000\n",
      "Epoch 428/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1154022768640.0000 - val_loss: 925208936448.0000\n",
      "Epoch 429/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1219107487744.0000 - val_loss: 928161726464.0000\n",
      "Epoch 430/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1129519382528.0000 - val_loss: 929746124800.0000\n",
      "Epoch 431/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1251797762048.0000 - val_loss: 928204914688.0000\n",
      "Epoch 432/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1282979135488.0000 - val_loss: 928506052608.0000\n",
      "Epoch 433/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1135070019584.0000 - val_loss: 928458539008.0000\n",
      "Epoch 434/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1213607968768.0000 - val_loss: 929126154240.0000\n",
      "Epoch 435/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1078400974848.0000 - val_loss: 929950203904.0000\n",
      "Epoch 436/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1086655823872.0000 - val_loss: 928231784448.0000\n",
      "Epoch 437/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1226762747904.0000 - val_loss: 927800164352.0000\n",
      "Epoch 438/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1148887629824.0000 - val_loss: 929196212224.0000\n",
      "Epoch 439/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1137040162816.0000 - val_loss: 929299365888.0000\n",
      "Epoch 440/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1117968924672.0000 - val_loss: 926062346240.0000\n",
      "Epoch 441/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1185184219136.0000 - val_loss: 923708358656.0000\n",
      "Epoch 442/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1320799830016.0000 - val_loss: 926348148736.0000\n",
      "Epoch 443/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1083078082560.0000 - val_loss: 924631957504.0000\n",
      "Epoch 444/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1105631641600.0000 - val_loss: 924800319488.0000\n",
      "Epoch 445/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1284293525504.0000 - val_loss: 924095217664.0000\n",
      "Epoch 446/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1125360861184.0000 - val_loss: 924736815104.0000\n",
      "Epoch 447/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1212827041792.0000 - val_loss: 924124971008.0000\n",
      "Epoch 448/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1154833055744.0000 - val_loss: 925622272000.0000\n",
      "Epoch 449/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1235125010432.0000 - val_loss: 927168397312.0000\n",
      "Epoch 450/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1288675131392.0000 - val_loss: 928703774720.0000\n",
      "Epoch 451/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1179358068736.0000 - val_loss: 928069320704.0000\n",
      "Epoch 452/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1262213922816.0000 - val_loss: 927300517888.0000\n",
      "Epoch 453/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1169283219456.0000 - val_loss: 928497336320.0000\n",
      "Epoch 454/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1202123177984.0000 - val_loss: 928598130688.0000\n",
      "Epoch 455/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1099506450432.0000 - val_loss: 926750081024.0000\n",
      "Epoch 456/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1169409835008.0000 - val_loss: 925268639744.0000\n",
      "Epoch 457/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1373664575488.0000 - val_loss: 927448694784.0000\n",
      "Epoch 458/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1270960226304.0000 - val_loss: 926210916352.0000\n",
      "Epoch 459/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1181795876864.0000 - val_loss: 926043996160.0000\n",
      "Epoch 460/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1282773876736.0000 - val_loss: 927266111488.0000\n",
      "Epoch 461/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1161660989440.0000 - val_loss: 924937420800.0000\n",
      "Epoch 462/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1112784240640.0000 - val_loss: 922403799040.0000\n",
      "Epoch 463/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1358485651456.0000 - val_loss: 921714229248.0000\n",
      "Epoch 464/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1235027755008.0000 - val_loss: 919805296640.0000\n",
      "Epoch 465/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1249015103488.0000 - val_loss: 918317957120.0000\n",
      "Epoch 466/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1208670224384.0000 - val_loss: 918790930432.0000\n",
      "Epoch 467/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1266547687424.0000 - val_loss: 919702667264.0000\n",
      "Epoch 468/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1291062083584.0000 - val_loss: 920431427584.0000\n",
      "Epoch 469/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1181926162432.0000 - val_loss: 921660358656.0000\n",
      "Epoch 470/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1094095470592.0000 - val_loss: 923415543808.0000\n",
      "Epoch 471/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1295105654784.0000 - val_loss: 923479048192.0000\n",
      "Epoch 472/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1215898976256.0000 - val_loss: 921813778432.0000\n",
      "Epoch 473/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1133810548736.0000 - val_loss: 923136688128.0000\n",
      "Epoch 474/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1222988136448.0000 - val_loss: 925736960000.0000\n",
      "Epoch 475/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1093283676160.0000 - val_loss: 925625679872.0000\n",
      "Epoch 476/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1173006450688.0000 - val_loss: 922714046464.0000\n",
      "Epoch 477/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1195995561984.0000 - val_loss: 923954839552.0000\n",
      "Epoch 478/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1133629145088.0000 - val_loss: 923558674432.0000\n",
      "Epoch 479/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1188182753280.0000 - val_loss: 926146363392.0000\n",
      "Epoch 480/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1136485072896.0000 - val_loss: 921287393280.0000\n",
      "Epoch 481/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1177125912576.0000 - val_loss: 919153475584.0000\n",
      "Epoch 482/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1135366766592.0000 - val_loss: 919616094208.0000\n",
      "Epoch 483/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1148924461056.0000 - val_loss: 920321458176.0000\n",
      "Epoch 484/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1134353186816.0000 - val_loss: 922235895808.0000\n",
      "Epoch 485/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1152188416000.0000 - val_loss: 923710849024.0000\n",
      "Epoch 486/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1157606539264.0000 - val_loss: 922878214144.0000\n",
      "Epoch 487/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1159909736448.0000 - val_loss: 922418348032.0000\n",
      "Epoch 488/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1323464261632.0000 - val_loss: 919031185408.0000\n",
      "Epoch 489/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1119433785344.0000 - val_loss: 921236078592.0000\n",
      "Epoch 490/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1168374628352.0000 - val_loss: 921064701952.0000\n",
      "Epoch 491/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1156474863616.0000 - val_loss: 920657002496.0000\n",
      "Epoch 492/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1160706129920.0000 - val_loss: 920943788032.0000\n",
      "Epoch 493/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1160883863552.0000 - val_loss: 923087863808.0000\n",
      "Epoch 494/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1231298232320.0000 - val_loss: 921676546048.0000\n",
      "Epoch 495/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1188445290496.0000 - val_loss: 921853100032.0000\n",
      "Epoch 496/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1203561562112.0000 - val_loss: 922815954944.0000\n",
      "Epoch 497/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1193896443904.0000 - val_loss: 921061359616.0000\n",
      "Epoch 498/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1330439258112.0000 - val_loss: 920142610432.0000\n",
      "Epoch 499/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1347125510144.0000 - val_loss: 922261585920.0000\n",
      "Epoch 500/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1180582936576.0000 - val_loss: 924260761600.0000\n",
      "Epoch 501/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1196265308160.0000 - val_loss: 921626804224.0000\n",
      "Epoch 502/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1076963770368.0000 - val_loss: 922402226176.0000\n",
      "Epoch 503/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1354775920640.0000 - val_loss: 923920891904.0000\n",
      "Epoch 504/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1336281006080.0000 - val_loss: 921406406656.0000\n",
      "Epoch 505/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1186491793408.0000 - val_loss: 922315718656.0000\n",
      "Epoch 506/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1217216643072.0000 - val_loss: 923043430400.0000\n",
      "Epoch 507/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1148456271872.0000 - val_loss: 921737887744.0000\n",
      "Epoch 508/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1237664268288.0000 - val_loss: 920943919104.0000\n",
      "Epoch 509/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1125596528640.0000 - val_loss: 919535157248.0000\n",
      "Epoch 510/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1173687107584.0000 - val_loss: 921040650240.0000\n",
      "Epoch 511/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1174592028672.0000 - val_loss: 920916066304.0000\n",
      "Epoch 512/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1194163699712.0000 - val_loss: 921107628032.0000\n",
      "Epoch 513/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1269918728192.0000 - val_loss: 919737860096.0000\n",
      "Epoch 514/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1146488225792.0000 - val_loss: 919050977280.0000\n",
      "Epoch 515/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1340937338880.0000 - val_loss: 918680502272.0000\n",
      "Epoch 516/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1113147179008.0000 - val_loss: 920146018304.0000\n",
      "Epoch 517/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1212472754176.0000 - val_loss: 919766958080.0000\n",
      "Epoch 518/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1334869229568.0000 - val_loss: 917551316992.0000\n",
      "Epoch 519/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1270417063936.0000 - val_loss: 918931505152.0000\n",
      "Epoch 520/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1216593002496.0000 - val_loss: 919029088256.0000\n",
      "Epoch 521/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1281264582656.0000 - val_loss: 918737125376.0000\n",
      "Epoch 522/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1117602447360.0000 - val_loss: 920772608000.0000\n",
      "Epoch 523/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1265175756800.0000 - val_loss: 922806845440.0000\n",
      "Epoch 524/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1213698801664.0000 - val_loss: 925134290944.0000\n",
      "Epoch 525/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1228002820096.0000 - val_loss: 924778364928.0000\n",
      "Epoch 526/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1214456004608.0000 - val_loss: 922376536064.0000\n",
      "Epoch 527/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1288713797632.0000 - val_loss: 920217124864.0000\n",
      "Epoch 528/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1284126932992.0000 - val_loss: 919617208320.0000\n",
      "Epoch 529/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1291186864128.0000 - val_loss: 918940811264.0000\n",
      "Epoch 530/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1160272674816.0000 - val_loss: 919607902208.0000\n",
      "Epoch 531/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1050030571520.0000 - val_loss: 920705105920.0000\n",
      "Epoch 532/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1191860109312.0000 - val_loss: 920631115776.0000\n",
      "Epoch 533/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1269260222464.0000 - val_loss: 920411766784.0000\n",
      "Epoch 534/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1320381317120.0000 - val_loss: 922324893696.0000\n",
      "Epoch 535/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1078197878784.0000 - val_loss: 922861633536.0000\n",
      "Epoch 536/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1152786759680.0000 - val_loss: 923328380928.0000\n",
      "Epoch 537/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1163594694656.0000 - val_loss: 924024373248.0000\n",
      "Epoch 538/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1266598019072.0000 - val_loss: 925472063488.0000\n",
      "Epoch 539/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1326891139072.0000 - val_loss: 923090419712.0000\n",
      "Epoch 540/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1098622304256.0000 - val_loss: 921210519552.0000\n",
      "Epoch 541/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1208975228928.0000 - val_loss: 920595595264.0000\n",
      "Epoch 542/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1150909939712.0000 - val_loss: 922642808832.0000\n",
      "Epoch 543/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1165828685824.0000 - val_loss: 925501358080.0000\n",
      "Epoch 544/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1117888708608.0000 - val_loss: 926139875328.0000\n",
      "Epoch 545/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1178263879680.0000 - val_loss: 925962928128.0000\n",
      "Epoch 546/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1198609793024.0000 - val_loss: 926449467392.0000\n",
      "Epoch 547/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1239558651904.0000 - val_loss: 926757879808.0000\n",
      "Epoch 548/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1209734397952.0000 - val_loss: 923736604672.0000\n",
      "Epoch 549/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1256386330624.0000 - val_loss: 923101691904.0000\n",
      "Epoch 550/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1275657715712.0000 - val_loss: 922363691008.0000\n",
      "Epoch 551/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1155915972608.0000 - val_loss: 923437563904.0000\n",
      "Epoch 552/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1132391956480.0000 - val_loss: 927110135808.0000\n",
      "Epoch 553/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1282265317376.0000 - val_loss: 927405572096.0000\n",
      "Epoch 554/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1168576479232.0000 - val_loss: 924157542400.0000\n",
      "Epoch 555/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1157614403584.0000 - val_loss: 924035973120.0000\n",
      "Epoch 556/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1176602411008.0000 - val_loss: 924477030400.0000\n",
      "Epoch 557/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1229633617920.0000 - val_loss: 923716747264.0000\n",
      "Epoch 558/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1331332251648.0000 - val_loss: 920848760832.0000\n",
      "Epoch 559/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1173128478720.0000 - val_loss: 923309768704.0000\n",
      "Epoch 560/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1310614093824.0000 - val_loss: 923473739776.0000\n",
      "Epoch 561/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1144457789440.0000 - val_loss: 922412711936.0000\n",
      "Epoch 562/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1427635568640.0000 - val_loss: 919498784768.0000\n",
      "Epoch 563/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1222134202368.0000 - val_loss: 920714674176.0000\n",
      "Epoch 564/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1217250066432.0000 - val_loss: 921471746048.0000\n",
      "Epoch 565/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1241123258368.0000 - val_loss: 922127630336.0000\n",
      "Epoch 566/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1062035390464.0000 - val_loss: 922046431232.0000\n",
      "Epoch 567/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1210106249216.0000 - val_loss: 920464719872.0000\n",
      "Epoch 568/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1068322783232.0000 - val_loss: 921447366656.0000\n",
      "Epoch 569/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1124831330304.0000 - val_loss: 923118141440.0000\n",
      "Epoch 570/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1241490653184.0000 - val_loss: 923942649856.0000\n",
      "Epoch 571/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1255206813696.0000 - val_loss: 923243970560.0000\n",
      "Epoch 572/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1154270756864.0000 - val_loss: 922644316160.0000\n",
      "Epoch 573/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1152013434880.0000 - val_loss: 922566262784.0000\n",
      "Epoch 574/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1151254659072.0000 - val_loss: 921616777216.0000\n",
      "Epoch 575/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1137760272384.0000 - val_loss: 923246264320.0000\n",
      "Epoch 576/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1290943856640.0000 - val_loss: 924411625472.0000\n",
      "Epoch 577/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1301613510656.0000 - val_loss: 923757445120.0000\n",
      "Epoch 578/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1272854478848.0000 - val_loss: 921099894784.0000\n",
      "Epoch 579/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1231551856640.0000 - val_loss: 920358682624.0000\n",
      "Epoch 580/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1173368602624.0000 - val_loss: 919441637376.0000\n",
      "Epoch 581/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1117552640000.0000 - val_loss: 919798743040.0000\n",
      "Epoch 582/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1166606598144.0000 - val_loss: 920828248064.0000\n",
      "Epoch 583/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1200464986112.0000 - val_loss: 924600958976.0000\n",
      "Epoch 584/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1160254193664.0000 - val_loss: 924690350080.0000\n",
      "Epoch 585/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1153440808960.0000 - val_loss: 922871398400.0000\n",
      "Epoch 586/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1192171667456.0000 - val_loss: 925831659520.0000\n",
      "Epoch 587/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1191695876096.0000 - val_loss: 926793007104.0000\n",
      "Epoch 588/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1229343817728.0000 - val_loss: 926529880064.0000\n",
      "Epoch 589/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1226777296896.0000 - val_loss: 926256267264.0000\n",
      "Epoch 590/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1136045719552.0000 - val_loss: 927274631168.0000\n",
      "Epoch 591/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1138247729152.0000 - val_loss: 928063356928.0000\n",
      "Epoch 592/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1212304195584.0000 - val_loss: 928173522944.0000\n",
      "Epoch 593/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1309626204160.0000 - val_loss: 925643374592.0000\n",
      "Epoch 594/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1071935848448.0000 - val_loss: 924411625472.0000\n",
      "Epoch 595/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1333784215552.0000 - val_loss: 923551203328.0000\n",
      "Epoch 596/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1290463477760.0000 - val_loss: 921049432064.0000\n",
      "Epoch 597/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1226416586752.0000 - val_loss: 920732762112.0000\n",
      "Epoch 598/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1111816798208.0000 - val_loss: 920475533312.0000\n",
      "Epoch 599/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1115928002560.0000 - val_loss: 921551634432.0000\n",
      "Epoch 600/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1150109483008.0000 - val_loss: 921052643328.0000\n",
      "Epoch 601/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1244642148352.0000 - val_loss: 920994709504.0000\n",
      "Epoch 602/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1204163313664.0000 - val_loss: 920754323456.0000\n",
      "Epoch 603/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1231031762944.0000 - val_loss: 922717913088.0000\n",
      "Epoch 604/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1245499097088.0000 - val_loss: 924581888000.0000\n",
      "Epoch 605/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1295308554240.0000 - val_loss: 924546236416.0000\n",
      "Epoch 606/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1270767812608.0000 - val_loss: 924559474688.0000\n",
      "Epoch 607/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1146523615232.0000 - val_loss: 924015263744.0000\n",
      "Epoch 608/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1160460632064.0000 - val_loss: 924826861568.0000\n",
      "Epoch 609/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1146225426432.0000 - val_loss: 923484422144.0000\n",
      "Epoch 610/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1172504444928.0000 - val_loss: 924807593984.0000\n",
      "Epoch 611/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1249932738560.0000 - val_loss: 925462233088.0000\n",
      "Epoch 612/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1192713912320.0000 - val_loss: 924209577984.0000\n",
      "Epoch 613/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1070387101696.0000 - val_loss: 925644423168.0000\n",
      "Epoch 614/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1066700898304.0000 - val_loss: 925738008576.0000\n",
      "Epoch 615/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1091932520448.0000 - val_loss: 925988618240.0000\n",
      "Epoch 616/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1204365688832.0000 - val_loss: 924255453184.0000\n",
      "Epoch 617/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1154455699456.0000 - val_loss: 924911730688.0000\n",
      "Epoch 618/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1218099544064.0000 - val_loss: 926265049088.0000\n",
      "Epoch 619/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1146258587648.0000 - val_loss: 923142586368.0000\n",
      "Epoch 620/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1245124624384.0000 - val_loss: 924301787136.0000\n",
      "Epoch 621/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1125617369088.0000 - val_loss: 925121642496.0000\n",
      "Epoch 622/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1146174701568.0000 - val_loss: 926420828160.0000\n",
      "Epoch 623/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1215727271936.0000 - val_loss: 924862185472.0000\n",
      "Epoch 624/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1099552915456.0000 - val_loss: 926165106688.0000\n",
      "Epoch 625/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1137577689088.0000 - val_loss: 927617581056.0000\n",
      "Epoch 626/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1363648446464.0000 - val_loss: 931432431616.0000\n",
      "Epoch 627/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1090070839296.0000 - val_loss: 928424591360.0000\n",
      "Epoch 628/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1372804743168.0000 - val_loss: 925933830144.0000\n",
      "Epoch 629/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1257897721856.0000 - val_loss: 925441720320.0000\n",
      "Epoch 630/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1289396944896.0000 - val_loss: 927768969216.0000\n",
      "Epoch 631/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1031176585216.0000 - val_loss: 926881349632.0000\n",
      "Epoch 632/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1026378563584.0000 - val_loss: 925958012928.0000\n",
      "Epoch 633/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1110518792192.0000 - val_loss: 926757617664.0000\n",
      "Epoch 634/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1178516586496.0000 - val_loss: 926670913536.0000\n",
      "Epoch 635/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1242705297408.0000 - val_loss: 926649942016.0000\n",
      "Epoch 636/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1335799709696.0000 - val_loss: 928234536960.0000\n",
      "Epoch 637/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1259383816192.0000 - val_loss: 926769217536.0000\n",
      "Epoch 638/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1206736650240.0000 - val_loss: 923496284160.0000\n",
      "Epoch 639/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1248257769472.0000 - val_loss: 922588610560.0000\n",
      "Epoch 640/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1105060036608.0000 - val_loss: 922770931712.0000\n",
      "Epoch 641/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1266025234432.0000 - val_loss: 921525485568.0000\n",
      "Epoch 642/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1255399620608.0000 - val_loss: 922720993280.0000\n",
      "Epoch 643/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1209234227200.0000 - val_loss: 925528948736.0000\n",
      "Epoch 644/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1128827060224.0000 - val_loss: 925217193984.0000\n",
      "Epoch 645/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1194828365824.0000 - val_loss: 926338580480.0000\n",
      "Epoch 646/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1252700061696.0000 - val_loss: 924598403072.0000\n",
      "Epoch 647/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1310730747904.0000 - val_loss: 924667805696.0000\n",
      "Epoch 648/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1196648038400.0000 - val_loss: 925107290112.0000\n",
      "Epoch 649/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1149844193280.0000 - val_loss: 926070734848.0000\n",
      "Epoch 650/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1211389444096.0000 - val_loss: 924155838464.0000\n",
      "Epoch 651/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1205515714560.0000 - val_loss: 923662680064.0000\n",
      "Epoch 652/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1310542921728.0000 - val_loss: 925132849152.0000\n",
      "Epoch 653/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1297692753920.0000 - val_loss: 923537178624.0000\n",
      "Epoch 654/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1191016136704.0000 - val_loss: 923480031232.0000\n",
      "Epoch 655/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1166390329344.0000 - val_loss: 924593225728.0000\n",
      "Epoch 656/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1198190493696.0000 - val_loss: 927728467968.0000\n",
      "Epoch 657/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1191053099008.0000 - val_loss: 929101119488.0000\n",
      "Epoch 658/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1098928160768.0000 - val_loss: 932121608192.0000\n",
      "Epoch 659/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1216414482432.0000 - val_loss: 932706975744.0000\n",
      "Epoch 660/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1173824733184.0000 - val_loss: 931480535040.0000\n",
      "Epoch 661/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1247203819520.0000 - val_loss: 932158439424.0000\n",
      "Epoch 662/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1248201801728.0000 - val_loss: 933494652928.0000\n",
      "Epoch 663/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1095865466880.0000 - val_loss: 932559060992.0000\n",
      "Epoch 664/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1192035876864.0000 - val_loss: 930710683648.0000\n",
      "Epoch 665/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1153460862976.0000 - val_loss: 928376029184.0000\n",
      "Epoch 666/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1127850835968.0000 - val_loss: 929615314944.0000\n",
      "Epoch 667/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1051039498240.0000 - val_loss: 929155383296.0000\n",
      "Epoch 668/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1297212375040.0000 - val_loss: 926894325760.0000\n",
      "Epoch 669/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1345200193536.0000 - val_loss: 926308106240.0000\n",
      "Epoch 670/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1148172107776.0000 - val_loss: 927933988864.0000\n",
      "Epoch 671/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1149852844032.0000 - val_loss: 931437936640.0000\n",
      "Epoch 672/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1077532753920.0000 - val_loss: 927634948096.0000\n",
      "Epoch 673/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1065104179200.0000 - val_loss: 929375977472.0000\n",
      "Epoch 674/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1276996485120.0000 - val_loss: 927711887360.0000\n",
      "Epoch 675/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1234245517312.0000 - val_loss: 926590697472.0000\n",
      "Epoch 676/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1235283345408.0000 - val_loss: 925841555456.0000\n",
      "Epoch 677/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1154907373568.0000 - val_loss: 926852710400.0000\n",
      "Epoch 678/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1242417856512.0000 - val_loss: 926166614016.0000\n",
      "Epoch 679/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1100834144256.0000 - val_loss: 925186719744.0000\n",
      "Epoch 680/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1118331863040.0000 - val_loss: 923682603008.0000\n",
      "Epoch 681/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1204942536704.0000 - val_loss: 923919056896.0000\n",
      "Epoch 682/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1176584060928.0000 - val_loss: 923367309312.0000\n",
      "Epoch 683/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1236660256768.0000 - val_loss: 925025107968.0000\n",
      "Epoch 684/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1073492918272.0000 - val_loss: 924145483776.0000\n",
      "Epoch 685/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1253981159424.0000 - val_loss: 925159456768.0000\n",
      "Epoch 686/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1069443383296.0000 - val_loss: 925605888000.0000\n",
      "Epoch 687/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1294773911552.0000 - val_loss: 930760949760.0000\n",
      "Epoch 688/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1097385705472.0000 - val_loss: 929906425856.0000\n",
      "Epoch 689/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1221890932736.0000 - val_loss: 928180600832.0000\n",
      "Epoch 690/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1245518626816.0000 - val_loss: 927773032448.0000\n",
      "Epoch 691/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1184578273280.0000 - val_loss: 924444590080.0000\n",
      "Epoch 692/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1107729055744.0000 - val_loss: 925810098176.0000\n",
      "Epoch 693/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1224641478656.0000 - val_loss: 925695868928.0000\n",
      "Epoch 694/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1176694685696.0000 - val_loss: 925857218560.0000\n",
      "Epoch 695/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1230571175936.0000 - val_loss: 927240617984.0000\n",
      "Epoch 696/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1229419708416.0000 - val_loss: 926469259264.0000\n",
      "Epoch 697/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1128949350400.0000 - val_loss: 928428326912.0000\n",
      "Epoch 698/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1182250565632.0000 - val_loss: 929280557056.0000\n",
      "Epoch 699/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1173833515008.0000 - val_loss: 930363736064.0000\n",
      "Epoch 700/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1187458580480.0000 - val_loss: 929693040640.0000\n",
      "Epoch 701/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1182146625536.0000 - val_loss: 929386790912.0000\n",
      "Epoch 702/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1096016592896.0000 - val_loss: 927464882176.0000\n",
      "Epoch 703/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1075464372224.0000 - val_loss: 924898295808.0000\n",
      "Epoch 704/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1090529001472.0000 - val_loss: 927296782336.0000\n",
      "Epoch 705/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1124583342080.0000 - val_loss: 924285206528.0000\n",
      "Epoch 706/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1223309656064.0000 - val_loss: 925681451008.0000\n",
      "Epoch 707/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1191815020544.0000 - val_loss: 927217614848.0000\n",
      "Epoch 708/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1166616690688.0000 - val_loss: 926177230848.0000\n",
      "Epoch 709/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1221559189504.0000 - val_loss: 925621223424.0000\n",
      "Epoch 710/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1192469069824.0000 - val_loss: 921134039040.0000\n",
      "Epoch 711/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1224635973632.0000 - val_loss: 921682247680.0000\n",
      "Epoch 712/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1358496661504.0000 - val_loss: 920905973760.0000\n",
      "Epoch 713/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1235305627648.0000 - val_loss: 921674645504.0000\n",
      "Epoch 714/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1316647731200.0000 - val_loss: 924575465472.0000\n",
      "Epoch 715/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1137870241792.0000 - val_loss: 925227220992.0000\n",
      "Epoch 716/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1147056160768.0000 - val_loss: 927047548928.0000\n",
      "Epoch 717/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1205508898816.0000 - val_loss: 926709776384.0000\n",
      "Epoch 718/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1346703458304.0000 - val_loss: 924302508032.0000\n",
      "Epoch 719/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1204002488320.0000 - val_loss: 922766082048.0000\n",
      "Epoch 720/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1260210094080.0000 - val_loss: 923343323136.0000\n",
      "Epoch 721/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1441300611072.0000 - val_loss: 922424508416.0000\n",
      "Epoch 722/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1148855779328.0000 - val_loss: 922171277312.0000\n",
      "Epoch 723/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1163967594496.0000 - val_loss: 923342864384.0000\n",
      "Epoch 724/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1175470473216.0000 - val_loss: 925342433280.0000\n",
      "Epoch 725/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1222104186880.0000 - val_loss: 924917039104.0000\n",
      "Epoch 726/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1161087025152.0000 - val_loss: 925512433664.0000\n",
      "Epoch 727/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1133716176896.0000 - val_loss: 926180835328.0000\n",
      "Epoch 728/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1185767882752.0000 - val_loss: 924340912128.0000\n",
      "Epoch 729/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1154523201536.0000 - val_loss: 924216786944.0000\n",
      "Epoch 730/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1115282735104.0000 - val_loss: 927340691456.0000\n",
      "Epoch 731/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1346884337664.0000 - val_loss: 928186695680.0000\n",
      "Epoch 732/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1147616231424.0000 - val_loss: 925034086400.0000\n",
      "Epoch 733/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1273474842624.0000 - val_loss: 923430551552.0000\n",
      "Epoch 734/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1119861997568.0000 - val_loss: 924441968640.0000\n",
      "Epoch 735/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1226808492032.0000 - val_loss: 924684779520.0000\n",
      "Epoch 736/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1259258249216.0000 - val_loss: 924130410496.0000\n",
      "Epoch 737/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1199201976320.0000 - val_loss: 925660217344.0000\n",
      "Epoch 738/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1117293117440.0000 - val_loss: 929459011584.0000\n",
      "Epoch 739/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1179214675968.0000 - val_loss: 930079637504.0000\n",
      "Epoch 740/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1275407499264.0000 - val_loss: 930621292544.0000\n",
      "Epoch 741/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1215936856064.0000 - val_loss: 926719672320.0000\n",
      "Epoch 742/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1312199409664.0000 - val_loss: 929539162112.0000\n",
      "Epoch 743/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1173968519168.0000 - val_loss: 927189762048.0000\n",
      "Epoch 744/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1184601473024.0000 - val_loss: 928734248960.0000\n",
      "Epoch 745/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1097341403136.0000 - val_loss: 928113885184.0000\n",
      "Epoch 746/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1290090315776.0000 - val_loss: 922679377920.0000\n",
      "Epoch 747/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1198175813632.0000 - val_loss: 920751112192.0000\n",
      "Epoch 748/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1158174736384.0000 - val_loss: 922783645696.0000\n",
      "Epoch 749/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1163526406144.0000 - val_loss: 924675407872.0000\n",
      "Epoch 750/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1162618077184.0000 - val_loss: 924045672448.0000\n",
      "Epoch 751/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1072560603136.0000 - val_loss: 925372907520.0000\n",
      "Epoch 752/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1104128376832.0000 - val_loss: 926889869312.0000\n",
      "Epoch 753/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1125125324800.0000 - val_loss: 927219712000.0000\n",
      "Epoch 754/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1245929537536.0000 - val_loss: 924316663808.0000\n",
      "Epoch 755/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1240506433536.0000 - val_loss: 925169156096.0000\n",
      "Epoch 756/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1210881933312.0000 - val_loss: 924868476928.0000\n",
      "Epoch 757/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1126016221184.0000 - val_loss: 927679840256.0000\n",
      "Epoch 758/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1222131974144.0000 - val_loss: 925855842304.0000\n",
      "Epoch 759/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1056721928192.0000 - val_loss: 923613331456.0000\n",
      "Epoch 760/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1280736624640.0000 - val_loss: 924128772096.0000\n",
      "Epoch 761/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1319409942528.0000 - val_loss: 922053574656.0000\n",
      "Epoch 762/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1129143861248.0000 - val_loss: 923193769984.0000\n",
      "Epoch 763/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1322464968704.0000 - val_loss: 923798929408.0000\n",
      "Epoch 764/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1121178877952.0000 - val_loss: 922236944384.0000\n",
      "Epoch 765/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1208892260352.0000 - val_loss: 919887347712.0000\n",
      "Epoch 766/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1321372221440.0000 - val_loss: 920877858816.0000\n",
      "Epoch 767/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1220896882688.0000 - val_loss: 919442161664.0000\n",
      "Epoch 768/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1138805833728.0000 - val_loss: 918619947008.0000\n",
      "Epoch 769/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1192549023744.0000 - val_loss: 918418161664.0000\n",
      "Epoch 770/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1086149427200.0000 - val_loss: 919378264064.0000\n",
      "Epoch 771/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1172868562944.0000 - val_loss: 918722838528.0000\n",
      "Epoch 772/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1248797130752.0000 - val_loss: 918090350592.0000\n",
      "Epoch 773/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1194915266560.0000 - val_loss: 916923678720.0000\n",
      "Epoch 774/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1097790062592.0000 - val_loss: 916901330944.0000\n",
      "Epoch 775/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1107800752128.0000 - val_loss: 918555525120.0000\n",
      "Epoch 776/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1208179097600.0000 - val_loss: 917777219584.0000\n",
      "Epoch 777/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1165916110848.0000 - val_loss: 919499309056.0000\n",
      "Epoch 778/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1218610724864.0000 - val_loss: 921479086080.0000\n",
      "Epoch 779/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1161050324992.0000 - val_loss: 922843742208.0000\n",
      "Epoch 780/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1233753341952.0000 - val_loss: 922167083008.0000\n",
      "Epoch 781/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1339509833728.0000 - val_loss: 922309296128.0000\n",
      "Epoch 782/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1191912931328.0000 - val_loss: 922889682944.0000\n",
      "Epoch 783/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1259642683392.0000 - val_loss: 924356182016.0000\n",
      "Epoch 784/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1114100989952.0000 - val_loss: 922766802944.0000\n",
      "Epoch 785/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1142361292800.0000 - val_loss: 920192221184.0000\n",
      "Epoch 786/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1205890318336.0000 - val_loss: 921022758912.0000\n",
      "Epoch 787/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1097086009344.0000 - val_loss: 920087429120.0000\n",
      "Epoch 788/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1133947387904.0000 - val_loss: 919695065088.0000\n",
      "Epoch 789/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1420526878720.0000 - val_loss: 920468324352.0000\n",
      "Epoch 790/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1263784296448.0000 - val_loss: 921632833536.0000\n",
      "Epoch 791/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1236593410048.0000 - val_loss: 922836860928.0000\n",
      "Epoch 792/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1308274982912.0000 - val_loss: 919815127040.0000\n",
      "Epoch 793/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1182581260288.0000 - val_loss: 920940052480.0000\n",
      "Epoch 794/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1156713414656.0000 - val_loss: 923320909824.0000\n",
      "Epoch 795/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1285768871936.0000 - val_loss: 922589003776.0000\n",
      "Epoch 796/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1183141855232.0000 - val_loss: 925206839296.0000\n",
      "Epoch 797/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1215950618624.0000 - val_loss: 922369982464.0000\n",
      "Epoch 798/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1223346356224.0000 - val_loss: 924393013248.0000\n",
      "Epoch 799/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1199297265664.0000 - val_loss: 922404716544.0000\n",
      "Epoch 800/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1404892872704.0000 - val_loss: 921481052160.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x16d7be3a180>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train/fit neural network with validation data\n",
    "# see the instructions on the train/test -split above on how to split the data correctly\n",
    "model.fit(x=X_train, y=y_train, epochs=800, validation_data=(X_val, y_val), callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance and error metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's use pandas for this (easy code)\n",
    "# try to look if the model is actually training \n",
    "# => the error is going downwards\n",
    "# if using validation data, you get two lines\n",
    "# in this case, see if the lines follow a similar trend \n",
    "# (they don't always overlap with complex data, the trend is more important)\n",
    "loss_df = pd.DataFrame(model.history.history)\n",
    "loss_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload the best version of the model from history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically replace the model version of LAST EPOCH with the best version from training history!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload model from best model checkpoint\n",
    "from keras.models import load_model\n",
    "model = load_model(\"best_model_regression2_housing.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data evaluation:\n",
      "1195605622784.0\n",
      "\n",
      "Train data evaluation:\n",
      "960001998848.0\n"
     ]
    }
   ],
   "source": [
    "# compare the final model loss/evaluation values\n",
    "print(\"Test data evaluation:\")\n",
    "print(model.evaluate(X_test, y_test, verbose=0))\n",
    "print(\"\\nTrain data evaluation:\")\n",
    "print(model.evaluate(X_train, y_train, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test True Y</th>\n",
       "      <th>Model Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4200000</td>\n",
       "      <td>4614287.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7000000</td>\n",
       "      <td>6774323.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3010000</td>\n",
       "      <td>4194349.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3430000</td>\n",
       "      <td>3068602.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2275000</td>\n",
       "      <td>3401636.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5523000</td>\n",
       "      <td>5161378.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3115000</td>\n",
       "      <td>3288312.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4900000</td>\n",
       "      <td>4517897.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4893000</td>\n",
       "      <td>6065172.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2695000</td>\n",
       "      <td>2942574.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4550000</td>\n",
       "      <td>3692327.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5950000</td>\n",
       "      <td>6019720.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4690000</td>\n",
       "      <td>4945884.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4900000</td>\n",
       "      <td>4146869.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5250000</td>\n",
       "      <td>5710049.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1750000</td>\n",
       "      <td>2859667.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4305000</td>\n",
       "      <td>3530456.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3640000</td>\n",
       "      <td>4275900.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3920000</td>\n",
       "      <td>6148107.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6650000</td>\n",
       "      <td>6767261.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1890000</td>\n",
       "      <td>2819232.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4375000</td>\n",
       "      <td>3299221.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2380000</td>\n",
       "      <td>4556881.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3290000</td>\n",
       "      <td>2951301.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2660000</td>\n",
       "      <td>3329734.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>8680000</td>\n",
       "      <td>6603788.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3500000</td>\n",
       "      <td>3352746.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4403000</td>\n",
       "      <td>3975164.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6083000</td>\n",
       "      <td>5186149.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2450000</td>\n",
       "      <td>3749828.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3920000</td>\n",
       "      <td>3451552.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2520000</td>\n",
       "      <td>3301969.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4007500</td>\n",
       "      <td>4680699.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5600000</td>\n",
       "      <td>5796843.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>6440000</td>\n",
       "      <td>7276418.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3360000</td>\n",
       "      <td>4644577.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>9100000</td>\n",
       "      <td>4646650.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3087000</td>\n",
       "      <td>3989019.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2310000</td>\n",
       "      <td>2763670.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1750000</td>\n",
       "      <td>3288312.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3325000</td>\n",
       "      <td>3639709.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4515000</td>\n",
       "      <td>3965214.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>5145000</td>\n",
       "      <td>5010905.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3780000</td>\n",
       "      <td>3848634.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>3500000</td>\n",
       "      <td>5043529.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2660000</td>\n",
       "      <td>2928175.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2870000</td>\n",
       "      <td>3776069.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>3465000</td>\n",
       "      <td>3932281.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>6930000</td>\n",
       "      <td>6954912.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3605000</td>\n",
       "      <td>3400353.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>4200000</td>\n",
       "      <td>4551140.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>5110000</td>\n",
       "      <td>5515157.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>7455000</td>\n",
       "      <td>4627771.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>3118850</td>\n",
       "      <td>3641122.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>6293000</td>\n",
       "      <td>6648388.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>5040000</td>\n",
       "      <td>5887791.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>3920000</td>\n",
       "      <td>5614052.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>6650000</td>\n",
       "      <td>6957807.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>3500000</td>\n",
       "      <td>4174077.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>3010000</td>\n",
       "      <td>3422171.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Test True Y  Model Predictions\n",
       "0       4200000         4614287.50\n",
       "1       7000000         6774323.50\n",
       "2       3010000         4194349.50\n",
       "3       3430000         3068602.25\n",
       "4       2275000         3401636.75\n",
       "5       5523000         5161378.50\n",
       "6       3115000         3288312.25\n",
       "7       4900000         4517897.50\n",
       "8       4893000         6065172.50\n",
       "9       2695000         2942574.75\n",
       "10      4550000         3692327.25\n",
       "11      5950000         6019720.50\n",
       "12      4690000         4945884.00\n",
       "13      4900000         4146869.25\n",
       "14      5250000         5710049.50\n",
       "15      1750000         2859667.75\n",
       "16      4305000         3530456.75\n",
       "17      3640000         4275900.00\n",
       "18      3920000         6148107.00\n",
       "19      6650000         6767261.50\n",
       "20      1890000         2819232.75\n",
       "21      4375000         3299221.50\n",
       "22      2380000         4556881.50\n",
       "23      3290000         2951301.75\n",
       "24      2660000         3329734.00\n",
       "25      8680000         6603788.50\n",
       "26      3500000         3352746.75\n",
       "27      4403000         3975164.25\n",
       "28      6083000         5186149.50\n",
       "29      2450000         3749828.25\n",
       "30      3920000         3451552.75\n",
       "31      2520000         3301969.25\n",
       "32      4007500         4680699.50\n",
       "33      5600000         5796843.50\n",
       "34      6440000         7276418.50\n",
       "35      3360000         4644577.00\n",
       "36      9100000         4646650.50\n",
       "37      3087000         3989019.50\n",
       "38      2310000         2763670.00\n",
       "39      1750000         3288312.25\n",
       "40      3325000         3639709.25\n",
       "41      4515000         3965214.00\n",
       "42      5145000         5010905.50\n",
       "43      3780000         3848634.25\n",
       "44      3500000         5043529.50\n",
       "45      2660000         2928175.25\n",
       "46      2870000         3776069.75\n",
       "47      3465000         3932281.75\n",
       "48      6930000         6954912.00\n",
       "49      3605000         3400353.75\n",
       "50      4200000         4551140.50\n",
       "51      5110000         5515157.50\n",
       "52      7455000         4627771.50\n",
       "53      3118850         3641122.75\n",
       "54      6293000         6648388.50\n",
       "55      5040000         5887791.50\n",
       "56      3920000         5614052.00\n",
       "57      6650000         6957807.50\n",
       "58      3500000         4174077.50\n",
       "59      3010000         3422171.25"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get test predictions\n",
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "# reshape the data for easier comparison table\n",
    "test_predictions = pd.Series(test_predictions.reshape(len(y_test),))\n",
    "pred_df = pd.DataFrame(np.asarray(y_test), columns=['Test True Y'])\n",
    "pred_df = pd.concat([pred_df, test_predictions], axis=1)\n",
    "pred_df.columns = ['Test True Y', 'Model Predictions']\n",
    "\n",
    "# print the comparison table - true values vs. model predicted values\n",
    "# we can nicely see here how far off our model is in some cases\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Test True Y', ylabel='Model Predictions'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# these values follow a linear diagonal line = good predictions\n",
    "# we basically compare the predicted values \n",
    "# to true test values and see the differences\n",
    "sns.scatterplot(x='Test True Y', y='Model Predictions', data=pred_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Much better metrics when compared to lecture 2, but still far from optimal! But it's a good start!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE\n",
      "790285.12 $\n",
      "\n",
      "MSE\n",
      "1195605622784.0 $^2\n",
      "\n",
      "RMSE:\n",
      "1093437.53 $\n",
      "\n",
      "R-squared:\n",
      "0.56\n",
      "\n",
      "Explained variance score:\n",
      "0.57\n"
     ]
    }
   ],
   "source": [
    "# MAE - Mean average error\n",
    "print(\"MAE\")\n",
    "print(round(metrics.mean_absolute_error(y_test, test_predictions), 2), \"$\")\n",
    "\n",
    "# MSE - Mean square error\n",
    "print(\"\\nMSE\")\n",
    "print(round(metrics.mean_squared_error(y_test, test_predictions), 2), \"$^2\")\n",
    "\n",
    "# RMSE - Root mean square error\n",
    "print('\\nRMSE:')\n",
    "print(round(np.sqrt(metrics.mean_squared_error(y_test, test_predictions)), 2), \"$\")\n",
    "\n",
    "# R-squared. 0 = the model descibes the dataset poorly\n",
    "# 1 = model describes the dataset perfectly\n",
    "print('\\nR-squared:')\n",
    "print(round(metrics.r2_score(y_test, test_predictions), 2))\n",
    "\n",
    "# Explained Variance Score => 0 = the model descibes the dataset poorly\n",
    "# 1 = model describes the dataset perfectly\n",
    "# high variance score = model is a good fit for the data \n",
    "# low variance score = model is not a good fit for the data\n",
    "# the higher the score, the model is more able to explain the variation in the data\n",
    "# if score is low, we might need more and better data\n",
    "print(\"\\nExplained variance score:\")\n",
    "print(round(metrics.explained_variance_score(y_test, test_predictions), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tuomas.valtanen\\AppData\\Local\\Temp\\ipykernel_12364\\3124900743.py:5: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot((y_test - test_predictions))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# if the prediction distribution are far from normal distribution\n",
    "# then the model is not probably good enough\n",
    "# distplot is deprecating in future pandas-version\n",
    "# unfortunately, there's no exact alternative to do this plot at the moment\n",
    "sns.distplot((y_test - test_predictions))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying the model in practice with new imaginary house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11410000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10850000</td>\n",
       "      <td>7500</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9870000</td>\n",
       "      <td>8100</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  area  bedrooms  bathrooms  stories  mainroad  guestroom  \\\n",
       "4  11410000  7420         4          1        2         1          1   \n",
       "5  10850000  7500         3          3        1         1          0   \n",
       "8   9870000  8100         4          1        2         1          1   \n",
       "\n",
       "   basement  hotwaterheating  airconditioning  parking  prefarea  furnished  \n",
       "4         1                0                1        2         0          1  \n",
       "5         1                0                1        2         1          1  \n",
       "8         1                0                1        2         1          1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just to see what kind of values are usually in the dataset\n",
    "# so we can test with the tester_row\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since we change the furnished-variable, we have to modify the code below to match the new variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try with some new imaginary data\n",
    "# this example uses the student performance index score dataset\n",
    "# modify this as needed regarding your own dataset\n",
    "tester_row = {\n",
    "    'area': 7420, \n",
    "    'bedrooms': 4, \n",
    "    'bathrooms': 2, \n",
    "    'stories': 3, \n",
    "    'mainroad': 1,\n",
    "    'guestroom': 0, \n",
    "    'basement': 0, \n",
    "    'hotwaterheating': 0, \n",
    "    'airconditioning': 1,\n",
    "    'parking': 2,\n",
    "    'prefarea': 1,\n",
    "    'furnished': 1\n",
    "}\n",
    "\n",
    "# convert to pandas-format\n",
    "tester_row = pd.DataFrame([tester_row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\n",
      "Estimated house price with this example:\n",
      "$ 7629409.0\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "# get the prediction from the model and print out the result\n",
    "result = model.predict(tester_row)[0]\n",
    "\n",
    "print()\n",
    "print(f\"Estimated house price with this example:\")\n",
    "print(f\"$ {round(float(result[0]), 2)}\")\n",
    "print(\"----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model above undershoots the estimation\n",
    "# should be 13.3 million => prediction is 6.45 million"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
