{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN for regression, example 2, house market data (how to handle categorical variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THIS VERSION DEMONSTRATES HOW YOU CAN USE SCALERS AND TRANSFORMATIONS IN DATA (also potential beginner's traps will be mentioned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, using manual scalers and transformations for a dataset (scikit-learn) will make your machine learning training more complicated, but in some projects it's the necessary thing to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports / modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikit-learn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# pip install tensorflow\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "# you can lock down all random seeds in order \n",
    "# to reproduce same results, metrics etc. every time\n",
    "# this technique is often used in working life in order\n",
    "# to cut down the random variation between training runs\n",
    "import os\n",
    "import random\n",
    "seed = 869173539\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)      \n",
    "random.seed(seed)                             \n",
    "np.random.seed(seed)                          \n",
    "tf.random.set_seed(seed) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "df = pd.read_csv(\"Housing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WE HAVE SOME BOOLEAN CATEGORIES\n",
    "# => change them to 0 and 1\n",
    "\n",
    "# this just converts the value of column to 0 or 1\n",
    "# factorize in pandas works too, but only one column at a time\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "variables = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']\n",
    "encoder = LabelEncoder()\n",
    "df[variables] = df[variables].apply(encoder.fit_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert text categories with multiple choices into multiple variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a helper function for pandas and replace\n",
    "# the different furnishingstatus values into either 0 or 1\n",
    "def modify_furnishing(row):\n",
    "    if row['furnishingstatus'] == 'unfurnished':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "# create a new boolean/binary furnished status \n",
    "# 0 => not furnished\n",
    "# 1 => either fully or partially furnished\n",
    "df['furnished'] = df.apply(modify_furnishing, axis=1)\n",
    "\n",
    "# drop the original 3-option furnishing status\n",
    "df = df.drop(\"furnishingstatus\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can also get as fancy you wish with outlier detection and removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\n"
     ]
    }
   ],
   "source": [
    "# let's try a fancier example for outlier removal\n",
    "# this code is originally from:\n",
    "# https://stackoverflow.com/questions/69248118/detect-outliers-across-all-columns-of-pandas-dataframe\n",
    "\n",
    "def find_outliers(col):\n",
    "    q1 = col.quantile(.15)\n",
    "    q3 = col.quantile(.85)\n",
    "    IQR = q3 - q1\n",
    "    ll = q1 - (1.5*IQR)\n",
    "    ul = q3 + (1.5*IQR)\n",
    "    upper_outliers = col[col > ul].index.tolist()\n",
    "    lower_outliers = col[col < ll].index.tolist()\n",
    "    bad_indices = list(set(upper_outliers + lower_outliers))\n",
    "    return(bad_indices)\n",
    "\n",
    "# get indexes of all outliers into a list\n",
    "bad_indexes = []\n",
    "for col in df.columns:\n",
    "    if df[col].dtype in [\"int64\",\"float64\"]:\n",
    "        bad_indexes.append(find_outliers(df[col]))\n",
    "\n",
    "\n",
    "# modify the list so that we can drop these rows from the DataFrame\n",
    "\n",
    "bad_indexes = set(list(np.concatenate(bad_indexes).flat))\n",
    "\n",
    "print(len(bad_indexes))\n",
    "\n",
    "# drop the outliers\n",
    "df = df.drop(bad_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X/y -split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform X/y -split\n",
    "# if you  have more than one independent variable, list them all here\n",
    "# leave out the target variable! (dependent variable)\n",
    "\n",
    "# this is a nice and common trick => everything EXCEPT target variable => support variable\n",
    "X = df.drop(\"price\", axis=1)\n",
    "\n",
    "# have only the target variable here (dependent variable)\n",
    "y = df[\"price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test/validation -split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IF YOU EVER USE DATA SCALING/NORMALIZATION/STANDARDIZATION/TRANSFORMATION instead of neural network layers, ALWAYS DO THESE STEPS AFTER THE TRAIN-TEST -SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, FunctionTransformer, PowerTransformer, QuantileTransformer\n",
    "\n",
    "# split the dataset into train/test/validation by using the trick we have used\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalers and transformations can be done after train/test -split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple normalization, standardization, regularization and transformation algorithms available. This example uses MinMaxScaler for support variables nad QuantileTransformer for the target. You can search for more online and experiment with them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tuomas.valtanen\\DL2025lecturenotes2\\DeepLearning2025\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:2846: UserWarning: n_quantiles (1000) is greater than the total number of samples (280). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# scalers are always fit (trained) with training data only, DON'T USE TESTING DATA FOR FITTING A SCALER\n",
    "# because we otherwise we leak information of the correct answers to the model\n",
    "\n",
    "# transform support variables, change the scaler if you wish!\n",
    "x_scaler = MinMaxScaler()\n",
    "x_scaler.fit(X_train)\n",
    "\n",
    "# transform target variable separately to avoid data leakage\n",
    "y_scaler = QuantileTransformer(output_distribution='normal', random_state=42)\n",
    "y_scaler.fit(y_train.values.reshape(-1, 1))\n",
    "\n",
    "# transform/scale all our support variables in train, validation and test datasets\n",
    "X_train = x_scaler.transform(X_train)\n",
    "X_val = x_scaler.transform(X_val)\n",
    "X_test = x_scaler.transform(X_test)\n",
    "\n",
    "# transform/scale all our target variables in train, validation and test datasets\n",
    "# scalers and transformers often require data in NumPy -format\n",
    "# this is why we need the values.reshape(-1, 1)\n",
    "y_train = y_scaler.transform(y_train.values.reshape(-1, 1))\n",
    "y_val = y_scaler.transform(y_val.values.reshape(-1, 1))\n",
    "y_test  = y_scaler.transform(y_test.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a neural network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tuomas.valtanen\\DL2025lecturenotes2\\DeepLearning2025\\.venv\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:142: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">204</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │            \u001b[38;5;34m48\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │           \u001b[38;5;34m312\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m204\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m13\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">977</span> (3.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m977\u001b[0m (3.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">953</span> (3.72 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m953\u001b[0m (3.72 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> (96.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m24\u001b[0m (96.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create neural network\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# save the amount of support variables into a helper variable\n",
    "# so we don't have to update the input_shape all the time\n",
    "variable_amount = len(X.columns)\n",
    "\n",
    "# create callbacks and place them into a parameter list\n",
    "# NOTE! if you get PermissionError while training the model,\n",
    "# just try training it again\n",
    "mc = ModelCheckpoint('best_model_regression3_housing_scalers.keras', monitor='val_loss', mode='min', save_best_only=True)\n",
    "\n",
    "# if you use multiple callbacks (EarlyStoppin, ReduceLROnPlateau etc.)\n",
    "# add them to this same list\n",
    "callback_list = [mc]\n",
    "\n",
    "# Define Sequential neural network model\n",
    "# input shape has to match the amount of SUPPORT VARIABLES\n",
    "# in other words => amount of columns in X \n",
    "\n",
    "# Tip: have at least the same number of nodes as in the input shape\n",
    "\n",
    "# since we have 13 support variables this time => 16 nodes in first layer\n",
    "\n",
    "# output layer in regression is always 1 node without activation function\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.BatchNormalization(input_shape=(variable_amount,)),\n",
    "        layers.Dense(24, activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=0.105, l2=0.105)),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(16, activation=\"relu\"),\n",
    "        layers.Dense(12, activation=\"relu\"),\n",
    "        layers.Dense(1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# select the optimizer and loss function\n",
    "# you can try rmsprop also as optimizer, or stochastic gradient descent\n",
    "# model.compile(optimizer='adam', loss='mse')\n",
    "# model.compile(optimizer=keras.optimizers.RMSprop(0.00085), loss=keras.losses.Huber())\n",
    "# model.compile(optimizer=keras.optimizers.SGD(0.001), loss=\"mse\")\n",
    "# an example where we alter the learning rate of Adam-optimizer\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.00125), loss='mse')\n",
    "\n",
    "# common tips on how to change neural network structure if your metrics are not good:\n",
    "\n",
    "# make wider (or narrower) layers (for example, 64 or 128 nodes)\n",
    "# make a longer or shorter network (add or remove layers)\n",
    "# use Dropout -layers (e.g. layers.Dropout(0.1))\n",
    "\n",
    "# remember: there's no process or mathematical formula\n",
    "# in order to figure out the optimal neural network structure\n",
    "# it's mostly all about trial and error => EXPERIMENTATION!\n",
    "\n",
    "# remember to have enough \"decision-space\" for your data!\n",
    "# it's highly unlikely a dataset with 20 different variables is going\n",
    "# to work well with only 8 nodes in each layer etc.\n",
    "\n",
    "# print out the summary of your model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 10.6915 - val_loss: 8.6063\n",
      "Epoch 2/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.2483 - val_loss: 8.0734\n",
      "Epoch 3/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.4269 - val_loss: 7.6287\n",
      "Epoch 4/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 7.8184 - val_loss: 7.2297\n",
      "Epoch 5/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.3843 - val_loss: 6.8548\n",
      "Epoch 6/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.9815 - val_loss: 6.4960\n",
      "Epoch 7/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.5987 - val_loss: 6.1466\n",
      "Epoch 8/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.2268 - val_loss: 5.8188\n",
      "Epoch 9/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.8698 - val_loss: 5.4956\n",
      "Epoch 10/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.5442 - val_loss: 5.1881\n",
      "Epoch 11/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 5.2198 - val_loss: 4.8960\n",
      "Epoch 12/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.9492 - val_loss: 4.6173\n",
      "Epoch 13/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.6069 - val_loss: 4.3490\n",
      "Epoch 14/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4.3339 - val_loss: 4.0895\n",
      "Epoch 15/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.1270 - val_loss: 3.8456\n",
      "Epoch 16/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.8334 - val_loss: 3.6101\n",
      "Epoch 17/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.5744 - val_loss: 3.3785\n",
      "Epoch 18/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.3399 - val_loss: 3.1538\n",
      "Epoch 19/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.1369 - val_loss: 2.9493\n",
      "Epoch 20/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.9830 - val_loss: 2.7625\n",
      "Epoch 21/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.7560 - val_loss: 2.5844\n",
      "Epoch 22/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.5741 - val_loss: 2.4113\n",
      "Epoch 23/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.4475 - val_loss: 2.2535\n",
      "Epoch 24/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.2638 - val_loss: 2.0896\n",
      "Epoch 25/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.1356 - val_loss: 1.9479\n",
      "Epoch 26/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.9963 - val_loss: 1.8203\n",
      "Epoch 27/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.8372 - val_loss: 1.6938\n",
      "Epoch 28/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7209 - val_loss: 1.5651\n",
      "Epoch 29/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5791 - val_loss: 1.4275\n",
      "Epoch 30/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4836 - val_loss: 1.3022\n",
      "Epoch 31/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3870 - val_loss: 1.2128\n",
      "Epoch 32/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3127 - val_loss: 1.1352\n",
      "Epoch 33/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2649 - val_loss: 1.0482\n",
      "Epoch 34/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1903 - val_loss: 0.9718\n",
      "Epoch 35/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1187 - val_loss: 0.9070\n",
      "Epoch 36/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0579 - val_loss: 0.8681\n",
      "Epoch 37/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0302 - val_loss: 0.8192\n",
      "Epoch 38/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.9926 - val_loss: 0.7699\n",
      "Epoch 39/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9235 - val_loss: 0.7231\n",
      "Epoch 40/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8696 - val_loss: 0.6931\n",
      "Epoch 41/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8342 - val_loss: 0.6546\n",
      "Epoch 42/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.8232 - val_loss: 0.6162\n",
      "Epoch 43/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.7788 - val_loss: 0.6104\n",
      "Epoch 44/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.7705 - val_loss: 0.5694\n",
      "Epoch 45/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.7875 - val_loss: 0.5654\n",
      "Epoch 46/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.7737 - val_loss: 0.5694\n",
      "Epoch 47/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.7325 - val_loss: 0.5309\n",
      "Epoch 48/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.7738 - val_loss: 0.5387\n",
      "Epoch 49/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7583 - val_loss: 0.5267\n",
      "Epoch 50/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7157 - val_loss: 0.5118\n",
      "Epoch 51/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.7176 - val_loss: 0.5356\n",
      "Epoch 52/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7266 - val_loss: 0.5171\n",
      "Epoch 53/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.7190 - val_loss: 0.5120\n",
      "Epoch 54/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.7248 - val_loss: 0.5225\n",
      "Epoch 55/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6976 - val_loss: 0.5054\n",
      "Epoch 56/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.7063 - val_loss: 0.5039\n",
      "Epoch 57/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7046 - val_loss: 0.4963\n",
      "Epoch 58/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6864 - val_loss: 0.4982\n",
      "Epoch 59/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6839 - val_loss: 0.4874\n",
      "Epoch 60/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6538 - val_loss: 0.5108\n",
      "Epoch 61/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6752 - val_loss: 0.4930\n",
      "Epoch 62/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6379 - val_loss: 0.4754\n",
      "Epoch 63/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6322 - val_loss: 0.4776\n",
      "Epoch 64/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6622 - val_loss: 0.5026\n",
      "Epoch 65/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6577 - val_loss: 0.4835\n",
      "Epoch 66/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6707 - val_loss: 0.4760\n",
      "Epoch 67/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6774 - val_loss: 0.4799\n",
      "Epoch 68/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6522 - val_loss: 0.4826\n",
      "Epoch 69/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6626 - val_loss: 0.4694\n",
      "Epoch 70/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6294 - val_loss: 0.4878\n",
      "Epoch 71/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6606 - val_loss: 0.4621\n",
      "Epoch 72/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6582 - val_loss: 0.4869\n",
      "Epoch 73/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.6522 - val_loss: 0.4782\n",
      "Epoch 74/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6045 - val_loss: 0.4823\n",
      "Epoch 75/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6458 - val_loss: 0.4556\n",
      "Epoch 76/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6300 - val_loss: 0.4759\n",
      "Epoch 77/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.6268 - val_loss: 0.4560\n",
      "Epoch 78/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6651 - val_loss: 0.4688\n",
      "Epoch 79/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6242 - val_loss: 0.4533\n",
      "Epoch 80/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6434 - val_loss: 0.4608\n",
      "Epoch 81/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6461 - val_loss: 0.4723\n",
      "Epoch 82/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6397 - val_loss: 0.4606\n",
      "Epoch 83/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.6386 - val_loss: 0.4733\n",
      "Epoch 84/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6253 - val_loss: 0.4483\n",
      "Epoch 85/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6398 - val_loss: 0.4901\n",
      "Epoch 86/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6500 - val_loss: 0.4612\n",
      "Epoch 87/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.6286 - val_loss: 0.4519\n",
      "Epoch 88/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6508 - val_loss: 0.4594\n",
      "Epoch 89/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6271 - val_loss: 0.4714\n",
      "Epoch 90/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6441 - val_loss: 0.4666\n",
      "Epoch 91/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6162 - val_loss: 0.4529\n",
      "Epoch 92/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5962 - val_loss: 0.4522\n",
      "Epoch 93/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.6506 - val_loss: 0.4650\n",
      "Epoch 94/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6223 - val_loss: 0.4732\n",
      "Epoch 95/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5963 - val_loss: 0.4629\n",
      "Epoch 96/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5894 - val_loss: 0.4428\n",
      "Epoch 97/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6006 - val_loss: 0.4753\n",
      "Epoch 98/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6100 - val_loss: 0.4866\n",
      "Epoch 99/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6347 - val_loss: 0.4676\n",
      "Epoch 100/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6268 - val_loss: 0.4627\n",
      "Epoch 101/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6045 - val_loss: 0.4527\n",
      "Epoch 102/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.6198 - val_loss: 0.4747\n",
      "Epoch 103/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6053 - val_loss: 0.4593\n",
      "Epoch 104/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6114 - val_loss: 0.4648\n",
      "Epoch 105/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6355 - val_loss: 0.4693\n",
      "Epoch 106/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6244 - val_loss: 0.4750\n",
      "Epoch 107/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.6059 - val_loss: 0.4886\n",
      "Epoch 108/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6044 - val_loss: 0.4498\n",
      "Epoch 109/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.6256 - val_loss: 0.4518\n",
      "Epoch 110/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.6010 - val_loss: 0.4551\n",
      "Epoch 111/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5928 - val_loss: 0.4455\n",
      "Epoch 112/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6306 - val_loss: 0.4630\n",
      "Epoch 113/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6169 - val_loss: 0.4497\n",
      "Epoch 114/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6048 - val_loss: 0.4311\n",
      "Epoch 115/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6214 - val_loss: 0.4709\n",
      "Epoch 116/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6478 - val_loss: 0.4547\n",
      "Epoch 117/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6195 - val_loss: 0.4560\n",
      "Epoch 118/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6055 - val_loss: 0.4667\n",
      "Epoch 119/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5806 - val_loss: 0.4336\n",
      "Epoch 120/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5913 - val_loss: 0.4683\n",
      "Epoch 121/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5939 - val_loss: 0.4510\n",
      "Epoch 122/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5592 - val_loss: 0.4519\n",
      "Epoch 123/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.6117 - val_loss: 0.4557\n",
      "Epoch 124/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5656 - val_loss: 0.4529\n",
      "Epoch 125/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5893 - val_loss: 0.4665\n",
      "Epoch 126/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5697 - val_loss: 0.4448\n",
      "Epoch 127/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6089 - val_loss: 0.4631\n",
      "Epoch 128/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5815 - val_loss: 0.4454\n",
      "Epoch 129/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6168 - val_loss: 0.4352\n",
      "Epoch 130/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5984 - val_loss: 0.4366\n",
      "Epoch 131/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5801 - val_loss: 0.4462\n",
      "Epoch 132/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5852 - val_loss: 0.4399\n",
      "Epoch 133/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5836 - val_loss: 0.4345\n",
      "Epoch 134/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5704 - val_loss: 0.4567\n",
      "Epoch 135/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5790 - val_loss: 0.4446\n",
      "Epoch 136/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6114 - val_loss: 0.4612\n",
      "Epoch 137/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5947 - val_loss: 0.4536\n",
      "Epoch 138/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5855 - val_loss: 0.4599\n",
      "Epoch 139/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5883 - val_loss: 0.4732\n",
      "Epoch 140/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5695 - val_loss: 0.4758\n",
      "Epoch 141/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5900 - val_loss: 0.4676\n",
      "Epoch 142/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6210 - val_loss: 0.4562\n",
      "Epoch 143/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6110 - val_loss: 0.4864\n",
      "Epoch 144/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5971 - val_loss: 0.4638\n",
      "Epoch 145/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.6098 - val_loss: 0.4738\n",
      "Epoch 146/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6098 - val_loss: 0.4662\n",
      "Epoch 147/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5915 - val_loss: 0.4901\n",
      "Epoch 148/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.6112 - val_loss: 0.4440\n",
      "Epoch 149/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5878 - val_loss: 0.4829\n",
      "Epoch 150/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5458 - val_loss: 0.4597\n",
      "Epoch 151/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5883 - val_loss: 0.4742\n",
      "Epoch 152/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5569 - val_loss: 0.4580\n",
      "Epoch 153/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5959 - val_loss: 0.4536\n",
      "Epoch 154/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5563 - val_loss: 0.4900\n",
      "Epoch 155/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5820 - val_loss: 0.4490\n",
      "Epoch 156/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5877 - val_loss: 0.4563\n",
      "Epoch 157/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5828 - val_loss: 0.4403\n",
      "Epoch 158/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5560 - val_loss: 0.4675\n",
      "Epoch 159/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5835 - val_loss: 0.4471\n",
      "Epoch 160/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5708 - val_loss: 0.4756\n",
      "Epoch 161/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6047 - val_loss: 0.4595\n",
      "Epoch 162/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5961 - val_loss: 0.4451\n",
      "Epoch 163/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6139 - val_loss: 0.4483\n",
      "Epoch 164/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5741 - val_loss: 0.4472\n",
      "Epoch 165/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5639 - val_loss: 0.4471\n",
      "Epoch 166/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5950 - val_loss: 0.4642\n",
      "Epoch 167/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5748 - val_loss: 0.4385\n",
      "Epoch 168/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5656 - val_loss: 0.4649\n",
      "Epoch 169/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5754 - val_loss: 0.4422\n",
      "Epoch 170/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5482 - val_loss: 0.4644\n",
      "Epoch 171/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6000 - val_loss: 0.4809\n",
      "Epoch 172/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5495 - val_loss: 0.4520\n",
      "Epoch 173/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5422 - val_loss: 0.4754\n",
      "Epoch 174/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5815 - val_loss: 0.4366\n",
      "Epoch 175/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5848 - val_loss: 0.4413\n",
      "Epoch 176/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5495 - val_loss: 0.4484\n",
      "Epoch 177/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5547 - val_loss: 0.4481\n",
      "Epoch 178/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5428 - val_loss: 0.4815\n",
      "Epoch 179/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5819 - val_loss: 0.4781\n",
      "Epoch 180/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5501 - val_loss: 0.4510\n",
      "Epoch 181/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5658 - val_loss: 0.4937\n",
      "Epoch 182/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5648 - val_loss: 0.4630\n",
      "Epoch 183/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5945 - val_loss: 0.4810\n",
      "Epoch 184/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5959 - val_loss: 0.4628\n",
      "Epoch 185/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5668 - val_loss: 0.4657\n",
      "Epoch 186/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5499 - val_loss: 0.4600\n",
      "Epoch 187/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5668 - val_loss: 0.4551\n",
      "Epoch 188/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5443 - val_loss: 0.4650\n",
      "Epoch 189/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5389 - val_loss: 0.4842\n",
      "Epoch 190/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5903 - val_loss: 0.4977\n",
      "Epoch 191/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5672 - val_loss: 0.4706\n",
      "Epoch 192/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6049 - val_loss: 0.4998\n",
      "Epoch 193/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6098 - val_loss: 0.5018\n",
      "Epoch 194/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5762 - val_loss: 0.5202\n",
      "Epoch 195/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5721 - val_loss: 0.4913\n",
      "Epoch 196/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5922 - val_loss: 0.4753\n",
      "Epoch 197/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5386 - val_loss: 0.4931\n",
      "Epoch 198/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5679 - val_loss: 0.4922\n",
      "Epoch 199/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5772 - val_loss: 0.4966\n",
      "Epoch 200/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5816 - val_loss: 0.5132\n",
      "Epoch 201/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5736 - val_loss: 0.4898\n",
      "Epoch 202/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5890 - val_loss: 0.4781\n",
      "Epoch 203/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5623 - val_loss: 0.4809\n",
      "Epoch 204/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.6104 - val_loss: 0.4707\n",
      "Epoch 205/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5426 - val_loss: 0.4868\n",
      "Epoch 206/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5884 - val_loss: 0.4493\n",
      "Epoch 207/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5446 - val_loss: 0.5277\n",
      "Epoch 208/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5714 - val_loss: 0.4457\n",
      "Epoch 209/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5888 - val_loss: 0.4733\n",
      "Epoch 210/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5527 - val_loss: 0.4776\n",
      "Epoch 211/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5471 - val_loss: 0.4671\n",
      "Epoch 212/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.5632 - val_loss: 0.4938\n",
      "Epoch 213/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.5531 - val_loss: 0.4771\n",
      "Epoch 214/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5896 - val_loss: 0.4537\n",
      "Epoch 215/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5462 - val_loss: 0.4840\n",
      "Epoch 216/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5715 - val_loss: 0.4913\n",
      "Epoch 217/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5660 - val_loss: 0.4544\n",
      "Epoch 218/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5427 - val_loss: 0.5134\n",
      "Epoch 219/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5751 - val_loss: 0.5032\n",
      "Epoch 220/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5698 - val_loss: 0.4967\n",
      "Epoch 221/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5394 - val_loss: 0.5530\n",
      "Epoch 222/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5970 - val_loss: 0.4604\n",
      "Epoch 223/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5744 - val_loss: 0.4988\n",
      "Epoch 224/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5744 - val_loss: 0.4838\n",
      "Epoch 225/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6242 - val_loss: 0.4665\n",
      "Epoch 226/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5665 - val_loss: 0.4565\n",
      "Epoch 227/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5559 - val_loss: 0.4766\n",
      "Epoch 228/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5552 - val_loss: 0.4921\n",
      "Epoch 229/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5577 - val_loss: 0.4902\n",
      "Epoch 230/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5566 - val_loss: 0.4844\n",
      "Epoch 231/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5685 - val_loss: 0.4909\n",
      "Epoch 232/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5625 - val_loss: 0.4935\n",
      "Epoch 233/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5580 - val_loss: 0.5091\n",
      "Epoch 234/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5570 - val_loss: 0.5043\n",
      "Epoch 235/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5481 - val_loss: 0.4948\n",
      "Epoch 236/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5679 - val_loss: 0.4807\n",
      "Epoch 237/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5543 - val_loss: 0.4837\n",
      "Epoch 238/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5463 - val_loss: 0.4784\n",
      "Epoch 239/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5664 - val_loss: 0.4637\n",
      "Epoch 240/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5800 - val_loss: 0.5045\n",
      "Epoch 241/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5962 - val_loss: 0.4924\n",
      "Epoch 242/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6012 - val_loss: 0.4781\n",
      "Epoch 243/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5736 - val_loss: 0.4865\n",
      "Epoch 244/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5304 - val_loss: 0.4817\n",
      "Epoch 245/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.5491 - val_loss: 0.4865\n",
      "Epoch 246/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5840 - val_loss: 0.4669\n",
      "Epoch 247/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5557 - val_loss: 0.4919\n",
      "Epoch 248/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5665 - val_loss: 0.4864\n",
      "Epoch 249/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5522 - val_loss: 0.4966\n",
      "Epoch 250/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.5862 - val_loss: 0.4775\n",
      "Epoch 251/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5662 - val_loss: 0.4856\n",
      "Epoch 252/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5437 - val_loss: 0.4794\n",
      "Epoch 253/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5888 - val_loss: 0.4772\n",
      "Epoch 254/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5695 - val_loss: 0.5179\n",
      "Epoch 255/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.5138 - val_loss: 0.5301\n",
      "Epoch 256/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5441 - val_loss: 0.5254\n",
      "Epoch 257/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5714 - val_loss: 0.5538\n",
      "Epoch 258/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6121 - val_loss: 0.5268\n",
      "Epoch 259/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5425 - val_loss: 0.5063\n",
      "Epoch 260/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5125 - val_loss: 0.5030\n",
      "Epoch 261/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5595 - val_loss: 0.4841\n",
      "Epoch 262/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5283 - val_loss: 0.5117\n",
      "Epoch 263/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5655 - val_loss: 0.5060\n",
      "Epoch 264/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5599 - val_loss: 0.5309\n",
      "Epoch 265/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5744 - val_loss: 0.5084\n",
      "Epoch 266/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5863 - val_loss: 0.5388\n",
      "Epoch 267/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5631 - val_loss: 0.5171\n",
      "Epoch 268/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5680 - val_loss: 0.5291\n",
      "Epoch 269/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5615 - val_loss: 0.4867\n",
      "Epoch 270/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.5614 - val_loss: 0.5144\n",
      "Epoch 271/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5568 - val_loss: 0.5085\n",
      "Epoch 272/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5767 - val_loss: 0.5045\n",
      "Epoch 273/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5502 - val_loss: 0.5263\n",
      "Epoch 274/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5774 - val_loss: 0.5184\n",
      "Epoch 275/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5828 - val_loss: 0.5471\n",
      "Epoch 276/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5424 - val_loss: 0.5156\n",
      "Epoch 277/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.5708 - val_loss: 0.5072\n",
      "Epoch 278/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.5936 - val_loss: 0.4875\n",
      "Epoch 279/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.5608 - val_loss: 0.5031\n",
      "Epoch 280/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.5494 - val_loss: 0.5130\n",
      "Epoch 281/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5559 - val_loss: 0.4642\n",
      "Epoch 282/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5430 - val_loss: 0.5101\n",
      "Epoch 283/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5774 - val_loss: 0.5367\n",
      "Epoch 284/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5766 - val_loss: 0.4995\n",
      "Epoch 285/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.5762 - val_loss: 0.5303\n",
      "Epoch 286/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5601 - val_loss: 0.4978\n",
      "Epoch 287/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5261 - val_loss: 0.5036\n",
      "Epoch 288/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5202 - val_loss: 0.5340\n",
      "Epoch 289/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5318 - val_loss: 0.5107\n",
      "Epoch 290/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5452 - val_loss: 0.5209\n",
      "Epoch 291/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5406 - val_loss: 0.5093\n",
      "Epoch 292/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5292 - val_loss: 0.5064\n",
      "Epoch 293/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5965 - val_loss: 0.5232\n",
      "Epoch 294/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5534 - val_loss: 0.5116\n",
      "Epoch 295/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5658 - val_loss: 0.5287\n",
      "Epoch 296/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5629 - val_loss: 0.5380\n",
      "Epoch 297/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5580 - val_loss: 0.4706\n",
      "Epoch 298/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5694 - val_loss: 0.5509\n",
      "Epoch 299/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5660 - val_loss: 0.4856\n",
      "Epoch 300/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5464 - val_loss: 0.5102\n",
      "Epoch 301/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6056 - val_loss: 0.4891\n",
      "Epoch 302/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5526 - val_loss: 0.5448\n",
      "Epoch 303/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5309 - val_loss: 0.5179\n",
      "Epoch 304/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5273 - val_loss: 0.5139\n",
      "Epoch 305/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5687 - val_loss: 0.5129\n",
      "Epoch 306/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5406 - val_loss: 0.5186\n",
      "Epoch 307/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5554 - val_loss: 0.5244\n",
      "Epoch 308/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5815 - val_loss: 0.4882\n",
      "Epoch 309/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5453 - val_loss: 0.4766\n",
      "Epoch 310/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6062 - val_loss: 0.4846\n",
      "Epoch 311/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5710 - val_loss: 0.4999\n",
      "Epoch 312/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5456 - val_loss: 0.5175\n",
      "Epoch 313/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5441 - val_loss: 0.5369\n",
      "Epoch 314/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5556 - val_loss: 0.5110\n",
      "Epoch 315/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5625 - val_loss: 0.5277\n",
      "Epoch 316/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5001 - val_loss: 0.5044\n",
      "Epoch 317/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5768 - val_loss: 0.5386\n",
      "Epoch 318/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5454 - val_loss: 0.5411\n",
      "Epoch 319/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5438 - val_loss: 0.4985\n",
      "Epoch 320/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5484 - val_loss: 0.5108\n",
      "Epoch 321/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5742 - val_loss: 0.4905\n",
      "Epoch 322/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5297 - val_loss: 0.5226\n",
      "Epoch 323/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5407 - val_loss: 0.5202\n",
      "Epoch 324/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5054 - val_loss: 0.5300\n",
      "Epoch 325/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5616 - val_loss: 0.5229\n",
      "Epoch 326/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5613 - val_loss: 0.5040\n",
      "Epoch 327/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5907 - val_loss: 0.5467\n",
      "Epoch 328/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5832 - val_loss: 0.5269\n",
      "Epoch 329/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5700 - val_loss: 0.5239\n",
      "Epoch 330/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5609 - val_loss: 0.5448\n",
      "Epoch 331/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5279 - val_loss: 0.5202\n",
      "Epoch 332/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5236 - val_loss: 0.5475\n",
      "Epoch 333/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5676 - val_loss: 0.5538\n",
      "Epoch 334/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5073 - val_loss: 0.5336\n",
      "Epoch 335/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5750 - val_loss: 0.5083\n",
      "Epoch 336/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5252 - val_loss: 0.5501\n",
      "Epoch 337/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5402 - val_loss: 0.5128\n",
      "Epoch 338/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5882 - val_loss: 0.5409\n",
      "Epoch 339/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5312 - val_loss: 0.4889\n",
      "Epoch 340/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5527 - val_loss: 0.4955\n",
      "Epoch 341/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5769 - val_loss: 0.5180\n",
      "Epoch 342/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5552 - val_loss: 0.5158\n",
      "Epoch 343/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5501 - val_loss: 0.5338\n",
      "Epoch 344/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5515 - val_loss: 0.4996\n",
      "Epoch 345/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5962 - val_loss: 0.5193\n",
      "Epoch 346/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5503 - val_loss: 0.5292\n",
      "Epoch 347/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5671 - val_loss: 0.5104\n",
      "Epoch 348/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5621 - val_loss: 0.5373\n",
      "Epoch 349/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5430 - val_loss: 0.5030\n",
      "Epoch 350/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5426 - val_loss: 0.5285\n",
      "Epoch 351/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5456 - val_loss: 0.5340\n",
      "Epoch 352/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.6087 - val_loss: 0.5028\n",
      "Epoch 353/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5422 - val_loss: 0.4781\n",
      "Epoch 354/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5798 - val_loss: 0.5119\n",
      "Epoch 355/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5501 - val_loss: 0.5203\n",
      "Epoch 356/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5222 - val_loss: 0.5331\n",
      "Epoch 357/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5465 - val_loss: 0.5044\n",
      "Epoch 358/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5593 - val_loss: 0.5319\n",
      "Epoch 359/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5628 - val_loss: 0.5040\n",
      "Epoch 360/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5698 - val_loss: 0.5228\n",
      "Epoch 361/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5249 - val_loss: 0.5324\n",
      "Epoch 362/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5451 - val_loss: 0.4969\n",
      "Epoch 363/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5463 - val_loss: 0.5392\n",
      "Epoch 364/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5492 - val_loss: 0.5309\n",
      "Epoch 365/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5654 - val_loss: 0.5693\n",
      "Epoch 366/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5705 - val_loss: 0.5111\n",
      "Epoch 367/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5608 - val_loss: 0.5325\n",
      "Epoch 368/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5636 - val_loss: 0.5176\n",
      "Epoch 369/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6051 - val_loss: 0.4823\n",
      "Epoch 370/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5387 - val_loss: 0.5296\n",
      "Epoch 371/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5439 - val_loss: 0.5066\n",
      "Epoch 372/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5675 - val_loss: 0.5096\n",
      "Epoch 373/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5175 - val_loss: 0.4952\n",
      "Epoch 374/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5453 - val_loss: 0.5359\n",
      "Epoch 375/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5396 - val_loss: 0.4907\n",
      "Epoch 376/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5266 - val_loss: 0.5070\n",
      "Epoch 377/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5471 - val_loss: 0.5141\n",
      "Epoch 378/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5405 - val_loss: 0.4899\n",
      "Epoch 379/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5302 - val_loss: 0.5126\n",
      "Epoch 380/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5145 - val_loss: 0.5048\n",
      "Epoch 381/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4827 - val_loss: 0.5250\n",
      "Epoch 382/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5360 - val_loss: 0.5283\n",
      "Epoch 383/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5574 - val_loss: 0.5339\n",
      "Epoch 384/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5634 - val_loss: 0.4899\n",
      "Epoch 385/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5233 - val_loss: 0.5204\n",
      "Epoch 386/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5619 - val_loss: 0.5192\n",
      "Epoch 387/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5771 - val_loss: 0.5221\n",
      "Epoch 388/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5338 - val_loss: 0.4786\n",
      "Epoch 389/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.6086 - val_loss: 0.4874\n",
      "Epoch 390/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5559 - val_loss: 0.5219\n",
      "Epoch 391/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5273 - val_loss: 0.5057\n",
      "Epoch 392/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5328 - val_loss: 0.4844\n",
      "Epoch 393/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5454 - val_loss: 0.5248\n",
      "Epoch 394/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5198 - val_loss: 0.4934\n",
      "Epoch 395/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5782 - val_loss: 0.5107\n",
      "Epoch 396/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5359 - val_loss: 0.5160\n",
      "Epoch 397/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5434 - val_loss: 0.5316\n",
      "Epoch 398/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5170 - val_loss: 0.5175\n",
      "Epoch 399/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5251 - val_loss: 0.5150\n",
      "Epoch 400/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5284 - val_loss: 0.5359\n",
      "Epoch 401/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5257 - val_loss: 0.5642\n",
      "Epoch 402/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5222 - val_loss: 0.5377\n",
      "Epoch 403/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5075 - val_loss: 0.5390\n",
      "Epoch 404/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5460 - val_loss: 0.5499\n",
      "Epoch 405/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5477 - val_loss: 0.5138\n",
      "Epoch 406/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5545 - val_loss: 0.5191\n",
      "Epoch 407/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5128 - val_loss: 0.5329\n",
      "Epoch 408/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5513 - val_loss: 0.5385\n",
      "Epoch 409/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5435 - val_loss: 0.5330\n",
      "Epoch 410/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5501 - val_loss: 0.5019\n",
      "Epoch 411/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5782 - val_loss: 0.5273\n",
      "Epoch 412/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5702 - val_loss: 0.4939\n",
      "Epoch 413/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5203 - val_loss: 0.5078\n",
      "Epoch 414/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5315 - val_loss: 0.5382\n",
      "Epoch 415/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5400 - val_loss: 0.5136\n",
      "Epoch 416/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5493 - val_loss: 0.5313\n",
      "Epoch 417/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5201 - val_loss: 0.4932\n",
      "Epoch 418/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5581 - val_loss: 0.5155\n",
      "Epoch 419/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5623 - val_loss: 0.5298\n",
      "Epoch 420/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5125 - val_loss: 0.5154\n",
      "Epoch 421/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5233 - val_loss: 0.5512\n",
      "Epoch 422/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5320 - val_loss: 0.5036\n",
      "Epoch 423/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5009 - val_loss: 0.5009\n",
      "Epoch 424/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5369 - val_loss: 0.4558\n",
      "Epoch 425/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5578 - val_loss: 0.4879\n",
      "Epoch 426/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5453 - val_loss: 0.5746\n",
      "Epoch 427/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5513 - val_loss: 0.4975\n",
      "Epoch 428/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5134 - val_loss: 0.4812\n",
      "Epoch 429/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5625 - val_loss: 0.5357\n",
      "Epoch 430/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5611 - val_loss: 0.5314\n",
      "Epoch 431/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5165 - val_loss: 0.5029\n",
      "Epoch 432/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5187 - val_loss: 0.5282\n",
      "Epoch 433/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5598 - val_loss: 0.5406\n",
      "Epoch 434/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5496 - val_loss: 0.4746\n",
      "Epoch 435/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5609 - val_loss: 0.5098\n",
      "Epoch 436/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5580 - val_loss: 0.5261\n",
      "Epoch 437/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5190 - val_loss: 0.5476\n",
      "Epoch 438/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6104 - val_loss: 0.5056\n",
      "Epoch 439/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5252 - val_loss: 0.5412\n",
      "Epoch 440/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5191 - val_loss: 0.5325\n",
      "Epoch 441/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5716 - val_loss: 0.5624\n",
      "Epoch 442/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5604 - val_loss: 0.5012\n",
      "Epoch 443/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5116 - val_loss: 0.5372\n",
      "Epoch 444/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5220 - val_loss: 0.5284\n",
      "Epoch 445/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5239 - val_loss: 0.4931\n",
      "Epoch 446/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5120 - val_loss: 0.4983\n",
      "Epoch 447/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4873 - val_loss: 0.5004\n",
      "Epoch 448/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5289 - val_loss: 0.4837\n",
      "Epoch 449/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5206 - val_loss: 0.5098\n",
      "Epoch 450/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4993 - val_loss: 0.5469\n",
      "Epoch 451/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5156 - val_loss: 0.5551\n",
      "Epoch 452/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5235 - val_loss: 0.5738\n",
      "Epoch 453/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5156 - val_loss: 0.5586\n",
      "Epoch 454/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5151 - val_loss: 0.5146\n",
      "Epoch 455/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4617 - val_loss: 0.5361\n",
      "Epoch 456/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4821 - val_loss: 0.5400\n",
      "Epoch 457/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5197 - val_loss: 0.5279\n",
      "Epoch 458/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5283 - val_loss: 0.4908\n",
      "Epoch 459/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5318 - val_loss: 0.5392\n",
      "Epoch 460/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5141 - val_loss: 0.5388\n",
      "Epoch 461/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5145 - val_loss: 0.5525\n",
      "Epoch 462/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5081 - val_loss: 0.5755\n",
      "Epoch 463/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5051 - val_loss: 0.5283\n",
      "Epoch 464/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5077 - val_loss: 0.5285\n",
      "Epoch 465/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4881 - val_loss: 0.5710\n",
      "Epoch 466/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5060 - val_loss: 0.5416\n",
      "Epoch 467/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5357 - val_loss: 0.5673\n",
      "Epoch 468/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4863 - val_loss: 0.5864\n",
      "Epoch 469/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5281 - val_loss: 0.5392\n",
      "Epoch 470/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5288 - val_loss: 0.5466\n",
      "Epoch 471/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5292 - val_loss: 0.4843\n",
      "Epoch 472/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5412 - val_loss: 0.5636\n",
      "Epoch 473/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5204 - val_loss: 0.5299\n",
      "Epoch 474/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5697 - val_loss: 0.5442\n",
      "Epoch 475/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4836 - val_loss: 0.5403\n",
      "Epoch 476/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4779 - val_loss: 0.6115\n",
      "Epoch 477/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5593 - val_loss: 0.4944\n",
      "Epoch 478/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5227 - val_loss: 0.5987\n",
      "Epoch 479/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5519 - val_loss: 0.5141\n",
      "Epoch 480/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5558 - val_loss: 0.5280\n",
      "Epoch 481/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5341 - val_loss: 0.5470\n",
      "Epoch 482/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5619 - val_loss: 0.5368\n",
      "Epoch 483/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5533 - val_loss: 0.5449\n",
      "Epoch 484/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5253 - val_loss: 0.5223\n",
      "Epoch 485/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4738 - val_loss: 0.6097\n",
      "Epoch 486/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5387 - val_loss: 0.5834\n",
      "Epoch 487/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5342 - val_loss: 0.5826\n",
      "Epoch 488/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5023 - val_loss: 0.5668\n",
      "Epoch 489/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5113 - val_loss: 0.6040\n",
      "Epoch 490/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5717 - val_loss: 0.5796\n",
      "Epoch 491/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4775 - val_loss: 0.6179\n",
      "Epoch 492/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5179 - val_loss: 0.5648\n",
      "Epoch 493/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4864 - val_loss: 0.5252\n",
      "Epoch 494/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4926 - val_loss: 0.5351\n",
      "Epoch 495/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5800 - val_loss: 0.6224\n",
      "Epoch 496/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4905 - val_loss: 0.5874\n",
      "Epoch 497/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4901 - val_loss: 0.5738\n",
      "Epoch 498/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5367 - val_loss: 0.5799\n",
      "Epoch 499/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5072 - val_loss: 0.5706\n",
      "Epoch 500/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4943 - val_loss: 0.5641\n",
      "Epoch 501/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4955 - val_loss: 0.5710\n",
      "Epoch 502/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5100 - val_loss: 0.5640\n",
      "Epoch 503/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5333 - val_loss: 0.5756\n",
      "Epoch 504/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5162 - val_loss: 0.5430\n",
      "Epoch 505/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5083 - val_loss: 0.5844\n",
      "Epoch 506/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5895 - val_loss: 0.5205\n",
      "Epoch 507/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5350 - val_loss: 0.5913\n",
      "Epoch 508/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5613 - val_loss: 0.5292\n",
      "Epoch 509/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5881 - val_loss: 0.5584\n",
      "Epoch 510/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5940 - val_loss: 0.5561\n",
      "Epoch 511/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5298 - val_loss: 0.5276\n",
      "Epoch 512/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5024 - val_loss: 0.5419\n",
      "Epoch 513/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5634 - val_loss: 0.5117\n",
      "Epoch 514/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5070 - val_loss: 0.5385\n",
      "Epoch 515/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5241 - val_loss: 0.5646\n",
      "Epoch 516/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5316 - val_loss: 0.6107\n",
      "Epoch 517/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4506 - val_loss: 0.5229\n",
      "Epoch 518/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5256 - val_loss: 0.5077\n",
      "Epoch 519/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5720 - val_loss: 0.5363\n",
      "Epoch 520/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5426 - val_loss: 0.5634\n",
      "Epoch 521/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5410 - val_loss: 0.5551\n",
      "Epoch 522/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5448 - val_loss: 0.5915\n",
      "Epoch 523/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5229 - val_loss: 0.6211\n",
      "Epoch 524/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5452 - val_loss: 0.5242\n",
      "Epoch 525/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5076 - val_loss: 0.5706\n",
      "Epoch 526/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4879 - val_loss: 0.5481\n",
      "Epoch 527/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5042 - val_loss: 0.5475\n",
      "Epoch 528/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5296 - val_loss: 0.5466\n",
      "Epoch 529/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4653 - val_loss: 0.5257\n",
      "Epoch 530/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4875 - val_loss: 0.5612\n",
      "Epoch 531/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5043 - val_loss: 0.5423\n",
      "Epoch 532/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4561 - val_loss: 0.5784\n",
      "Epoch 533/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6106 - val_loss: 0.5299\n",
      "Epoch 534/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5290 - val_loss: 0.6184\n",
      "Epoch 535/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5133 - val_loss: 0.5667\n",
      "Epoch 536/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4946 - val_loss: 0.5731\n",
      "Epoch 537/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5076 - val_loss: 0.6028\n",
      "Epoch 538/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5375 - val_loss: 0.5661\n",
      "Epoch 539/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5551 - val_loss: 0.5687\n",
      "Epoch 540/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4838 - val_loss: 0.5137\n",
      "Epoch 541/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5136 - val_loss: 0.5475\n",
      "Epoch 542/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5224 - val_loss: 0.6062\n",
      "Epoch 543/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5328 - val_loss: 0.5734\n",
      "Epoch 544/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5510 - val_loss: 0.5816\n",
      "Epoch 545/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5590 - val_loss: 0.5932\n",
      "Epoch 546/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6303 - val_loss: 0.5185\n",
      "Epoch 547/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5123 - val_loss: 0.4927\n",
      "Epoch 548/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5274 - val_loss: 0.5208\n",
      "Epoch 549/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5054 - val_loss: 0.4974\n",
      "Epoch 550/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5594 - val_loss: 0.5722\n",
      "Epoch 551/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5052 - val_loss: 0.5575\n",
      "Epoch 552/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4787 - val_loss: 0.5687\n",
      "Epoch 553/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5153 - val_loss: 0.5200\n",
      "Epoch 554/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5614 - val_loss: 0.5751\n",
      "Epoch 555/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4964 - val_loss: 0.5592\n",
      "Epoch 556/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4571 - val_loss: 0.5779\n",
      "Epoch 557/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4932 - val_loss: 0.5668\n",
      "Epoch 558/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5187 - val_loss: 0.5796\n",
      "Epoch 559/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4963 - val_loss: 0.5384\n",
      "Epoch 560/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5048 - val_loss: 0.5417\n",
      "Epoch 561/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5211 - val_loss: 0.5369\n",
      "Epoch 562/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5373 - val_loss: 0.5232\n",
      "Epoch 563/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4697 - val_loss: 0.5461\n",
      "Epoch 564/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5156 - val_loss: 0.5335\n",
      "Epoch 565/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4809 - val_loss: 0.5055\n",
      "Epoch 566/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5005 - val_loss: 0.5349\n",
      "Epoch 567/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4874 - val_loss: 0.5384\n",
      "Epoch 568/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5126 - val_loss: 0.5649\n",
      "Epoch 569/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5540 - val_loss: 0.6040\n",
      "Epoch 570/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5971 - val_loss: 0.5704\n",
      "Epoch 571/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5237 - val_loss: 0.5758\n",
      "Epoch 572/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5289 - val_loss: 0.5525\n",
      "Epoch 573/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5525 - val_loss: 0.5735\n",
      "Epoch 574/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5654 - val_loss: 0.5459\n",
      "Epoch 575/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5386 - val_loss: 0.5770\n",
      "Epoch 576/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5597 - val_loss: 0.4864\n",
      "Epoch 577/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5005 - val_loss: 0.5563\n",
      "Epoch 578/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5188 - val_loss: 0.5473\n",
      "Epoch 579/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5458 - val_loss: 0.5761\n",
      "Epoch 580/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5027 - val_loss: 0.5273\n",
      "Epoch 581/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5345 - val_loss: 0.6019\n",
      "Epoch 582/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4956 - val_loss: 0.5861\n",
      "Epoch 583/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4970 - val_loss: 0.5627\n",
      "Epoch 584/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5775 - val_loss: 0.5664\n",
      "Epoch 585/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5228 - val_loss: 0.6061\n",
      "Epoch 586/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5020 - val_loss: 0.5240\n",
      "Epoch 587/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5050 - val_loss: 0.5474\n",
      "Epoch 588/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5812 - val_loss: 0.5608\n",
      "Epoch 589/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4958 - val_loss: 0.5510\n",
      "Epoch 590/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5160 - val_loss: 0.5575\n",
      "Epoch 591/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5647 - val_loss: 0.5123\n",
      "Epoch 592/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5161 - val_loss: 0.5199\n",
      "Epoch 593/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5193 - val_loss: 0.5633\n",
      "Epoch 594/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4680 - val_loss: 0.5577\n",
      "Epoch 595/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4937 - val_loss: 0.5594\n",
      "Epoch 596/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4980 - val_loss: 0.5350\n",
      "Epoch 597/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5428 - val_loss: 0.5582\n",
      "Epoch 598/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5641 - val_loss: 0.5636\n",
      "Epoch 599/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5374 - val_loss: 0.5928\n",
      "Epoch 600/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4882 - val_loss: 0.5757\n",
      "Epoch 601/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5339 - val_loss: 0.5263\n",
      "Epoch 602/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4884 - val_loss: 0.6020\n",
      "Epoch 603/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5064 - val_loss: 0.5655\n",
      "Epoch 604/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4811 - val_loss: 0.5322\n",
      "Epoch 605/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4648 - val_loss: 0.5748\n",
      "Epoch 606/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4514 - val_loss: 0.5562\n",
      "Epoch 607/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4650 - val_loss: 0.5510\n",
      "Epoch 608/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5128 - val_loss: 0.5649\n",
      "Epoch 609/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4995 - val_loss: 0.5791\n",
      "Epoch 610/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4906 - val_loss: 0.5240\n",
      "Epoch 611/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5484 - val_loss: 0.5590\n",
      "Epoch 612/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5851 - val_loss: 0.5744\n",
      "Epoch 613/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4764 - val_loss: 0.6247\n",
      "Epoch 614/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5631 - val_loss: 0.5582\n",
      "Epoch 615/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5629 - val_loss: 0.6193\n",
      "Epoch 616/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5552 - val_loss: 0.5685\n",
      "Epoch 617/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4744 - val_loss: 0.6177\n",
      "Epoch 618/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5118 - val_loss: 0.5804\n",
      "Epoch 619/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5008 - val_loss: 0.5974\n",
      "Epoch 620/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5133 - val_loss: 0.6012\n",
      "Epoch 621/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4643 - val_loss: 0.5986\n",
      "Epoch 622/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4687 - val_loss: 0.5926\n",
      "Epoch 623/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4945 - val_loss: 0.6170\n",
      "Epoch 624/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4828 - val_loss: 0.6089\n",
      "Epoch 625/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5024 - val_loss: 0.5844\n",
      "Epoch 626/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5479 - val_loss: 0.6205\n",
      "Epoch 627/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4918 - val_loss: 0.6366\n",
      "Epoch 628/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5400 - val_loss: 0.6016\n",
      "Epoch 629/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5514 - val_loss: 0.5821\n",
      "Epoch 630/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5240 - val_loss: 0.6523\n",
      "Epoch 631/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4960 - val_loss: 0.6237\n",
      "Epoch 632/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4672 - val_loss: 0.5872\n",
      "Epoch 633/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5115 - val_loss: 0.5898\n",
      "Epoch 634/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5671 - val_loss: 0.5679\n",
      "Epoch 635/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6076 - val_loss: 0.5312\n",
      "Epoch 636/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5204 - val_loss: 0.5991\n",
      "Epoch 637/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5207 - val_loss: 0.5326\n",
      "Epoch 638/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5077 - val_loss: 0.5991\n",
      "Epoch 639/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4981 - val_loss: 0.5434\n",
      "Epoch 640/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5721 - val_loss: 0.6538\n",
      "Epoch 641/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5433 - val_loss: 0.5510\n",
      "Epoch 642/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5147 - val_loss: 0.6317\n",
      "Epoch 643/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4929 - val_loss: 0.5659\n",
      "Epoch 644/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5826 - val_loss: 0.6350\n",
      "Epoch 645/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4997 - val_loss: 0.5764\n",
      "Epoch 646/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4811 - val_loss: 0.6063\n",
      "Epoch 647/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4660 - val_loss: 0.6411\n",
      "Epoch 648/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5313 - val_loss: 0.6304\n",
      "Epoch 649/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5463 - val_loss: 0.5736\n",
      "Epoch 650/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5461 - val_loss: 0.5883\n",
      "Epoch 651/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5489 - val_loss: 0.5870\n",
      "Epoch 652/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5212 - val_loss: 0.6086\n",
      "Epoch 653/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4937 - val_loss: 0.5950\n",
      "Epoch 654/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5065 - val_loss: 0.6228\n",
      "Epoch 655/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4834 - val_loss: 0.5554\n",
      "Epoch 656/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5028 - val_loss: 0.6196\n",
      "Epoch 657/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4425 - val_loss: 0.5731\n",
      "Epoch 658/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4536 - val_loss: 0.6118\n",
      "Epoch 659/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4739 - val_loss: 0.5664\n",
      "Epoch 660/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5594 - val_loss: 0.6463\n",
      "Epoch 661/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4802 - val_loss: 0.6361\n",
      "Epoch 662/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4783 - val_loss: 0.5777\n",
      "Epoch 663/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5186 - val_loss: 0.6236\n",
      "Epoch 664/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4801 - val_loss: 0.5427\n",
      "Epoch 665/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5040 - val_loss: 0.6200\n",
      "Epoch 666/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5709 - val_loss: 0.5990\n",
      "Epoch 667/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5345 - val_loss: 0.6040\n",
      "Epoch 668/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4960 - val_loss: 0.6022\n",
      "Epoch 669/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5019 - val_loss: 0.5820\n",
      "Epoch 670/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5365 - val_loss: 0.5836\n",
      "Epoch 671/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4818 - val_loss: 0.5880\n",
      "Epoch 672/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4636 - val_loss: 0.6147\n",
      "Epoch 673/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5535 - val_loss: 0.6118\n",
      "Epoch 674/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5572 - val_loss: 0.6129\n",
      "Epoch 675/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5590 - val_loss: 0.5541\n",
      "Epoch 676/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5428 - val_loss: 0.6227\n",
      "Epoch 677/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5739 - val_loss: 0.6095\n",
      "Epoch 678/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4952 - val_loss: 0.6723\n",
      "Epoch 679/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5592 - val_loss: 0.6105\n",
      "Epoch 680/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5011 - val_loss: 0.6249\n",
      "Epoch 681/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5577 - val_loss: 0.5697\n",
      "Epoch 682/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5724 - val_loss: 0.6797\n",
      "Epoch 683/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5492 - val_loss: 0.6226\n",
      "Epoch 684/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5451 - val_loss: 0.5967\n",
      "Epoch 685/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5454 - val_loss: 0.6091\n",
      "Epoch 686/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5155 - val_loss: 0.6003\n",
      "Epoch 687/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5666 - val_loss: 0.6383\n",
      "Epoch 688/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5255 - val_loss: 0.6055\n",
      "Epoch 689/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5111 - val_loss: 0.5941\n",
      "Epoch 690/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5044 - val_loss: 0.5961\n",
      "Epoch 691/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5346 - val_loss: 0.6294\n",
      "Epoch 692/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5628 - val_loss: 0.6031\n",
      "Epoch 693/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5467 - val_loss: 0.6501\n",
      "Epoch 694/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5719 - val_loss: 0.6095\n",
      "Epoch 695/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5263 - val_loss: 0.5730\n",
      "Epoch 696/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5188 - val_loss: 0.5407\n",
      "Epoch 697/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5297 - val_loss: 0.6221\n",
      "Epoch 698/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5575 - val_loss: 0.6087\n",
      "Epoch 699/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5396 - val_loss: 0.6080\n",
      "Epoch 700/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5141 - val_loss: 0.6159\n",
      "Epoch 701/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5336 - val_loss: 0.6224\n",
      "Epoch 702/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5178 - val_loss: 0.6342\n",
      "Epoch 703/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5472 - val_loss: 0.5901\n",
      "Epoch 704/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5625 - val_loss: 0.5860\n",
      "Epoch 705/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5712 - val_loss: 0.6013\n",
      "Epoch 706/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5024 - val_loss: 0.6064\n",
      "Epoch 707/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5470 - val_loss: 0.6054\n",
      "Epoch 708/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5444 - val_loss: 0.6067\n",
      "Epoch 709/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4867 - val_loss: 0.6366\n",
      "Epoch 710/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5286 - val_loss: 0.5874\n",
      "Epoch 711/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5002 - val_loss: 0.6916\n",
      "Epoch 712/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5573 - val_loss: 0.6010\n",
      "Epoch 713/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5272 - val_loss: 0.6126\n",
      "Epoch 714/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5461 - val_loss: 0.6451\n",
      "Epoch 715/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5017 - val_loss: 0.6185\n",
      "Epoch 716/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5173 - val_loss: 0.5972\n",
      "Epoch 717/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5190 - val_loss: 0.6551\n",
      "Epoch 718/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5617 - val_loss: 0.6066\n",
      "Epoch 719/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5223 - val_loss: 0.6667\n",
      "Epoch 720/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5646 - val_loss: 0.5834\n",
      "Epoch 721/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5438 - val_loss: 0.5746\n",
      "Epoch 722/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5450 - val_loss: 0.5544\n",
      "Epoch 723/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5380 - val_loss: 0.5835\n",
      "Epoch 724/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5290 - val_loss: 0.5690\n",
      "Epoch 725/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5209 - val_loss: 0.6161\n",
      "Epoch 726/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5291 - val_loss: 0.6312\n",
      "Epoch 727/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5184 - val_loss: 0.5744\n",
      "Epoch 728/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5128 - val_loss: 0.6333\n",
      "Epoch 729/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5428 - val_loss: 0.6386\n",
      "Epoch 730/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4963 - val_loss: 0.5875\n",
      "Epoch 731/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5398 - val_loss: 0.6283\n",
      "Epoch 732/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4924 - val_loss: 0.6158\n",
      "Epoch 733/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5123 - val_loss: 0.6785\n",
      "Epoch 734/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6159 - val_loss: 0.5991\n",
      "Epoch 735/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5585 - val_loss: 0.6184\n",
      "Epoch 736/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5111 - val_loss: 0.6038\n",
      "Epoch 737/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5186 - val_loss: 0.6478\n",
      "Epoch 738/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5177 - val_loss: 0.5659\n",
      "Epoch 739/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5197 - val_loss: 0.6076\n",
      "Epoch 740/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5243 - val_loss: 0.5841\n",
      "Epoch 741/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5265 - val_loss: 0.6200\n",
      "Epoch 742/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5296 - val_loss: 0.6094\n",
      "Epoch 743/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5443 - val_loss: 0.6162\n",
      "Epoch 744/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5209 - val_loss: 0.6170\n",
      "Epoch 745/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5185 - val_loss: 0.6563\n",
      "Epoch 746/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4834 - val_loss: 0.6386\n",
      "Epoch 747/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4991 - val_loss: 0.6337\n",
      "Epoch 748/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4768 - val_loss: 0.5930\n",
      "Epoch 749/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5164 - val_loss: 0.5838\n",
      "Epoch 750/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4960 - val_loss: 0.6505\n",
      "Epoch 751/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5074 - val_loss: 0.6657\n",
      "Epoch 752/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5032 - val_loss: 0.6561\n",
      "Epoch 753/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5085 - val_loss: 0.6027\n",
      "Epoch 754/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4951 - val_loss: 0.5859\n",
      "Epoch 755/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5019 - val_loss: 0.6158\n",
      "Epoch 756/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5268 - val_loss: 0.6359\n",
      "Epoch 757/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5509 - val_loss: 0.6691\n",
      "Epoch 758/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5290 - val_loss: 0.5857\n",
      "Epoch 759/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5216 - val_loss: 0.5933\n",
      "Epoch 760/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5665 - val_loss: 0.6680\n",
      "Epoch 761/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5207 - val_loss: 0.6348\n",
      "Epoch 762/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5290 - val_loss: 0.6324\n",
      "Epoch 763/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4954 - val_loss: 0.6247\n",
      "Epoch 764/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5346 - val_loss: 0.6407\n",
      "Epoch 765/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5063 - val_loss: 0.5735\n",
      "Epoch 766/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5212 - val_loss: 0.5673\n",
      "Epoch 767/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5118 - val_loss: 0.5709\n",
      "Epoch 768/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5614 - val_loss: 0.6157\n",
      "Epoch 769/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5180 - val_loss: 0.6136\n",
      "Epoch 770/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5571 - val_loss: 0.5568\n",
      "Epoch 771/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5441 - val_loss: 0.5963\n",
      "Epoch 772/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4930 - val_loss: 0.6282\n",
      "Epoch 773/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5626 - val_loss: 0.6743\n",
      "Epoch 774/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5223 - val_loss: 0.5799\n",
      "Epoch 775/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5646 - val_loss: 0.5493\n",
      "Epoch 776/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5124 - val_loss: 0.6083\n",
      "Epoch 777/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5446 - val_loss: 0.5939\n",
      "Epoch 778/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5680 - val_loss: 0.6251\n",
      "Epoch 779/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5204 - val_loss: 0.5615\n",
      "Epoch 780/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4725 - val_loss: 0.6055\n",
      "Epoch 781/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5187 - val_loss: 0.6264\n",
      "Epoch 782/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5546 - val_loss: 0.6018\n",
      "Epoch 783/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4614 - val_loss: 0.6211\n",
      "Epoch 784/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5337 - val_loss: 0.6029\n",
      "Epoch 785/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5568 - val_loss: 0.5494\n",
      "Epoch 786/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5190 - val_loss: 0.5339\n",
      "Epoch 787/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5308 - val_loss: 0.5248\n",
      "Epoch 788/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5164 - val_loss: 0.5956\n",
      "Epoch 789/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5655 - val_loss: 0.5348\n",
      "Epoch 790/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5114 - val_loss: 0.5606\n",
      "Epoch 791/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5558 - val_loss: 0.5454\n",
      "Epoch 792/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5165 - val_loss: 0.5786\n",
      "Epoch 793/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5261 - val_loss: 0.6106\n",
      "Epoch 794/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4990 - val_loss: 0.5589\n",
      "Epoch 795/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5203 - val_loss: 0.5194\n",
      "Epoch 796/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5044 - val_loss: 0.6505\n",
      "Epoch 797/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5226 - val_loss: 0.6039\n",
      "Epoch 798/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5237 - val_loss: 0.6523\n",
      "Epoch 799/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5236 - val_loss: 0.5519\n",
      "Epoch 800/800\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5081 - val_loss: 0.6581\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1c0a55af6b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train/fit neural network with validation data\n",
    "# see the instructions on the train/test -split above on how to split the data correctly\n",
    "model.fit(x=X_train, y=y_train, epochs=800, validation_data=(X_val, y_val), callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance and error metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's use pandas for this (easy code)\n",
    "# try to look if the model is actually training \n",
    "# => the error is going downwards\n",
    "# if using validation data, you get two lines\n",
    "# in this case, see if the lines follow a similar trend \n",
    "# (they don't always overlap with complex data, the trend is more important)\n",
    "loss_df = pd.DataFrame(model.history.history)\n",
    "loss_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload the best version of the model from history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('best_model_regression3_housing_scalers.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data evaluation:\n",
      "0.34819379448890686\n",
      "\n",
      "Train data evaluation:\n",
      "0.5689365267753601\n"
     ]
    }
   ],
   "source": [
    "# compare the final model loss/evaluation values\n",
    "print(\"Test data evaluation:\")\n",
    "print(model.evaluate(X_test, y_test, verbose=0))\n",
    "print(\"\\nTrain data evaluation:\")\n",
    "print(model.evaluate(X_train, y_train, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This part is modified so, that the original \"test_predictions\" is left in the original format (instead of replacing it with pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test True Y</th>\n",
       "      <th>Model Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.561886</td>\n",
       "      <td>0.462997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.098989</td>\n",
       "      <td>0.137675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.839063</td>\n",
       "      <td>-0.778505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.194380</td>\n",
       "      <td>0.941646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.313250</td>\n",
       "      <td>1.342133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.321364</td>\n",
       "      <td>-1.454918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.795155</td>\n",
       "      <td>-1.272151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.109524</td>\n",
       "      <td>-0.531795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.705841</td>\n",
       "      <td>-0.045912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.111637</td>\n",
       "      <td>-0.015867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Test True Y  Model Predictions\n",
       "0     0.561886           0.462997\n",
       "1    -0.098989           0.137675\n",
       "2    -0.839063          -0.778505\n",
       "3     0.194380           0.941646\n",
       "4     2.313250           1.342133\n",
       "5    -1.321364          -1.454918\n",
       "6    -0.795155          -1.272151\n",
       "7    -1.109524          -0.531795\n",
       "8     0.705841          -0.045912\n",
       "9    -0.111637          -0.015867"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get test predictions\n",
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "# reshape the data for easier comparison table\n",
    "test_predictions_table = pd.Series(test_predictions.reshape(len(y_test),))\n",
    "pred_df = pd.DataFrame(np.asarray(y_test), columns=['Test True Y'])\n",
    "pred_df = pd.concat([pred_df, test_predictions_table], axis=1)\n",
    "pred_df.columns = ['Test True Y', 'Model Predictions']\n",
    "\n",
    "# print the comparison table - true values vs. model predicted values\n",
    "# we can nicely see here how far off our model is in some cases\n",
    "pred_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Test True Y', ylabel='Model Predictions'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# these values follow a linear diagonal line = good predictions\n",
    "# we basically compare the predicted values \n",
    "# to true test values and see the differences\n",
    "sns.scatterplot(x='Test True Y', y='Model Predictions', data=pred_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The metrics have been modified as well so that we have a reference point in actual units (dollars) to see how much the scaled metrics are off currently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE! The metrics are also scaled since we used scalers/transformations after the train/test/validation split!\n",
    "\n",
    "In order to reverse the scaled value, we re-use the scalers to perform INVERSE TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE\n",
      "0.38 units (% in decimals if using MinMaxScaler, kind of)\n",
      "\n",
      "MSE\n",
      "0.25 units^2\n",
      "\n",
      "RMSE:\n",
      "0.5 units\n",
      "\n",
      "RMSE (original units):\n",
      "823410.29 $\n",
      "\n",
      "R-squared:\n",
      "0.71\n",
      "\n",
      "Explained variance score:\n",
      "0.72\n"
     ]
    }
   ],
   "source": [
    "# MAE - Mean average error\n",
    "print(\"MAE\")\n",
    "print(round(metrics.mean_absolute_error(y_test, test_predictions_table), 2), \"units (% in decimals if using MinMaxScaler, kind of)\")\n",
    "\n",
    "# MSE - Mean square error\n",
    "print(\"\\nMSE\")\n",
    "print(round(metrics.mean_squared_error(y_test, test_predictions), 2), \"units^2\")\n",
    "\n",
    "# RMSE - Root mean square error\n",
    "print('\\nRMSE:')\n",
    "print(round(np.sqrt(metrics.mean_squared_error(y_test, test_predictions_table)), 2), \"units\")\n",
    "\n",
    "# we need the original values in order to calculate RMSE with actual units\n",
    "# inverse transform is once again very useful here\n",
    "# reshape(-1, 1) is used to convert the data to required format for inverse_transform\n",
    "y_test_orig = y_scaler.inverse_transform(np.array(y_test).reshape(-1, 1))\n",
    "test_predictions_orig = y_scaler.inverse_transform(test_predictions.reshape(-1, 1))\n",
    "\n",
    "# Now compute RMSE in original units\n",
    "rmse = np.sqrt(metrics.mean_squared_error(y_test_orig, test_predictions_orig))\n",
    "print(f'\\nRMSE (original units):\\n{rmse:.2f} $')\n",
    "\n",
    "# R-squared. 0 = the model descibes the dataset poorly\n",
    "# 1 = model describes the datas'et perfectly\n",
    "print('\\nR-squared:')\n",
    "print(round(metrics.r2_score(y_test, test_predictions), 2))\n",
    "\n",
    "# Explained Variance Score => 0 = the model descibes the dataset poorly\n",
    "# 1 = model describes the dataset perfectly\n",
    "# high variance score = model is a good fit for the data \n",
    "# low variance score = model is not a good fit for the data\n",
    "# the higher the score, the model is more able to explain the variation in the data\n",
    "# if score is low, we might need more and better data\n",
    "print(\"\\nExplained variance score:\")\n",
    "print(round(metrics.explained_variance_score(y_test, test_predictions), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tuomas.valtanen\\AppData\\Local\\Temp\\ipykernel_14196\\3124900743.py:5: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot((y_test - test_predictions))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# if the prediction distribution are far from normal distribution\n",
    "# then the model is not probably good enough\n",
    "# distplot is deprecating in future pandas-version\n",
    "# unfortunately, there's no exact alternative to do this plot at the moment\n",
    "sns.distplot((y_test - test_predictions))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying the model in practice with new imaginary house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11410000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10850000</td>\n",
       "      <td>7500</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9870000</td>\n",
       "      <td>8100</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  area  bedrooms  bathrooms  stories  mainroad  guestroom  \\\n",
       "4  11410000  7420         4          1        2         1          1   \n",
       "5  10850000  7500         3          3        1         1          0   \n",
       "8   9870000  8100         4          1        2         1          1   \n",
       "\n",
       "   basement  hotwaterheating  airconditioning  parking  prefarea  furnished  \n",
       "4         1                0                1        2         0          1  \n",
       "5         1                0                1        2         1          1  \n",
       "8         1                0                1        2         1          1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just to see what kind of values are usually in the dataset\n",
    "# so we can test with the tester_row\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: fix the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try with some new imaginary data\n",
    "# this example uses the student performance index score dataset\n",
    "# modify this as needed regarding your own dataset\n",
    "tester_row = {\n",
    "    'area': 7420, \n",
    "    'bedrooms': 4, \n",
    "    'bathrooms': 2, \n",
    "    'stories': 3, \n",
    "    'mainroad': 1,\n",
    "    'guestroom': 0, \n",
    "    'basement': 0, \n",
    "    'hotwaterheating': 0, \n",
    "    'airconditioning': 1,\n",
    "    'parking': 2,\n",
    "    'prefarea': 1,\n",
    "    'furnished': 1,\n",
    "}\n",
    "\n",
    "# convert to pandas-format\n",
    "tester_row = pd.DataFrame([tester_row])\n",
    "\n",
    "# scale our tester row with original x-scaler (support variable scaler)\n",
    "tester_row = x_scaler.transform(tester_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "Predicted price with given apartment parameters:\n",
      "8095444.5 $\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "# make a prediction and save the scaled result back into the tester_row\n",
    "result = model.predict(tester_row)\n",
    "\n",
    "# inverse the scaling back to original unit (dollars in this case)\n",
    "result = y_scaler.inverse_transform(result.reshape(-1, 1))[0]\n",
    "\n",
    "print()\n",
    "print(f\"Predicted price with given apartment parameters:\")\n",
    "print(f\"{round(float(result[0]), 2)} $\")\n",
    "print(\"----------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
