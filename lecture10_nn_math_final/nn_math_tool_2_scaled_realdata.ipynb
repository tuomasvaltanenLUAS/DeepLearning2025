{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network, experimentation tool, version 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDIT: the scaling is now done separately for independent support variables and the target. The model works a bit better now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# activation functions\n",
    "# ReLu is very simple, it filters out all negative values\n",
    "# this is a powerful activation function in reality\n",
    "def activation_ReLu(number):\n",
    "    if number > 0:\n",
    "        return number\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# we also need a derivated version of ReLu\n",
    "# otherwise same as original, but instead of original value, return 1 instead\n",
    "def activation_ReLu_partial_derivative(number):\n",
    "    if number > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lock down the randomness in order to get same results everytime\n",
    "# you can change or disable this if you want\n",
    "np.random.seed(123)\n",
    "\n",
    "def generate_train_data():\n",
    "    result = []\n",
    "\n",
    "    # create 100 numbers\n",
    "    for x in range(100):\n",
    "        n1 = np.random.randint(0, 5)\n",
    "        n2 = np.random.randint(3, 7)\n",
    "\n",
    "        # formula for the target variable: x1 ^^ 2 + x2 + (random integer between 0-5)\n",
    "        # the only point of this is to have some kind of logic in the data\n",
    "        n3 = n1 ** 2 + n2 + np.random.randint(0, 5)\n",
    "        n3 = int(n3)\n",
    "\n",
    "        result.append([n1, n2, n3])\n",
    "\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767</th>\n",
       "      <td>47</td>\n",
       "      <td>45.320</td>\n",
       "      <td>8569.86180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2768</th>\n",
       "      <td>21</td>\n",
       "      <td>34.600</td>\n",
       "      <td>2020.17700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2769</th>\n",
       "      <td>19</td>\n",
       "      <td>26.030</td>\n",
       "      <td>16450.89470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2770</th>\n",
       "      <td>23</td>\n",
       "      <td>18.715</td>\n",
       "      <td>21595.38229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2771</th>\n",
       "      <td>54</td>\n",
       "      <td>31.600</td>\n",
       "      <td>9850.43200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2772 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     bmi      charges\n",
       "0      19  27.900  16884.92400\n",
       "1      18  33.770   1725.55230\n",
       "2      28  33.000   4449.46200\n",
       "3      33  22.705  21984.47061\n",
       "4      32  28.880   3866.85520\n",
       "...   ...     ...          ...\n",
       "2767   47  45.320   8569.86180\n",
       "2768   21  34.600   2020.17700\n",
       "2769   19  26.030  16450.89470\n",
       "2770   23  18.715  21595.38229\n",
       "2771   54  31.600   9850.43200\n",
       "\n",
       "[2772 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use generated training data from our helper function\n",
    "# data = generate_train_data()\n",
    "# df = pd.DataFrame(data, columns=[\"x1\", \"x2\", \"y\"])\n",
    "df = pd.read_csv(\"medical_insurance.csv\")\n",
    "df = df[[\"age\", \"bmi\", \"charges\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 0.0497451243686288\n",
      "Epoch: 2, loss: 0.033573965414824075\n",
      "Epoch: 3, loss: 0.03355457692731701\n",
      "Epoch: 4, loss: 0.033553319228997625\n",
      "Epoch: 5, loss: 0.03355190225829146\n",
      "Epoch: 6, loss: 0.0335502260272176\n",
      "Epoch: 7, loss: 0.0335484998870231\n",
      "Epoch: 8, loss: 0.03354678617488219\n",
      "Epoch: 9, loss: 0.03354509946666493\n",
      "Epoch: 10, loss: 0.033543442250419594\n",
      "Epoch: 11, loss: 0.03354181415732012\n",
      "Epoch: 12, loss: 0.03354021420770331\n",
      "Epoch: 13, loss: 0.03353864134552851\n",
      "Epoch: 14, loss: 0.033537094560809125\n",
      "Epoch: 15, loss: 0.03353557291356248\n",
      "Epoch: 16, loss: 0.033534075534522687\n",
      "Epoch: 17, loss: 0.03353260162063645\n",
      "Epoch: 18, loss: 0.03353115042964563\n",
      "Epoch: 19, loss: 0.03352972127477254\n",
      "Epoch: 20, loss: 0.0335283135197383\n",
      "Epoch: 21, loss: 0.03352692657415607\n",
      "Epoch: 22, loss: 0.03352555988929014\n",
      "Epoch: 23, loss: 0.0335242129541669\n",
      "Epoch: 24, loss: 0.03352288529201547\n",
      "Epoch: 25, loss: 0.0335215764570184\n",
      "Epoch: 26, loss: 0.03352028603135116\n",
      "Epoch: 27, loss: 0.03351901362249066\n",
      "Epoch: 28, loss: 0.03351775886077225\n",
      "Epoch: 29, loss: 0.03351652139717762\n",
      "Epoch: 30, loss: 0.0335153009013341\n",
      "Epoch: 31, loss: 0.03351409705970867\n",
      "Epoch: 32, loss: 0.03351290957398065\n",
      "Epoch: 33, loss: 0.03351173815957689\n",
      "Epoch: 34, loss: 0.0335105825443568\n",
      "Epoch: 35, loss: 0.033509442467430685\n",
      "Epoch: 36, loss: 0.033508366523512335\n",
      "Epoch: 37, loss: 0.0335073153246681\n",
      "Epoch: 38, loss: 0.03350627830881679\n",
      "Epoch: 39, loss: 0.03350525676041462\n",
      "Epoch: 40, loss: 0.033504250796304084\n",
      "Epoch: 41, loss: 0.03350326026441605\n",
      "Epoch: 42, loss: 0.03350228495389826\n",
      "Epoch: 43, loss: 0.03350132464393342\n",
      "Epoch: 44, loss: 0.03350042222131474\n",
      "Epoch: 45, loss: 0.03349912404687129\n",
      "Epoch: 46, loss: 0.03349785432582955\n",
      "Epoch: 47, loss: 0.033496606883368744\n",
      "Epoch: 48, loss: 0.03349538007178344\n",
      "Epoch: 49, loss: 0.03349421373558354\n",
      "Epoch: 50, loss: 0.03349309720528122\n",
      "Epoch: 51, loss: 0.033492056565385786\n",
      "Epoch: 52, loss: 0.03349105901585458\n",
      "Epoch: 53, loss: 0.0334900819263413\n",
      "Epoch: 54, loss: 0.03348913987289771\n",
      "Epoch: 55, loss: 0.03348824290784226\n",
      "Epoch: 56, loss: 0.03348735886841921\n",
      "Epoch: 57, loss: 0.03348649490027894\n",
      "Epoch: 58, loss: 0.033485810548064286\n",
      "Epoch: 59, loss: 0.03348516704649317\n",
      "Epoch: 60, loss: 0.03348453351612966\n",
      "Epoch: 61, loss: 0.03348391554352686\n",
      "Epoch: 62, loss: 0.03348331415286729\n",
      "Epoch: 63, loss: 0.03348272926046593\n",
      "Epoch: 64, loss: 0.03348216053373989\n",
      "Epoch: 65, loss: 0.03348160758885177\n",
      "Epoch: 66, loss: 0.033481070036094324\n",
      "Epoch: 67, loss: 0.03348058423966325\n",
      "Epoch: 68, loss: 0.033480184636186947\n",
      "Epoch: 69, loss: 0.03347982350358047\n",
      "Epoch: 70, loss: 0.033479526749898424\n",
      "Epoch: 71, loss: 0.033479243969331\n",
      "Epoch: 72, loss: 0.033479004450796435\n",
      "Epoch: 73, loss: 0.033478807795407475\n",
      "Epoch: 74, loss: 0.033478613363391474\n",
      "Epoch: 75, loss: 0.03347842334323618\n",
      "Epoch: 76, loss: 0.03347823810229113\n",
      "Epoch: 77, loss: 0.033478058666432386\n",
      "Epoch: 78, loss: 0.0334779139367246\n",
      "Epoch: 79, loss: 0.03347776974176139\n",
      "Epoch: 80, loss: 0.03347764791540593\n",
      "Epoch: 81, loss: 0.03347754810864743\n",
      "Epoch: 82, loss: 0.03347743191807465\n",
      "Epoch: 83, loss: 0.03347731541268917\n",
      "Epoch: 84, loss: 0.03347719976198698\n",
      "Epoch: 85, loss: 0.03347708520859392\n",
      "Epoch: 86, loss: 0.03347697177958479\n",
      "Epoch: 87, loss: 0.03347685945295268\n",
      "Epoch: 88, loss: 0.03347674819654062\n",
      "Epoch: 89, loss: 0.03347663797710182\n",
      "Epoch: 90, loss: 0.03347652876235947\n",
      "Epoch: 91, loss: 0.03347642052142421\n",
      "Epoch: 92, loss: 0.03347622786141433\n",
      "Epoch: 93, loss: 0.033476168818577325\n",
      "Epoch: 94, loss: 0.033476502476498346\n",
      "Epoch: 95, loss: 0.033477196452623044\n",
      "Epoch: 96, loss: 0.03347824736787177\n",
      "Epoch: 97, loss: 0.03348094187719958\n",
      "Epoch: 98, loss: 0.03348496230802427\n",
      "Epoch: 99, loss: 0.03349063525897461\n",
      "Epoch: 100, loss: 0.03349731766934037\n",
      "Epoch: 101, loss: 0.03350538882098921\n",
      "Epoch: 102, loss: 0.033514176707311445\n",
      "Epoch: 103, loss: 0.03352601095233124\n",
      "Epoch: 104, loss: 0.033541453907338814\n",
      "Epoch: 105, loss: 0.03355963666835978\n",
      "Epoch: 106, loss: 0.03357856354183022\n",
      "Epoch: 107, loss: 0.033594366188928616\n",
      "Epoch: 108, loss: 0.03360782689797507\n",
      "Epoch: 109, loss: 0.033618286451630036\n",
      "Epoch: 110, loss: 0.033627989545440655\n",
      "Epoch: 111, loss: 0.03363599648047229\n",
      "Epoch: 112, loss: 0.03364164579461686\n",
      "Epoch: 113, loss: 0.03364382358871579\n",
      "Epoch: 114, loss: 0.03364318536066348\n",
      "Epoch: 115, loss: 0.033636911746052336\n",
      "Epoch: 116, loss: 0.03362804564856961\n",
      "Epoch: 117, loss: 0.03362242606910101\n",
      "Epoch: 118, loss: 0.03362124072586312\n",
      "Epoch: 119, loss: 0.03362190465623652\n",
      "Epoch: 120, loss: 0.033626323990890085\n",
      "Epoch: 121, loss: 0.033634907803721546\n",
      "Epoch: 122, loss: 0.03364739147793042\n",
      "Epoch: 123, loss: 0.03365497878279063\n",
      "Epoch: 124, loss: 0.03366612803112678\n",
      "Epoch: 125, loss: 0.033688860504367854\n",
      "Epoch: 126, loss: 0.033723775464203604\n",
      "Epoch: 127, loss: 0.033766130526447946\n",
      "Epoch: 128, loss: 0.03380696037643407\n",
      "Epoch: 129, loss: 0.03382094727589965\n",
      "Epoch: 130, loss: 0.0338165332267779\n",
      "Epoch: 131, loss: 0.03379222463398269\n",
      "Epoch: 132, loss: 0.03376313051560527\n",
      "Epoch: 133, loss: 0.03374009773746588\n",
      "Epoch: 134, loss: 0.033714279204453364\n",
      "Epoch: 135, loss: 0.033695714442695764\n",
      "Epoch: 136, loss: 0.033682162253400545\n",
      "Epoch: 137, loss: 0.03367232157214933\n",
      "Epoch: 138, loss: 0.03366103109878885\n",
      "Epoch: 139, loss: 0.03365309187597006\n",
      "Epoch: 140, loss: 0.03365050407673157\n",
      "Epoch: 141, loss: 0.03364710645979394\n",
      "Epoch: 142, loss: 0.03364157671888559\n",
      "Epoch: 143, loss: 0.03363643030803068\n",
      "Epoch: 144, loss: 0.03363260556185058\n",
      "Epoch: 145, loss: 0.03362881713266107\n",
      "Epoch: 146, loss: 0.033625642231666385\n",
      "Epoch: 147, loss: 0.03362314645926346\n",
      "Epoch: 148, loss: 0.03362043708530956\n",
      "Epoch: 149, loss: 0.03361772334215145\n",
      "Epoch: 150, loss: 0.033615168014054085\n",
      "Epoch: 151, loss: 0.03361218057070858\n",
      "Epoch: 152, loss: 0.033609418453697616\n",
      "Epoch: 153, loss: 0.03360819179651672\n",
      "Epoch: 154, loss: 0.03360725234360302\n",
      "Epoch: 155, loss: 0.03360634890031913\n",
      "Epoch: 156, loss: 0.03360290239192568\n",
      "Epoch: 157, loss: 0.03359970638225377\n",
      "Epoch: 158, loss: 0.03359737445400329\n",
      "Epoch: 159, loss: 0.033595270705387204\n",
      "Epoch: 160, loss: 0.033593104173734956\n",
      "Epoch: 161, loss: 0.03359095007370857\n",
      "Epoch: 162, loss: 0.03358900497351046\n",
      "Epoch: 163, loss: 0.033586950423026424\n",
      "Epoch: 164, loss: 0.03358497427220544\n",
      "Epoch: 165, loss: 0.03358305997261394\n",
      "Epoch: 166, loss: 0.033581118860088535\n",
      "Epoch: 167, loss: 0.0335793803736887\n",
      "Epoch: 168, loss: 0.033577485586983265\n",
      "Epoch: 169, loss: 0.03357581853972623\n",
      "Epoch: 170, loss: 0.033574005082444236\n",
      "Epoch: 171, loss: 0.03357241410468025\n",
      "Epoch: 172, loss: 0.0335706801790308\n",
      "Epoch: 173, loss: 0.03356916284696552\n",
      "Epoch: 174, loss: 0.033567505539941235\n",
      "Epoch: 175, loss: 0.03356605923787014\n",
      "Epoch: 176, loss: 0.03356447563817303\n",
      "Epoch: 177, loss: 0.03356309776113494\n",
      "Epoch: 178, loss: 0.03356158499975645\n",
      "Epoch: 179, loss: 0.03356027297002481\n",
      "Epoch: 180, loss: 0.033558868904806284\n",
      "Epoch: 181, loss: 0.03355754273851815\n",
      "Epoch: 182, loss: 0.033556234296188404\n",
      "Epoch: 183, loss: 0.03355493316008354\n",
      "Epoch: 184, loss: 0.03355377163098108\n",
      "Epoch: 185, loss: 0.033552525013779644\n",
      "Epoch: 186, loss: 0.033551350142084914\n",
      "Epoch: 187, loss: 0.033550190891792564\n",
      "Epoch: 188, loss: 0.03354907455138415\n",
      "Epoch: 189, loss: 0.03354798112144387\n",
      "Epoch: 190, loss: 0.033546903348398535\n",
      "Epoch: 191, loss: 0.03354586717337496\n",
      "Epoch: 192, loss: 0.0335448515113949\n",
      "Epoch: 193, loss: 0.033543850529299674\n",
      "Epoch: 194, loss: 0.0335428892065047\n",
      "Epoch: 195, loss: 0.03354191106669738\n",
      "Epoch: 196, loss: 0.03354105422179181\n",
      "Epoch: 197, loss: 0.03354012279745556\n",
      "Epoch: 198, loss: 0.033539249798341615\n",
      "Epoch: 199, loss: 0.03353836208822145\n",
      "Epoch: 200, loss: 0.033537589331971915\n",
      "Epoch: 201, loss: 0.03353674486641193\n",
      "Epoch: 202, loss: 0.033535955572661265\n",
      "Epoch: 203, loss: 0.03353518362865948\n",
      "Epoch: 204, loss: 0.03353439756275099\n",
      "Epoch: 205, loss: 0.033533718795680886\n",
      "Epoch: 206, loss: 0.03353297160583158\n",
      "Epoch: 207, loss: 0.03353227579128483\n",
      "Epoch: 208, loss: 0.033531595096785285\n",
      "Epoch: 209, loss: 0.0335309307559262\n",
      "Epoch: 210, loss: 0.033530282731150086\n",
      "Epoch: 211, loss: 0.033529650689514474\n",
      "Epoch: 212, loss: 0.03352900306718316\n",
      "Epoch: 213, loss: 0.03352845144735911\n",
      "Epoch: 214, loss: 0.03352783605861111\n",
      "Epoch: 215, loss: 0.03352726660142887\n",
      "Epoch: 216, loss: 0.033526709148417835\n",
      "Epoch: 217, loss: 0.033526164773748764\n",
      "Epoch: 218, loss: 0.03352563347662369\n",
      "Epoch: 219, loss: 0.03352511499493481\n",
      "Epoch: 220, loss: 0.03352460900496716\n",
      "Epoch: 221, loss: 0.033524115171528326\n",
      "Epoch: 222, loss: 0.033523633161142194\n",
      "Epoch: 223, loss: 0.033523162645850806\n",
      "Epoch: 224, loss: 0.03352270330446745\n",
      "Epoch: 225, loss: 0.03352225482304381\n",
      "Epoch: 226, loss: 0.033521816895038\n",
      "Epoch: 227, loss: 0.0335213892213425\n",
      "Epoch: 228, loss: 0.03352097151023498\n",
      "Epoch: 229, loss: 0.0335205634772831\n",
      "Epoch: 230, loss: 0.03352016484522055\n",
      "Epoch: 231, loss: 0.03351977534381048\n",
      "Epoch: 232, loss: 0.03351939470969617\n",
      "Epoch: 233, loss: 0.03351902268625116\n",
      "Epoch: 234, loss: 0.03351865902342655\n",
      "Epoch: 235, loss: 0.03351830347760018\n",
      "Epoch: 236, loss: 0.03351795581142797\n",
      "Epoch: 237, loss: 0.03351761579369752\n",
      "Epoch: 238, loss: 0.033517283199185746\n",
      "Epoch: 239, loss: 0.03351695780851914\n",
      "Epoch: 240, loss: 0.03351663940803828\n",
      "Epoch: 241, loss: 0.033516327789664735\n",
      "Epoch: 242, loss: 0.03351607711222496\n",
      "Epoch: 243, loss: 0.03351571896791671\n",
      "Epoch: 244, loss: 0.03351542677253655\n",
      "Epoch: 245, loss: 0.03351519363596546\n",
      "Epoch: 246, loss: 0.0335148548556675\n",
      "Epoch: 247, loss: 0.03351463515124176\n",
      "Epoch: 248, loss: 0.03351430580027937\n",
      "Epoch: 249, loss: 0.033514096191772924\n",
      "Epoch: 250, loss: 0.033513778316115544\n",
      "Epoch: 251, loss: 0.03351357831947097\n",
      "Epoch: 252, loss: 0.03351327111672186\n",
      "Epoch: 253, loss: 0.033513080242265215\n",
      "Epoch: 254, loss: 0.03351278296235848\n",
      "Epoch: 255, loss: 0.03351259778250302\n",
      "Epoch: 256, loss: 0.03351236431072373\n",
      "Epoch: 257, loss: 0.033512081298192054\n",
      "Epoch: 258, loss: 0.03351190785620039\n",
      "Epoch: 259, loss: 0.03351168685047936\n",
      "Epoch: 260, loss: 0.0335114667270446\n",
      "Epoch: 261, loss: 0.03351120073468386\n",
      "Epoch: 262, loss: 0.03351104135356348\n",
      "Epoch: 263, loss: 0.03351083219297302\n",
      "Epoch: 264, loss: 0.03351062651517553\n",
      "Epoch: 265, loss: 0.03351042736200927\n",
      "Epoch: 266, loss: 0.03351022834263461\n",
      "Epoch: 267, loss: 0.03351003237332711\n",
      "Epoch: 268, loss: 0.03350983945843507\n",
      "Epoch: 269, loss: 0.03350964951351151\n",
      "Epoch: 270, loss: 0.0335094624411588\n",
      "Epoch: 271, loss: 0.03350927814273577\n",
      "Epoch: 272, loss: 0.0335090933172022\n",
      "Epoch: 273, loss: 0.03350891427442559\n",
      "Epoch: 274, loss: 0.03350878412087545\n",
      "Epoch: 275, loss: 0.033508560689053835\n",
      "Epoch: 276, loss: 0.033508389182358024\n",
      "Epoch: 277, loss: 0.033508216727979344\n",
      "Epoch: 278, loss: 0.033508095086377906\n",
      "Epoch: 279, loss: 0.033507881683411594\n",
      "Epoch: 280, loss: 0.03350771571465047\n",
      "Epoch: 281, loss: 0.033507599947403044\n",
      "Epoch: 282, loss: 0.03350738993788844\n",
      "Epoch: 283, loss: 0.03350727758842237\n",
      "Epoch: 284, loss: 0.03350707194183788\n",
      "Epoch: 285, loss: 0.03350696298459105\n",
      "Epoch: 286, loss: 0.033506761246380405\n",
      "Epoch: 287, loss: 0.03350665556409277\n",
      "Epoch: 288, loss: 0.033506500799244276\n",
      "Epoch: 289, loss: 0.03350630462902383\n",
      "Epoch: 290, loss: 0.03350620323266221\n",
      "Epoch: 291, loss: 0.03350605335204886\n",
      "Epoch: 292, loss: 0.0335059048255686\n",
      "Epoch: 293, loss: 0.03350575783857343\n",
      "Epoch: 294, loss: 0.03350557027748144\n",
      "Epoch: 295, loss: 0.03350547530680235\n",
      "Epoch: 296, loss: 0.033505332669601144\n",
      "Epoch: 297, loss: 0.03350519105618316\n",
      "Epoch: 298, loss: 0.03350505067847965\n",
      "Epoch: 299, loss: 0.03350491154742488\n",
      "Epoch: 300, loss: 0.03350477362570858\n"
     ]
    }
   ],
   "source": [
    "# initialize weights and biases\n",
    "# in Keras/TensorFlow/PyTorch etc. these are usually randomized in the beginning\n",
    "w1 = 1\n",
    "w2 = 0.5\n",
    "w3 = 1\n",
    "w4 = -0.5\n",
    "w5 = 1\n",
    "w6 = 1\n",
    "bias1 = 0.5\n",
    "bias2 = 0\n",
    "bias3 = 0.5\n",
    "\n",
    "# just for comparison after the training\n",
    "original_w1 = w1\n",
    "original_w2 = w2\n",
    "original_w3 = w3\n",
    "original_w4 = w4\n",
    "original_w5 = w5\n",
    "original_w6 = w6\n",
    "original_b1 = bias1\n",
    "original_b2 = bias2\n",
    "original_b3 = bias3\n",
    "\n",
    "# DataFrame values as a list\n",
    "# data = list(df.values)\n",
    "data = df.values\n",
    "\n",
    "# use min/max -scaling to make values in the range 0-1\n",
    "\n",
    "# independent support variables => indeces 0 and 1 (X)\n",
    "# target variable => index 2 (y)\n",
    "X = data[:, :2]\n",
    "y = data[:, 2:]\n",
    "\n",
    "# Scale X and y\n",
    "X_scaled = (X - np.min(X, axis=0)) / (np.max(X, axis=0) - np.min(X, axis=0))\n",
    "y_scaled = (y - np.min(y, axis=0)) / (np.max(y, axis=0) - np.min(y, axis=0))\n",
    "\n",
    "# combine back to original data format\n",
    "data = np.hstack((X_scaled, y_scaled))\n",
    "\n",
    "# learning rate\n",
    "LR = 0.005\n",
    "epochs = 300\n",
    "\n",
    "# let's initalize a list for loss visualizations\n",
    "loss_points = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # the previous version only measured the loss value\n",
    "    # of the last calculation done in the code (node 3)\n",
    "    # it's probably better to measure the average loss for each epoch\n",
    "    epoch_losses = []\n",
    "\n",
    "    for row in data:\n",
    "        # this is where we do Forward pass + backpropagation\n",
    "        input1 = row[0]\n",
    "        input2 = row[1]\n",
    "        true_value = row[2]\n",
    "\n",
    "        # NODE 1 OUTPUT\n",
    "        node_1_output = input1 * w1 + input2 * w3 + bias1\n",
    "        node_1_output = activation_ReLu(node_1_output)\n",
    "        node_1_output\n",
    "\n",
    "        # NODE 2 OUTPUT\n",
    "        node_2_output = input1 * w2 + input2 * w4 + bias2\n",
    "        node_2_output = activation_ReLu(node_2_output)\n",
    "        node_2_output\n",
    "\n",
    "        # NODE 3 OUTPUT\n",
    "        # we can just use Node 1 and 2 outputs, since they\n",
    "        # already contain the previous weights in their result\n",
    "        node_3_output = node_1_output * w5 + node_2_output * w6 + bias3\n",
    "        node_3_output = activation_ReLu(node_3_output)\n",
    "        node_3_output\n",
    "\n",
    "        # LOSS FUNCTION - we are going to use MSE -> mean squared error\n",
    "        # MSE formula for LOSS => (predicted_value - true_value) ^ 2\n",
    "        predicted_value = node_3_output\n",
    "        loss = (predicted_value - true_value) ** 2\n",
    "\n",
    "        # add current loss into epoch losses -list\n",
    "        epoch_losses.append(loss)\n",
    "        \n",
    "        # BACKPROPAGATION - LAST LAYER FIRST\n",
    "        # solving the partial derivative of the loss function with respect to w5\n",
    "        deriv_L_w5 = 2 * node_1_output * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        new_w5 = w5 - LR * deriv_L_w5\n",
    "\n",
    "        deriv_L_w6 = 2 * node_2_output * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        new_w6 = w6 - LR * deriv_L_w6\n",
    "\n",
    "        deriv_L_b3 = 2 * 1 * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        new_b3 = bias3 - LR * deriv_L_b3\n",
    "\n",
    "        # BACKPROPAGATION - THE FIRST LAYER\n",
    "        # FROM THIS POINT ONWARD WE HAVE TO USE THE MORE COMPLEX VERSION\n",
    "        # OF UPDATING THE VALUES => CHAIN RULE\n",
    "\n",
    "        # weight 1\n",
    "        deriv_L_w1_left = 2 * w5 * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        deriv_L_w1_right = activation_ReLu_partial_derivative(input1 * w1 + input2 * w3 + bias1) * input1\n",
    "        deriv_L_w1 = deriv_L_w1_left * deriv_L_w1_right\n",
    "        new_w1 = w1 - LR * deriv_L_w1\n",
    "\n",
    "        deriv_L_w2_left = 2 * w6 * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        deriv_L_w2_right = activation_ReLu_partial_derivative(input1 * w1 + input2 * w3 + bias1) * input1\n",
    "        deriv_L_w2 = deriv_L_w2_left * deriv_L_w2_right\n",
    "        new_w2 = w2 - LR * deriv_L_w2\n",
    "\n",
    "        deriv_L_w3_left = 2 * w5 * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        deriv_L_w3_right = activation_ReLu_partial_derivative(input1 * w1 + input2 * w3 + bias1) * input2\n",
    "        deriv_L_w3 = deriv_L_w3_left * deriv_L_w3_right\n",
    "        new_w3 = w3 - LR * deriv_L_w3\n",
    "\n",
    "        deriv_L_w4_left = 2 * w6 * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        deriv_L_w4_right = activation_ReLu_partial_derivative(input1 * w1 + input2 * w3 + bias1) * input2\n",
    "        deriv_L_w4 = deriv_L_w4_left * deriv_L_w4_right\n",
    "        new_w4 = w4 - LR * deriv_L_w4\n",
    "\n",
    "        deriv_L_b1_left = 2 * w5 * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        deriv_L_b1_right = activation_ReLu_partial_derivative(input1 * w1 + input2 * w3 + bias1) * 1\n",
    "        deriv_L_b1 = deriv_L_b1_left * deriv_L_b1_right\n",
    "        new_b1 = bias1 - LR * deriv_L_b1\n",
    "\n",
    "        deriv_L_b2_left = 2 * w6 * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        deriv_L_b2_right = activation_ReLu_partial_derivative(input1 * w1 + input2 * w3 + bias1) * 1\n",
    "        deriv_L_b2 = deriv_L_b2_left * deriv_L_b2_right\n",
    "        new_b2 = bias2 - LR * deriv_L_b2\n",
    "\n",
    "        # ALL DONE! FINALLY UPDATE THE EXISTING WEIGHTS\n",
    "        w1 = new_w1\n",
    "        w2 = new_w2\n",
    "        w3 = new_w3\n",
    "        w4 = new_w4\n",
    "        w5 = new_w5\n",
    "        w6 = new_w6\n",
    "        bias1 = new_b1\n",
    "        bias2 = new_b2\n",
    "        bias3 = new_b3\n",
    "\n",
    "    # calculate average epoch-wise loss and add it to loss points\n",
    "    average_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "\n",
    "    # place the overall epoch loss into the loss_points list\n",
    "    loss_points.append(average_loss)\n",
    "    print(f\"Epoch: {epoch + 1}, loss: {average_loss}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_points)\n",
    "# plt.ylim(-1, 5)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL WEIGHTS AND BIASES\n",
      "w1: 1\n",
      "w2: 0.5\n",
      "w3: 1\n",
      "w4: -0.5\n",
      "w5: 1\n",
      "w6: 1\n",
      "b1: 0.5\n",
      "b2: 0\n",
      "b3: 0.5\n",
      "\n",
      "\n",
      "#################################\n",
      "\n",
      "\n",
      "NEW WEIGHTS AND BIASES\n",
      "w1: 0.4539259976780034\n",
      "w2: 0.13081584608007948\n",
      "w3: 0.7537462680426352\n",
      "w4: -0.10214758877990215\n",
      "w5: 0.30925823599182317\n",
      "w6: 0.27833813378346123\n",
      "b1: -0.15405046694510455\n",
      "b2: 0.3946950482666213\n",
      "b3: -0.02349838844576464\n"
     ]
    }
   ],
   "source": [
    "print(\"ORIGINAL WEIGHTS AND BIASES\")\n",
    "print(f\"w1: {original_w1}\")\n",
    "print(f\"w2: {original_w2}\")\n",
    "print(f\"w3: {original_w3}\")\n",
    "print(f\"w4: {original_w4}\")\n",
    "print(f\"w5: {original_w5}\")\n",
    "print(f\"w6: {original_w6}\")\n",
    "print(f\"b1: {original_b1}\")\n",
    "print(f\"b2: {original_b2}\")\n",
    "print(f\"b3: {original_b3}\")\n",
    "\n",
    "print(\"\\n\\n#################################\\n\\n\")\n",
    "\n",
    "print(\"NEW WEIGHTS AND BIASES\")\n",
    "print(f\"w1: {new_w1}\")\n",
    "print(f\"w2: {new_w2}\")\n",
    "print(f\"w3: {new_w3}\")\n",
    "print(f\"w4: {new_w4}\")\n",
    "print(f\"w5: {new_w5}\")\n",
    "print(f\"w6: {new_w6}\")\n",
    "print(f\"b1: {new_b1}\")\n",
    "print(f\"b2: {new_b2}\")\n",
    "print(f\"b3: {new_b3}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction function, just doing the forward pass\n",
    "# again (but only that)\n",
    "def predict(x1, x2):\n",
    "    input1 = x1\n",
    "    input2 = x2\n",
    "\n",
    "    # NODE 1 OUTPUT\n",
    "    node_1_output = input1 * w1 + input2 * w3 + bias1\n",
    "    node_1_output = activation_ReLu(node_1_output)\n",
    "\n",
    "    # NODE 2 OUTPUT\n",
    "    node_2_output = input1 * w2 + input2 * w4 + bias2\n",
    "    node_2_output = activation_ReLu(node_2_output)\n",
    "\n",
    "    # NODE 3 OUTPUT\n",
    "    # we can just use Node 1 and 2 outputs, since they\n",
    "    # already contain the previous weights in their result\n",
    "    node_3_output = node_1_output * w5 + node_2_output * w6 + bias3\n",
    "    node_3_output = activation_ReLu(node_3_output)\n",
    "    return node_3_output\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767</th>\n",
       "      <td>47</td>\n",
       "      <td>45.320</td>\n",
       "      <td>8569.86180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2768</th>\n",
       "      <td>21</td>\n",
       "      <td>34.600</td>\n",
       "      <td>2020.17700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2769</th>\n",
       "      <td>19</td>\n",
       "      <td>26.030</td>\n",
       "      <td>16450.89470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2770</th>\n",
       "      <td>23</td>\n",
       "      <td>18.715</td>\n",
       "      <td>21595.38229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2771</th>\n",
       "      <td>54</td>\n",
       "      <td>31.600</td>\n",
       "      <td>9850.43200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2772 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     bmi      charges\n",
       "0      19  27.900  16884.92400\n",
       "1      18  33.770   1725.55230\n",
       "2      28  33.000   4449.46200\n",
       "3      33  22.705  21984.47061\n",
       "4      32  28.880   3866.85520\n",
       "...   ...     ...          ...\n",
       "2767   47  45.320   8569.86180\n",
       "2768   21  34.600   2020.17700\n",
       "2769   19  26.030  16450.89470\n",
       "2770   23  18.715  21595.38229\n",
       "2771   54  31.600   9850.43200\n",
       "\n",
       "[2772 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           54.00000\n",
       "bmi           47.41000\n",
       "charges    63770.42801\n",
       "Name: 543, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index 543 is one of the biggest charges in the data\n",
    "df.iloc[543]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.set_printoptions(precision=12, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7826087 , 0.84611246, 1.        ])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scaled values\n",
    "data[543]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(63770.42801)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# $ ~63770 \n",
    "df['charges'].max() * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.35025180611651135)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try using the model with our prediction function\n",
    "# the value tends to be same as final bias 3\n",
    "# so if node1 and node2 outputs are small => more or less bias3\n",
    "result = predict(0.7826087 , 0.84611246)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(22335.707587325465)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['charges'].max() * result\n",
    "\n",
    "# estimated $ ~22335 USD, heavily undershoots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2772.000000</td>\n",
       "      <td>2772.000000</td>\n",
       "      <td>2772.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>39.109668</td>\n",
       "      <td>30.701349</td>\n",
       "      <td>13261.369959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.081459</td>\n",
       "      <td>6.129449</td>\n",
       "      <td>12151.768945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>15.960000</td>\n",
       "      <td>1121.873900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.220000</td>\n",
       "      <td>4687.797000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>30.447500</td>\n",
       "      <td>9333.014350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>34.770000</td>\n",
       "      <td>16577.779500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>53.130000</td>\n",
       "      <td>63770.428010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age          bmi       charges\n",
       "count  2772.000000  2772.000000   2772.000000\n",
       "mean     39.109668    30.701349  13261.369959\n",
       "std      14.081459     6.129449  12151.768945\n",
       "min      18.000000    15.960000   1121.873900\n",
       "25%      26.000000    26.220000   4687.797000\n",
       "50%      39.000000    30.447500   9333.014350\n",
       "75%      51.000000    34.770000  16577.779500\n",
       "max      64.000000    53.130000  63770.428010"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just checking if the value revolves around the average...\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
