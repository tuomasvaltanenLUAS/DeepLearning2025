{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN for regression, example 1, house energy bill estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Version 2: using some common optimization approaches (inspecting variable importance, neural network normalization, regularization, ModelCheckpoint etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports / modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikit-learn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# pip install tensorflow\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "# random seed locking code original from ChatGPT => has been tested that it works\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Set a fixed seed value\n",
    "SEED = 9876543\n",
    "\n",
    "# 1. Set Python's built-in random module seed\n",
    "random.seed(SEED)\n",
    "\n",
    "# 2. Set NumPy random seed\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# 3. Set TensorFlow seed\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# 4. Set environment variables (affects some backend randomness)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "# Optional: control inter-op and intra-op parallelism for determinism\n",
    "# (can slightly slow down training, but improves reproducibility)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the csv-file to pandas DataFrame\n",
    "df = pd.read_csv(\"Household energy bill data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### X/y-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform X/y -split\n",
    "# if you  have more than one independent variable, list them all here\n",
    "# leave out the target variable! (dependent variable)\n",
    "\n",
    "# this is a nice and common trick => everything EXCEPT target variable => support variable\n",
    "X = df.drop(\"amount_paid\", axis=1)\n",
    "\n",
    "# have only the target variable here (dependent variable)\n",
    "y = df[\"amount_paid\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/test/validation -split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in Classic ML, we only had train/test -split\n",
    "# in deep learning, we usually use validation-data also, for better\n",
    "# optimization possibilities and better metrics\n",
    "\n",
    "# unfortunately the scikit-learn's train_test_split doesn't support validation\n",
    "# set split in itself.\n",
    "\n",
    "# if you want to split the test set into two for a validation set too, try this trick:\n",
    "\n",
    "# step 1, split the data into 70% (training data) and 30% (temporary data)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# step 2, split the temporary data in HALF (0.5) => 15% test and 15% validation\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras tuner for finding optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 01m 05s]\n",
      "val_loss: 5082.67529296875\n",
      "\n",
      "Best val_loss So Far: 3684.2427571614585\n",
      "Total elapsed time: 00h 13m 19s\n"
     ]
    }
   ],
   "source": [
    "# pip install keras-tuner\n",
    "import keras_tuner\n",
    "\n",
    "def build_model(hp):\n",
    "    # iniatlize sequential test neural network\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # first layer, batch normalization + input shape, same as in typical neural network\n",
    "    model.add(layers.BatchNormalization(input_shape=(len(X.columns),)),)\n",
    "    \n",
    "    # add the first actual layer including the regularizer\n",
    "    model.add(\n",
    "        layers.Dense(\n",
    "            # Tune number of units separately.\n",
    "            units=hp.Int(f\"units_0\", min_value=4, max_value=32, step=2),\n",
    "            activation=hp.Choice(\"activation\", [\"relu\"]),\n",
    "            kernel_regularizer=keras.regularizers.l1(hp.Float(\"l1\", min_value=0.01, max_value=0.3, sampling=\"log\"))\n",
    "        )\n",
    "    )\n",
    "        \n",
    "    # automate a dropout layer\n",
    "    if hp.Boolean(\"dropout\"):\n",
    "        model.add(layers.Dropout(\n",
    "            hp.Float(\"rate\", min_value=0.05, max_value=0.35, step=0.025)\n",
    "            ))\n",
    "\n",
    "    # try additional layers, 1 or 2 extra layers\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 4)):\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                # Tune number of units separately.\n",
    "                units=hp.Int(f\"units_{i + 1}\", min_value=2, max_value=32, step=2),\n",
    "                activation=hp.Choice(\"activation\", [\"relu\"]),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # output layer, only one node since this is regression\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    # automate learning rate tests\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-5, max_value=1e-2, sampling=\"log\")\n",
    "\n",
    "    # compile the test neural network\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=\"mse\"\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# build the model + use RandomSearch to actually search the best options for our neural network\n",
    "build_model(keras_tuner.HyperParameters())\n",
    "\n",
    "# use val_loss as the objective, because regression tasks do not have accuracy\n",
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_loss\",\n",
    "    max_trials=10,\n",
    "    executions_per_trial=3,\n",
    "    overwrite=True,\n",
    "    directory=\"optimizations2\",\n",
    "    project_name=\"regression1test\",\n",
    ")\n",
    "\n",
    "# start searching\n",
    "tuner.search(X_train, y_train, epochs=250, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in optimizations2\\regression1test\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n",
      "\n",
      "Trial 05 summary\n",
      "Hyperparameters:\n",
      "units_0: 26\n",
      "activation: relu\n",
      "l1: 0.07550703449103036\n",
      "dropout: True\n",
      "num_layers: 2\n",
      "units_1: 12\n",
      "lr: 0.0010558463563330278\n",
      "units_2: 12\n",
      "rate: 0.2\n",
      "units_3: 10\n",
      "Score: 3684.2427571614585\n",
      "\n",
      "Trial 08 summary\n",
      "Hyperparameters:\n",
      "units_0: 14\n",
      "activation: relu\n",
      "l1: 0.011012382008768652\n",
      "dropout: True\n",
      "num_layers: 1\n",
      "units_1: 10\n",
      "lr: 0.002343528985475282\n",
      "units_2: 18\n",
      "rate: 0.325\n",
      "units_3: 16\n",
      "units_4: 18\n",
      "Score: 3736.46337890625\n",
      "\n",
      "Trial 01 summary\n",
      "Hyperparameters:\n",
      "units_0: 16\n",
      "activation: relu\n",
      "l1: 0.09639795801685072\n",
      "dropout: True\n",
      "num_layers: 1\n",
      "units_1: 24\n",
      "lr: 0.004488308420307574\n",
      "units_2: 16\n",
      "rate: 0.05\n",
      "Score: 3798.7180989583335\n",
      "\n",
      "Trial 06 summary\n",
      "Hyperparameters:\n",
      "units_0: 10\n",
      "activation: relu\n",
      "l1: 0.07256565819272734\n",
      "dropout: True\n",
      "num_layers: 2\n",
      "units_1: 14\n",
      "lr: 0.0017158449010619633\n",
      "units_2: 10\n",
      "rate: 0.22500000000000003\n",
      "units_3: 10\n",
      "Score: 4237.776204427083\n",
      "\n",
      "Trial 09 summary\n",
      "Hyperparameters:\n",
      "units_0: 32\n",
      "activation: relu\n",
      "l1: 0.18580315599691427\n",
      "dropout: False\n",
      "num_layers: 1\n",
      "units_1: 20\n",
      "lr: 0.007029262882902356\n",
      "units_2: 4\n",
      "rate: 0.15000000000000002\n",
      "units_3: 16\n",
      "units_4: 20\n",
      "Score: 5082.67529296875\n",
      "\n",
      "Trial 04 summary\n",
      "Hyperparameters:\n",
      "units_0: 28\n",
      "activation: relu\n",
      "l1: 0.1791381175146719\n",
      "dropout: False\n",
      "num_layers: 3\n",
      "units_1: 18\n",
      "lr: 0.0001784794574379517\n",
      "units_2: 8\n",
      "rate: 0.175\n",
      "units_3: 2\n",
      "Score: 6473.677083333333\n",
      "\n",
      "Trial 00 summary\n",
      "Hyperparameters:\n",
      "units_0: 32\n",
      "activation: relu\n",
      "l1: 0.01118809030227843\n",
      "dropout: False\n",
      "num_layers: 2\n",
      "units_1: 30\n",
      "lr: 0.006610921619024132\n",
      "units_2: 2\n",
      "Score: 115749.34847005208\n",
      "\n",
      "Trial 07 summary\n",
      "Hyperparameters:\n",
      "units_0: 8\n",
      "activation: relu\n",
      "l1: 0.02935694553717985\n",
      "dropout: True\n",
      "num_layers: 4\n",
      "units_1: 8\n",
      "lr: 8.556581060099099e-05\n",
      "units_2: 28\n",
      "rate: 0.15000000000000002\n",
      "units_3: 22\n",
      "units_4: 2\n",
      "Score: 134073.0791015625\n",
      "\n",
      "Trial 02 summary\n",
      "Hyperparameters:\n",
      "units_0: 20\n",
      "activation: relu\n",
      "l1: 0.01604890915641534\n",
      "dropout: True\n",
      "num_layers: 1\n",
      "units_1: 32\n",
      "lr: 3.681879293275022e-05\n",
      "units_2: 20\n",
      "rate: 0.2\n",
      "Score: 322613.3541666667\n",
      "\n",
      "Trial 03 summary\n",
      "Hyperparameters:\n",
      "units_0: 26\n",
      "activation: relu\n",
      "l1: 0.04525976660182839\n",
      "dropout: True\n",
      "num_layers: 2\n",
      "units_1: 2\n",
      "lr: 3.158420976695495e-05\n",
      "units_2: 28\n",
      "rate: 0.22500000000000003\n",
      "Score: 365143.4166666667\n"
     ]
    }
   ],
   "source": [
    "# print out the result and suggestions\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tuomas.valtanen\\DL2025lecturenotes2\\DeepLearning2025\\.venv\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:142: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "c:\\Users\\tuomas.valtanen\\DL2025lecturenotes2\\DeepLearning2025\\.venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 22 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">324</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)              │            \u001b[38;5;34m36\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)             │           \u001b[38;5;34m260\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m324\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m156\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m13\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">789</span> (3.08 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m789\u001b[0m (3.08 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">771</span> (3.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m771\u001b[0m (3.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18</span> (72.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m18\u001b[0m (72.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Get the top 2 models.\n",
    "models = tuner.get_best_models(num_models=1)\n",
    "best_model = models[0]\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'asfgsadfgsd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43masfgsadfgsd\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'asfgsadfgsd' is not defined"
     ]
    }
   ],
   "source": [
    "asfgsadfgsd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a neural network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tuomas.valtanen\\DL2025lecturenotes2\\DeepLearning2025\\.venv\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:142: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">324</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)              │            \u001b[38;5;34m36\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)             │           \u001b[38;5;34m260\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m324\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m156\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m13\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">789</span> (3.08 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m789\u001b[0m (3.08 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">771</span> (3.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m771\u001b[0m (3.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18</span> (72.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m18\u001b[0m (72.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create neural network\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# save the amount of support variables into a helper variable\n",
    "# so we don't have to update the input_shape all the time\n",
    "variable_amount = len(X.columns)\n",
    "\n",
    "# create callbacks and place them into a parameter list\n",
    "# NOTE! if you get PermissionError while training the model,\n",
    "# just try training it again\n",
    "mc = ModelCheckpoint('best_model_regression1_energybill_kt.keras', monitor='val_loss', mode='min', save_best_only=True)\n",
    "\n",
    "# if you use multiple callbacks (EarlyStoppin, ReduceLROnPlateau etc.)\n",
    "# add them to this same list\n",
    "callback_list = [mc]\n",
    "\n",
    "\n",
    "# Trial 05 summary\n",
    "# Hyperparameters:\n",
    "# units_0: 26\n",
    "# activation: relu\n",
    "# l1: 0.07550703449103036\n",
    "# dropout: True\n",
    "# num_layers: 2\n",
    "# units_1: 12\n",
    "# lr: 0.0010558463563330278\n",
    "# units_2: 12\n",
    "# rate: 0.2\n",
    "# units_3: 10\n",
    "# Score: 3684.2427571614585\n",
    "\n",
    "# ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "# ┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n",
    "# ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "# │ batch_normalization             │ (None, 9)              │            36 │\n",
    "# │ (BatchNormalization)            │                        │               │\n",
    "# ├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "# │ dense (Dense)                   │ (None, 26)             │           260 │\n",
    "# ├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "# │ dropout (Dropout)               │ (None, 26)             │             0 │\n",
    "# ├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "# │ dense_1 (Dense)                 │ (None, 12)             │           324 │\n",
    "# ├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "# │ dense_2 (Dense)                 │ (None, 12)             │           156 │\n",
    "# ├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "# │ dense_3 (Dense)                 │ (None, 1)              │            13 │\n",
    "# └─────────────────────────────────┴────────────────────────┴───────────────┘\n",
    "\n",
    "# once you know approximately a working neural network structure for your data\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.BatchNormalization(input_shape=(variable_amount,)),\n",
    "        layers.Dense(26, activation=\"relu\", kernel_regularizer=keras.regularizers.l1(l1=0.07550703449103036)),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(12, activation=\"relu\"),\n",
    "        layers.Dense(12, activation=\"relu\"),\n",
    "        layers.Dense(1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "optimal_lr = 0.0010558463563330278\n",
    "\n",
    "# select the optimizer and loss function\n",
    "# you can try rmsprop also as optimizer, or stochastic gradient descent\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=optimal_lr), loss='mse')\n",
    "\n",
    "# common tips on how to change neural network structure if your metrics are not good:\n",
    "\n",
    "# make wider (or narrower) layers (for example, 64 or 128 nodes)\n",
    "# make a longer or shorter network (add or remove layers)\n",
    "# use Dropout -layers (e.g. layers.Dropout(0.1))\n",
    "\n",
    "# remember: there's no process or mathematical formula\n",
    "# in order to figure out the optimal neural network structure\n",
    "# it's mostly all about trial and error => EXPERIMENTATION!\n",
    "\n",
    "# remember to have enough \"decision-space\" for your data!\n",
    "# it's highly unlikely a dataset with 20 different variables is going\n",
    "# to work well with only 8 nodes in each layer etc.\n",
    "\n",
    "# print out the summary of your model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the neural network (notice how we connect the callbacks here, this enables ModelCheckpoint etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 398742.6875 - val_loss: 376442.7812\n",
      "Epoch 2/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 398351.3750 - val_loss: 375812.5312\n",
      "Epoch 3/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 397598.3125 - val_loss: 374667.5312\n",
      "Epoch 4/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 396165.3125 - val_loss: 372442.0000\n",
      "Epoch 5/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 393438.0312 - val_loss: 367917.1250\n",
      "Epoch 6/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 387574.0312 - val_loss: 358675.9062\n",
      "Epoch 7/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 375756.7500 - val_loss: 340924.7188\n",
      "Epoch 8/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 351496.5625 - val_loss: 308388.4375\n",
      "Epoch 9/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 309312.4688 - val_loss: 254655.6250\n",
      "Epoch 10/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 242311.8125 - val_loss: 179723.4844\n",
      "Epoch 11/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 160567.5000 - val_loss: 105626.5156\n",
      "Epoch 12/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 96286.7578 - val_loss: 68583.8906\n",
      "Epoch 13/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 74091.5938 - val_loss: 57623.9531\n",
      "Epoch 14/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 61266.8477 - val_loss: 48816.8320\n",
      "Epoch 15/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 53375.2109 - val_loss: 41525.4258\n",
      "Epoch 16/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 45957.7656 - val_loss: 35333.7188\n",
      "Epoch 17/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 41950.3516 - val_loss: 30071.8457\n",
      "Epoch 18/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 34114.0781 - val_loss: 25556.5547\n",
      "Epoch 19/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 30182.2168 - val_loss: 21926.6133\n",
      "Epoch 20/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27803.1465 - val_loss: 18933.6230\n",
      "Epoch 21/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 24536.4180 - val_loss: 16658.8691\n",
      "Epoch 22/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22521.4043 - val_loss: 14789.0986\n",
      "Epoch 23/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 21366.1914 - val_loss: 13353.7832\n",
      "Epoch 24/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19396.9941 - val_loss: 12224.2461\n",
      "Epoch 25/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 18088.0430 - val_loss: 11272.7676\n",
      "Epoch 26/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 17548.8984 - val_loss: 10452.0127\n",
      "Epoch 27/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16406.3379 - val_loss: 9747.6475\n",
      "Epoch 28/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16863.5977 - val_loss: 9221.1201\n",
      "Epoch 29/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 17908.3945 - val_loss: 8804.2246\n",
      "Epoch 30/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15107.0869 - val_loss: 8411.9912\n",
      "Epoch 31/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15926.7627 - val_loss: 8086.2568\n",
      "Epoch 32/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14586.9668 - val_loss: 7833.5186\n",
      "Epoch 33/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 14819.6240 - val_loss: 7659.3999\n",
      "Epoch 34/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15050.4990 - val_loss: 7408.5542\n",
      "Epoch 35/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14250.4512 - val_loss: 7182.5835\n",
      "Epoch 36/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14629.1475 - val_loss: 6995.8843\n",
      "Epoch 37/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13493.4404 - val_loss: 6826.9077\n",
      "Epoch 38/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14694.3818 - val_loss: 6701.8027\n",
      "Epoch 39/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12867.9414 - val_loss: 6568.9502\n",
      "Epoch 40/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14738.8955 - val_loss: 6445.5581\n",
      "Epoch 41/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13524.0361 - val_loss: 6320.3896\n",
      "Epoch 42/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13214.2354 - val_loss: 6177.8569\n",
      "Epoch 43/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13644.6875 - val_loss: 6042.6904\n",
      "Epoch 44/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13971.8789 - val_loss: 5925.6440\n",
      "Epoch 45/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13534.1904 - val_loss: 5877.0176\n",
      "Epoch 46/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12821.8125 - val_loss: 5792.8672\n",
      "Epoch 47/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13566.9053 - val_loss: 5734.9683\n",
      "Epoch 48/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13772.1699 - val_loss: 5634.7041\n",
      "Epoch 49/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12340.3613 - val_loss: 5481.5386\n",
      "Epoch 50/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13316.9316 - val_loss: 5424.0371\n",
      "Epoch 51/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12520.0215 - val_loss: 5372.6909\n",
      "Epoch 52/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13004.8330 - val_loss: 5243.8921\n",
      "Epoch 53/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13112.4941 - val_loss: 5149.1182\n",
      "Epoch 54/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11785.7949 - val_loss: 5076.2964\n",
      "Epoch 55/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13131.8945 - val_loss: 5049.4219\n",
      "Epoch 56/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12119.3701 - val_loss: 4938.7485\n",
      "Epoch 57/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11855.5732 - val_loss: 4909.9258\n",
      "Epoch 58/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12555.9053 - val_loss: 4836.3335\n",
      "Epoch 59/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13213.5713 - val_loss: 4758.6777\n",
      "Epoch 60/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12075.9971 - val_loss: 4681.3804\n",
      "Epoch 61/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12388.1152 - val_loss: 4648.9810\n",
      "Epoch 62/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11906.9590 - val_loss: 4632.2930\n",
      "Epoch 63/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 12006.0010 - val_loss: 4658.3862\n",
      "Epoch 64/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11222.4102 - val_loss: 4577.8335\n",
      "Epoch 65/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 12113.0283 - val_loss: 4649.8291\n",
      "Epoch 66/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10895.7617 - val_loss: 4536.2129\n",
      "Epoch 67/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11956.4590 - val_loss: 4494.7842\n",
      "Epoch 68/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 11828.3955 - val_loss: 4586.8999\n",
      "Epoch 69/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10939.7832 - val_loss: 4467.4438\n",
      "Epoch 70/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11325.4717 - val_loss: 4437.2412\n",
      "Epoch 71/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 11184.6709 - val_loss: 4450.1660\n",
      "Epoch 72/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11626.9873 - val_loss: 4420.7671\n",
      "Epoch 73/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11542.8584 - val_loss: 4404.1240\n",
      "Epoch 74/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10620.9160 - val_loss: 4395.6724\n",
      "Epoch 75/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10564.0781 - val_loss: 4366.5259\n",
      "Epoch 76/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11070.1953 - val_loss: 4311.2354\n",
      "Epoch 77/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 11930.2236 - val_loss: 4319.8853\n",
      "Epoch 78/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 11069.2305 - val_loss: 4361.3701\n",
      "Epoch 79/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10805.9941 - val_loss: 4265.7231\n",
      "Epoch 80/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11372.0645 - val_loss: 4233.9468\n",
      "Epoch 81/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 11133.3105 - val_loss: 4244.4673\n",
      "Epoch 82/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 11945.7324 - val_loss: 4237.6265\n",
      "Epoch 83/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11046.7197 - val_loss: 4230.2856\n",
      "Epoch 84/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10922.9883 - val_loss: 4202.6685\n",
      "Epoch 85/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10966.2236 - val_loss: 4266.4702\n",
      "Epoch 86/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9713.3467 - val_loss: 4161.9854\n",
      "Epoch 87/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11352.5273 - val_loss: 4158.7285\n",
      "Epoch 88/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9927.9756 - val_loss: 4125.5410\n",
      "Epoch 89/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10784.7021 - val_loss: 4122.3892\n",
      "Epoch 90/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10839.8740 - val_loss: 4150.3945\n",
      "Epoch 91/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 11071.7432 - val_loss: 4158.5215\n",
      "Epoch 92/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10552.9971 - val_loss: 4157.7485\n",
      "Epoch 93/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10466.0605 - val_loss: 4155.3516\n",
      "Epoch 94/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10410.1738 - val_loss: 4106.1616\n",
      "Epoch 95/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10343.0547 - val_loss: 4063.4954\n",
      "Epoch 96/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10696.6357 - val_loss: 4045.0337\n",
      "Epoch 97/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10164.6504 - val_loss: 4038.1187\n",
      "Epoch 98/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11584.7891 - val_loss: 4037.3318\n",
      "Epoch 99/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9915.7822 - val_loss: 4002.1575\n",
      "Epoch 100/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10107.9756 - val_loss: 3976.5276\n",
      "Epoch 101/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9832.8057 - val_loss: 3960.7537\n",
      "Epoch 102/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10299.8760 - val_loss: 3945.8809\n",
      "Epoch 103/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 11161.4756 - val_loss: 3955.1709\n",
      "Epoch 104/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10552.8057 - val_loss: 3937.5701\n",
      "Epoch 105/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10561.3770 - val_loss: 3961.5166\n",
      "Epoch 106/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10806.4404 - val_loss: 3976.5813\n",
      "Epoch 107/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10247.9463 - val_loss: 3952.5618\n",
      "Epoch 108/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10217.6074 - val_loss: 3960.9521\n",
      "Epoch 109/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9733.9443 - val_loss: 3941.3997\n",
      "Epoch 110/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9761.9355 - val_loss: 3937.3979\n",
      "Epoch 111/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10320.5059 - val_loss: 3912.9167\n",
      "Epoch 112/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9921.9697 - val_loss: 4058.9216\n",
      "Epoch 113/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9800.8184 - val_loss: 3901.4014\n",
      "Epoch 114/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9998.3545 - val_loss: 3937.2637\n",
      "Epoch 115/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10236.5801 - val_loss: 3865.3142\n",
      "Epoch 116/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10278.8467 - val_loss: 3904.1272\n",
      "Epoch 117/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10555.7930 - val_loss: 3912.1433\n",
      "Epoch 118/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10415.3906 - val_loss: 3910.3501\n",
      "Epoch 119/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9976.1777 - val_loss: 4002.1738\n",
      "Epoch 120/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9871.4482 - val_loss: 3894.6704\n",
      "Epoch 121/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10368.1846 - val_loss: 3983.2883\n",
      "Epoch 122/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9208.6328 - val_loss: 3942.7412\n",
      "Epoch 123/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8976.0576 - val_loss: 3884.0247\n",
      "Epoch 124/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9798.3955 - val_loss: 3947.3574\n",
      "Epoch 125/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10188.1719 - val_loss: 3901.9292\n",
      "Epoch 126/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9296.4668 - val_loss: 3937.6892\n",
      "Epoch 127/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10620.3105 - val_loss: 3943.8562\n",
      "Epoch 128/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9590.6006 - val_loss: 3995.8562\n",
      "Epoch 129/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9763.7559 - val_loss: 3952.1016\n",
      "Epoch 130/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9923.2471 - val_loss: 3977.2334\n",
      "Epoch 131/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9509.5264 - val_loss: 3903.7224\n",
      "Epoch 132/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9846.3281 - val_loss: 3912.3542\n",
      "Epoch 133/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8792.9414 - val_loss: 3936.3259\n",
      "Epoch 134/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9620.1631 - val_loss: 4016.3162\n",
      "Epoch 135/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9734.2451 - val_loss: 3886.1792\n",
      "Epoch 136/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9905.4619 - val_loss: 3881.2322\n",
      "Epoch 137/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9197.6875 - val_loss: 3908.2275\n",
      "Epoch 138/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8835.1221 - val_loss: 3915.8743\n",
      "Epoch 139/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9634.2510 - val_loss: 4032.7334\n",
      "Epoch 140/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10000.0293 - val_loss: 3858.0325\n",
      "Epoch 141/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9771.9424 - val_loss: 3923.9751\n",
      "Epoch 142/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9528.2227 - val_loss: 3883.9746\n",
      "Epoch 143/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9390.7344 - val_loss: 3921.8779\n",
      "Epoch 144/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9131.0908 - val_loss: 3875.0996\n",
      "Epoch 145/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8684.5889 - val_loss: 3871.1533\n",
      "Epoch 146/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9436.1562 - val_loss: 3866.1338\n",
      "Epoch 147/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10180.5439 - val_loss: 3915.8945\n",
      "Epoch 148/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10113.0156 - val_loss: 3867.9692\n",
      "Epoch 149/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8951.6992 - val_loss: 3893.5300\n",
      "Epoch 150/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9709.8818 - val_loss: 3958.8132\n",
      "Epoch 151/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10217.1689 - val_loss: 3876.8208\n",
      "Epoch 152/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9400.6396 - val_loss: 3962.1042\n",
      "Epoch 153/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9873.8789 - val_loss: 3871.3467\n",
      "Epoch 154/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9399.6670 - val_loss: 3869.0833\n",
      "Epoch 155/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9570.4736 - val_loss: 3921.0933\n",
      "Epoch 156/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9546.7510 - val_loss: 3931.4683\n",
      "Epoch 157/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10011.5732 - val_loss: 3897.1555\n",
      "Epoch 158/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8943.4082 - val_loss: 3982.6001\n",
      "Epoch 159/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7489.9185 - val_loss: 3921.3557\n",
      "Epoch 160/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9140.5039 - val_loss: 3904.1042\n",
      "Epoch 161/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9190.5049 - val_loss: 3858.4736\n",
      "Epoch 162/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9904.3184 - val_loss: 4020.1755\n",
      "Epoch 163/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9543.7129 - val_loss: 3863.5093\n",
      "Epoch 164/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9276.0293 - val_loss: 3855.6057\n",
      "Epoch 165/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9092.9980 - val_loss: 3863.6904\n",
      "Epoch 166/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9369.4980 - val_loss: 3859.8696\n",
      "Epoch 167/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9401.7744 - val_loss: 3839.7095\n",
      "Epoch 168/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9241.4824 - val_loss: 3862.4695\n",
      "Epoch 169/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9469.6240 - val_loss: 3850.4326\n",
      "Epoch 170/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9553.7891 - val_loss: 3853.8914\n",
      "Epoch 171/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9449.6182 - val_loss: 3829.1033\n",
      "Epoch 172/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9363.1904 - val_loss: 3950.4583\n",
      "Epoch 173/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8326.9131 - val_loss: 3867.1655\n",
      "Epoch 174/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9826.8906 - val_loss: 3824.1191\n",
      "Epoch 175/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9895.6211 - val_loss: 3904.2920\n",
      "Epoch 176/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9392.4785 - val_loss: 3849.6433\n",
      "Epoch 177/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9376.4824 - val_loss: 3930.0171\n",
      "Epoch 178/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8425.2832 - val_loss: 3896.4951\n",
      "Epoch 179/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10317.3125 - val_loss: 3825.4475\n",
      "Epoch 180/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9869.7012 - val_loss: 3945.7583\n",
      "Epoch 181/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9665.3281 - val_loss: 3904.5076\n",
      "Epoch 182/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9449.7939 - val_loss: 3856.8491\n",
      "Epoch 183/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8543.5713 - val_loss: 3863.0671\n",
      "Epoch 184/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10060.8496 - val_loss: 3821.8997\n",
      "Epoch 185/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8271.9668 - val_loss: 3821.2422\n",
      "Epoch 186/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9100.9541 - val_loss: 3819.8503\n",
      "Epoch 187/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9460.0674 - val_loss: 3828.7334\n",
      "Epoch 188/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9055.4219 - val_loss: 3912.1599\n",
      "Epoch 189/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8262.0332 - val_loss: 3866.6580\n",
      "Epoch 190/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8905.8604 - val_loss: 3866.1067\n",
      "Epoch 191/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9348.5830 - val_loss: 3862.8596\n",
      "Epoch 192/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8786.3750 - val_loss: 3897.7571\n",
      "Epoch 193/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8616.2441 - val_loss: 3826.8008\n",
      "Epoch 194/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8752.4268 - val_loss: 3813.3650\n",
      "Epoch 195/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8989.9443 - val_loss: 3858.6067\n",
      "Epoch 196/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9352.3027 - val_loss: 3866.6775\n",
      "Epoch 197/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9417.0332 - val_loss: 3845.3230\n",
      "Epoch 198/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9043.0410 - val_loss: 3855.2170\n",
      "Epoch 199/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8860.0225 - val_loss: 3761.1938\n",
      "Epoch 200/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8380.9336 - val_loss: 3780.5183\n",
      "Epoch 201/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9243.5029 - val_loss: 3806.6450\n",
      "Epoch 202/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9561.1113 - val_loss: 3772.4524\n",
      "Epoch 203/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8836.5586 - val_loss: 3896.3486\n",
      "Epoch 204/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8932.7285 - val_loss: 3753.5125\n",
      "Epoch 205/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8704.0303 - val_loss: 3884.0342\n",
      "Epoch 206/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8482.8008 - val_loss: 3825.4297\n",
      "Epoch 207/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8990.3223 - val_loss: 3875.5916\n",
      "Epoch 208/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8733.7939 - val_loss: 3918.2075\n",
      "Epoch 209/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8803.6025 - val_loss: 3807.2571\n",
      "Epoch 210/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8443.9482 - val_loss: 3823.8147\n",
      "Epoch 211/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9074.9238 - val_loss: 3867.7124\n",
      "Epoch 212/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9637.7383 - val_loss: 3814.0708\n",
      "Epoch 213/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8552.0254 - val_loss: 3797.4880\n",
      "Epoch 214/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8413.8828 - val_loss: 3801.6904\n",
      "Epoch 215/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8088.3320 - val_loss: 3782.0117\n",
      "Epoch 216/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8673.4893 - val_loss: 3772.6238\n",
      "Epoch 217/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8641.5283 - val_loss: 3815.2075\n",
      "Epoch 218/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9087.4902 - val_loss: 3783.2776\n",
      "Epoch 219/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8479.8174 - val_loss: 3772.5867\n",
      "Epoch 220/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7937.5220 - val_loss: 3809.3503\n",
      "Epoch 221/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8970.9014 - val_loss: 3813.2429\n",
      "Epoch 222/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9420.1611 - val_loss: 3915.9246\n",
      "Epoch 223/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8720.7432 - val_loss: 3793.1045\n",
      "Epoch 224/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8501.1846 - val_loss: 3834.1738\n",
      "Epoch 225/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8904.2471 - val_loss: 3746.0791\n",
      "Epoch 226/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8680.8818 - val_loss: 3937.7554\n",
      "Epoch 227/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8549.0898 - val_loss: 3759.5603\n",
      "Epoch 228/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7947.0728 - val_loss: 3887.5249\n",
      "Epoch 229/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9070.6016 - val_loss: 3827.3650\n",
      "Epoch 230/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8771.6582 - val_loss: 3861.0872\n",
      "Epoch 231/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8034.8638 - val_loss: 3849.8284\n",
      "Epoch 232/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9402.0791 - val_loss: 3824.9109\n",
      "Epoch 233/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8344.3125 - val_loss: 3786.0732\n",
      "Epoch 234/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8101.8652 - val_loss: 3779.0525\n",
      "Epoch 235/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9195.4971 - val_loss: 3767.0750\n",
      "Epoch 236/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8938.7344 - val_loss: 3929.0662\n",
      "Epoch 237/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8147.1709 - val_loss: 3859.5933\n",
      "Epoch 238/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8339.2715 - val_loss: 3755.3113\n",
      "Epoch 239/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9470.8711 - val_loss: 3852.8474\n",
      "Epoch 240/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8095.4536 - val_loss: 3794.8103\n",
      "Epoch 241/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8312.5195 - val_loss: 3890.6841\n",
      "Epoch 242/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8549.2754 - val_loss: 3780.5076\n",
      "Epoch 243/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8894.7031 - val_loss: 3907.3171\n",
      "Epoch 244/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7435.1499 - val_loss: 3937.2600\n",
      "Epoch 245/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8101.8530 - val_loss: 3798.8933\n",
      "Epoch 246/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8675.1074 - val_loss: 3818.0024\n",
      "Epoch 247/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8840.0576 - val_loss: 3830.9587\n",
      "Epoch 248/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8349.6602 - val_loss: 3892.6897\n",
      "Epoch 249/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8573.5000 - val_loss: 3785.7188\n",
      "Epoch 250/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8543.9775 - val_loss: 3808.3601\n",
      "Epoch 251/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9165.4160 - val_loss: 3916.3008\n",
      "Epoch 252/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8526.5615 - val_loss: 3810.8245\n",
      "Epoch 253/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8300.2109 - val_loss: 3871.7905\n",
      "Epoch 254/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8639.5947 - val_loss: 3839.6968\n",
      "Epoch 255/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8262.5654 - val_loss: 3731.5413\n",
      "Epoch 256/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8472.3242 - val_loss: 3831.7942\n",
      "Epoch 257/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9274.6260 - val_loss: 3711.6504\n",
      "Epoch 258/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8207.5049 - val_loss: 3901.8787\n",
      "Epoch 259/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8594.8516 - val_loss: 3842.7737\n",
      "Epoch 260/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8242.0684 - val_loss: 3913.0518\n",
      "Epoch 261/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8762.1445 - val_loss: 3894.6550\n",
      "Epoch 262/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7980.7651 - val_loss: 3965.5334\n",
      "Epoch 263/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8062.4844 - val_loss: 3754.5933\n",
      "Epoch 264/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8696.1514 - val_loss: 3937.3230\n",
      "Epoch 265/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8466.9746 - val_loss: 3808.5325\n",
      "Epoch 266/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8219.4531 - val_loss: 3863.2620\n",
      "Epoch 267/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8081.2266 - val_loss: 3949.5833\n",
      "Epoch 268/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8442.8770 - val_loss: 3896.9539\n",
      "Epoch 269/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8418.1631 - val_loss: 3935.2446\n",
      "Epoch 270/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7775.5869 - val_loss: 3762.2083\n",
      "Epoch 271/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8549.4404 - val_loss: 3992.8933\n",
      "Epoch 272/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7612.0728 - val_loss: 3891.4268\n",
      "Epoch 273/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8314.6299 - val_loss: 3934.8567\n",
      "Epoch 274/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7804.8115 - val_loss: 3816.5142\n",
      "Epoch 275/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8219.8428 - val_loss: 3989.1025\n",
      "Epoch 276/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8533.8281 - val_loss: 3889.5378\n",
      "Epoch 277/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7701.8457 - val_loss: 3850.1184\n",
      "Epoch 278/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8139.7827 - val_loss: 3921.3708\n",
      "Epoch 279/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7665.0137 - val_loss: 3928.7505\n",
      "Epoch 280/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8291.3711 - val_loss: 4056.3826\n",
      "Epoch 281/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8291.0918 - val_loss: 3827.7188\n",
      "Epoch 282/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9338.9121 - val_loss: 3811.8616\n",
      "Epoch 283/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8407.4707 - val_loss: 3856.1758\n",
      "Epoch 284/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8443.8652 - val_loss: 3834.4504\n",
      "Epoch 285/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8195.2168 - val_loss: 4027.9192\n",
      "Epoch 286/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8120.0156 - val_loss: 3793.1426\n",
      "Epoch 287/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7909.0952 - val_loss: 3969.3455\n",
      "Epoch 288/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8407.1904 - val_loss: 3975.7791\n",
      "Epoch 289/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8645.8760 - val_loss: 3893.5049\n",
      "Epoch 290/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7780.4927 - val_loss: 3933.0854\n",
      "Epoch 291/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8135.6323 - val_loss: 3819.7708\n",
      "Epoch 292/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8257.6689 - val_loss: 3963.5891\n",
      "Epoch 293/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8806.2607 - val_loss: 3877.4595\n",
      "Epoch 294/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7654.3022 - val_loss: 3886.5513\n",
      "Epoch 295/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7858.4209 - val_loss: 3844.9229\n",
      "Epoch 296/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8429.4170 - val_loss: 3834.8467\n",
      "Epoch 297/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8798.2998 - val_loss: 3851.0801\n",
      "Epoch 298/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7497.4595 - val_loss: 3909.3076\n",
      "Epoch 299/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8408.1182 - val_loss: 3990.4592\n",
      "Epoch 300/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8161.5405 - val_loss: 4014.1484\n",
      "Epoch 301/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7527.0757 - val_loss: 3918.8950\n",
      "Epoch 302/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7656.7983 - val_loss: 3948.8059\n",
      "Epoch 303/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8368.6250 - val_loss: 3958.5330\n",
      "Epoch 304/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8015.6162 - val_loss: 3859.8159\n",
      "Epoch 305/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7970.7886 - val_loss: 4001.4150\n",
      "Epoch 306/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8151.1558 - val_loss: 4069.8662\n",
      "Epoch 307/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8058.4741 - val_loss: 3765.6509\n",
      "Epoch 308/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7850.0913 - val_loss: 3955.6970\n",
      "Epoch 309/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7734.5474 - val_loss: 3871.7336\n",
      "Epoch 310/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7807.5737 - val_loss: 3947.5034\n",
      "Epoch 311/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8255.3281 - val_loss: 3893.2175\n",
      "Epoch 312/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7681.7319 - val_loss: 3994.3691\n",
      "Epoch 313/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8521.6865 - val_loss: 3751.1450\n",
      "Epoch 314/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8069.1455 - val_loss: 4156.3516\n",
      "Epoch 315/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7459.3076 - val_loss: 3959.7158\n",
      "Epoch 316/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7662.9727 - val_loss: 3939.2805\n",
      "Epoch 317/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8307.3340 - val_loss: 3949.2925\n",
      "Epoch 318/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7950.8501 - val_loss: 3954.4524\n",
      "Epoch 319/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7693.0420 - val_loss: 4040.6838\n",
      "Epoch 320/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8188.6084 - val_loss: 3915.9651\n",
      "Epoch 321/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7327.2598 - val_loss: 3881.7576\n",
      "Epoch 322/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8129.4971 - val_loss: 3876.7578\n",
      "Epoch 323/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7578.5020 - val_loss: 3822.7041\n",
      "Epoch 324/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8125.0498 - val_loss: 4029.6003\n",
      "Epoch 325/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7705.5229 - val_loss: 3854.0459\n",
      "Epoch 326/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7337.9365 - val_loss: 4093.0164\n",
      "Epoch 327/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7846.0708 - val_loss: 3895.9084\n",
      "Epoch 328/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8173.0474 - val_loss: 3894.2891\n",
      "Epoch 329/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8040.2109 - val_loss: 4174.9766\n",
      "Epoch 330/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7675.4766 - val_loss: 3851.5874\n",
      "Epoch 331/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8558.1484 - val_loss: 4025.5671\n",
      "Epoch 332/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7725.2886 - val_loss: 3935.9451\n",
      "Epoch 333/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8292.0596 - val_loss: 3952.6755\n",
      "Epoch 334/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8101.2812 - val_loss: 3937.1067\n",
      "Epoch 335/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7783.9287 - val_loss: 3922.5437\n",
      "Epoch 336/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7904.7793 - val_loss: 4084.5571\n",
      "Epoch 337/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7385.6172 - val_loss: 4215.6011\n",
      "Epoch 338/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7180.5483 - val_loss: 3974.9595\n",
      "Epoch 339/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7658.8242 - val_loss: 4050.2849\n",
      "Epoch 340/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7521.5249 - val_loss: 4086.0618\n",
      "Epoch 341/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7919.5034 - val_loss: 4069.6750\n",
      "Epoch 342/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8289.7959 - val_loss: 4018.7122\n",
      "Epoch 343/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7917.1655 - val_loss: 4062.9463\n",
      "Epoch 344/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7781.0298 - val_loss: 3999.7307\n",
      "Epoch 345/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7821.6616 - val_loss: 3975.8909\n",
      "Epoch 346/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7974.0288 - val_loss: 4013.0288\n",
      "Epoch 347/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7118.7495 - val_loss: 4287.2466\n",
      "Epoch 348/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8129.5459 - val_loss: 3877.6741\n",
      "Epoch 349/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8140.3872 - val_loss: 4122.4902\n",
      "Epoch 350/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7683.1929 - val_loss: 4063.8259\n",
      "Epoch 351/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7664.7935 - val_loss: 4023.8120\n",
      "Epoch 352/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7620.1499 - val_loss: 3866.4746\n",
      "Epoch 353/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7656.9502 - val_loss: 3992.6555\n",
      "Epoch 354/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8036.5869 - val_loss: 4037.4116\n",
      "Epoch 355/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7820.7017 - val_loss: 4075.4263\n",
      "Epoch 356/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7767.5942 - val_loss: 4393.8604\n",
      "Epoch 357/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7643.4180 - val_loss: 3976.4326\n",
      "Epoch 358/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8144.7202 - val_loss: 4284.8081\n",
      "Epoch 359/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7375.7358 - val_loss: 4047.9412\n",
      "Epoch 360/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7571.9214 - val_loss: 4219.7310\n",
      "Epoch 361/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8496.6055 - val_loss: 4116.0391\n",
      "Epoch 362/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7740.3213 - val_loss: 4151.3457\n",
      "Epoch 363/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7594.2129 - val_loss: 4136.4980\n",
      "Epoch 364/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7221.3491 - val_loss: 4226.3633\n",
      "Epoch 365/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7188.6201 - val_loss: 4022.6138\n",
      "Epoch 366/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7718.9609 - val_loss: 4159.2017\n",
      "Epoch 367/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7637.9448 - val_loss: 4122.8130\n",
      "Epoch 368/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7360.0928 - val_loss: 4171.4907\n",
      "Epoch 369/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7302.0415 - val_loss: 3997.9192\n",
      "Epoch 370/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7566.8584 - val_loss: 4251.5522\n",
      "Epoch 371/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7793.9414 - val_loss: 4084.7524\n",
      "Epoch 372/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7600.2148 - val_loss: 4405.3618\n",
      "Epoch 373/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7653.3452 - val_loss: 4095.5354\n",
      "Epoch 374/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7402.3613 - val_loss: 4364.1289\n",
      "Epoch 375/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7488.9995 - val_loss: 4061.1970\n",
      "Epoch 376/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7722.1733 - val_loss: 4255.3857\n",
      "Epoch 377/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7498.9795 - val_loss: 4143.9956\n",
      "Epoch 378/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7346.0713 - val_loss: 4460.0571\n",
      "Epoch 379/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7276.6631 - val_loss: 4336.6943\n",
      "Epoch 380/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7405.8242 - val_loss: 4353.2554\n",
      "Epoch 381/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7576.6357 - val_loss: 4375.9375\n",
      "Epoch 382/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7502.0430 - val_loss: 4086.8438\n",
      "Epoch 383/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7524.8750 - val_loss: 4492.4683\n",
      "Epoch 384/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7459.5737 - val_loss: 4307.8555\n",
      "Epoch 385/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7231.1362 - val_loss: 4294.0327\n",
      "Epoch 386/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7842.5059 - val_loss: 4193.9551\n",
      "Epoch 387/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7316.0693 - val_loss: 4329.1616\n",
      "Epoch 388/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6868.6235 - val_loss: 4467.5752\n",
      "Epoch 389/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6791.7905 - val_loss: 4317.3325\n",
      "Epoch 390/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8062.7534 - val_loss: 4357.8081\n",
      "Epoch 391/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7018.8848 - val_loss: 4179.4985\n",
      "Epoch 392/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7294.0767 - val_loss: 4259.6543\n",
      "Epoch 393/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7461.2871 - val_loss: 4422.2412\n",
      "Epoch 394/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7836.7192 - val_loss: 4426.4688\n",
      "Epoch 395/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7572.6338 - val_loss: 4227.7964\n",
      "Epoch 396/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7998.8052 - val_loss: 4375.7002\n",
      "Epoch 397/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7922.0713 - val_loss: 4328.2061\n",
      "Epoch 398/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7359.5566 - val_loss: 4208.3081\n",
      "Epoch 399/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6981.3330 - val_loss: 4366.3340\n",
      "Epoch 400/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7142.9722 - val_loss: 4428.9106\n",
      "Epoch 401/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7556.6284 - val_loss: 4346.3896\n",
      "Epoch 402/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7114.7148 - val_loss: 4347.3218\n",
      "Epoch 403/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7480.5601 - val_loss: 4355.5269\n",
      "Epoch 404/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7730.4473 - val_loss: 4857.9922\n",
      "Epoch 405/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7294.7163 - val_loss: 4500.4780\n",
      "Epoch 406/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7454.0059 - val_loss: 4509.7222\n",
      "Epoch 407/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6981.9814 - val_loss: 4311.7344\n",
      "Epoch 408/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7099.3779 - val_loss: 4745.4385\n",
      "Epoch 409/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7198.0444 - val_loss: 4283.1738\n",
      "Epoch 410/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6994.1899 - val_loss: 4469.1235\n",
      "Epoch 411/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7552.8623 - val_loss: 4410.0190\n",
      "Epoch 412/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7504.8687 - val_loss: 4547.4033\n",
      "Epoch 413/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6979.0674 - val_loss: 4323.8672\n",
      "Epoch 414/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6978.5986 - val_loss: 4486.7778\n",
      "Epoch 415/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7361.5513 - val_loss: 4351.6401\n",
      "Epoch 416/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7692.4185 - val_loss: 4456.0576\n",
      "Epoch 417/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7243.0337 - val_loss: 4555.7651\n",
      "Epoch 418/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6987.9321 - val_loss: 4692.8345\n",
      "Epoch 419/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7499.6470 - val_loss: 4432.3618\n",
      "Epoch 420/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7357.6895 - val_loss: 4559.6196\n",
      "Epoch 421/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7425.6108 - val_loss: 4444.0703\n",
      "Epoch 422/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7176.5391 - val_loss: 4332.4067\n",
      "Epoch 423/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7092.7256 - val_loss: 4626.5830\n",
      "Epoch 424/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6796.0645 - val_loss: 4416.9624\n",
      "Epoch 425/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7172.6235 - val_loss: 4366.4663\n",
      "Epoch 426/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7100.3784 - val_loss: 4664.0732\n",
      "Epoch 427/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6810.3916 - val_loss: 4595.7422\n",
      "Epoch 428/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7275.3398 - val_loss: 4517.0229\n",
      "Epoch 429/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6812.5962 - val_loss: 4637.5068\n",
      "Epoch 430/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7328.5249 - val_loss: 4229.6865\n",
      "Epoch 431/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7138.0371 - val_loss: 4619.3770\n",
      "Epoch 432/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7237.4478 - val_loss: 4482.2432\n",
      "Epoch 433/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6998.1499 - val_loss: 4722.4409\n",
      "Epoch 434/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7030.8472 - val_loss: 4679.8740\n",
      "Epoch 435/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6573.4287 - val_loss: 4315.7944\n",
      "Epoch 436/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7254.6899 - val_loss: 4593.3120\n",
      "Epoch 437/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7086.5664 - val_loss: 4627.4209\n",
      "Epoch 438/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7325.0435 - val_loss: 4542.6816\n",
      "Epoch 439/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7250.3608 - val_loss: 4475.6860\n",
      "Epoch 440/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6983.8623 - val_loss: 4516.3628\n",
      "Epoch 441/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6833.6455 - val_loss: 4559.8301\n",
      "Epoch 442/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7055.2529 - val_loss: 4562.7124\n",
      "Epoch 443/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7320.2944 - val_loss: 4606.8374\n",
      "Epoch 444/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7079.3721 - val_loss: 4639.5127\n",
      "Epoch 445/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7017.2651 - val_loss: 4632.0044\n",
      "Epoch 446/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7168.6851 - val_loss: 4526.6060\n",
      "Epoch 447/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7598.7598 - val_loss: 4556.2573\n",
      "Epoch 448/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6846.0273 - val_loss: 4643.3037\n",
      "Epoch 449/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7108.9521 - val_loss: 4565.5317\n",
      "Epoch 450/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6570.3223 - val_loss: 5082.7373\n",
      "Epoch 451/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7037.9902 - val_loss: 4696.8862\n",
      "Epoch 452/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7166.2109 - val_loss: 4679.8394\n",
      "Epoch 453/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6909.4966 - val_loss: 4703.1475\n",
      "Epoch 454/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7137.8198 - val_loss: 4736.7114\n",
      "Epoch 455/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7165.3828 - val_loss: 4554.2769\n",
      "Epoch 456/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7031.6216 - val_loss: 4759.0186\n",
      "Epoch 457/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6926.5342 - val_loss: 4763.3765\n",
      "Epoch 458/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6722.9565 - val_loss: 4698.2305\n",
      "Epoch 459/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6931.1816 - val_loss: 4799.9995\n",
      "Epoch 460/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7372.6431 - val_loss: 4675.0518\n",
      "Epoch 461/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6999.6631 - val_loss: 4826.0435\n",
      "Epoch 462/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6691.0034 - val_loss: 4858.3311\n",
      "Epoch 463/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7269.1094 - val_loss: 4654.1147\n",
      "Epoch 464/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6830.0859 - val_loss: 4839.8042\n",
      "Epoch 465/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7236.4858 - val_loss: 4958.5840\n",
      "Epoch 466/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7463.0078 - val_loss: 4711.8330\n",
      "Epoch 467/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7365.0776 - val_loss: 5052.6123\n",
      "Epoch 468/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6791.4150 - val_loss: 4975.2666\n",
      "Epoch 469/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7042.6816 - val_loss: 5080.5581\n",
      "Epoch 470/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6569.3545 - val_loss: 4793.1597\n",
      "Epoch 471/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7039.2607 - val_loss: 4772.4404\n",
      "Epoch 472/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7082.8022 - val_loss: 4640.8389\n",
      "Epoch 473/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6829.7598 - val_loss: 5153.1445\n",
      "Epoch 474/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6933.0723 - val_loss: 4831.3604\n",
      "Epoch 475/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7000.0288 - val_loss: 4701.5044\n",
      "Epoch 476/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6609.2300 - val_loss: 5082.5386\n",
      "Epoch 477/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6514.7915 - val_loss: 4894.1895\n",
      "Epoch 478/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6764.4434 - val_loss: 5122.6509\n",
      "Epoch 479/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6825.9131 - val_loss: 4675.3657\n",
      "Epoch 480/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6527.3857 - val_loss: 5065.6577\n",
      "Epoch 481/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6499.0737 - val_loss: 4977.3320\n",
      "Epoch 482/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7284.3428 - val_loss: 4761.5781\n",
      "Epoch 483/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6931.8457 - val_loss: 5164.4126\n",
      "Epoch 484/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6414.8916 - val_loss: 5213.4810\n",
      "Epoch 485/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6887.4800 - val_loss: 4831.6323\n",
      "Epoch 486/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6815.3887 - val_loss: 5223.7729\n",
      "Epoch 487/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6421.9902 - val_loss: 5221.6973\n",
      "Epoch 488/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6629.2651 - val_loss: 4821.3540\n",
      "Epoch 489/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7120.5791 - val_loss: 5209.1665\n",
      "Epoch 490/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6529.9873 - val_loss: 4968.4937\n",
      "Epoch 491/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6861.7422 - val_loss: 5234.2803\n",
      "Epoch 492/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6792.2495 - val_loss: 4951.0913\n",
      "Epoch 493/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6931.8940 - val_loss: 5242.6089\n",
      "Epoch 494/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6832.5059 - val_loss: 5051.2979\n",
      "Epoch 495/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6688.8398 - val_loss: 5083.9824\n",
      "Epoch 496/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7181.4780 - val_loss: 5096.0444\n",
      "Epoch 497/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6711.6108 - val_loss: 5041.2734\n",
      "Epoch 498/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6881.7573 - val_loss: 4919.4829\n",
      "Epoch 499/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6998.6865 - val_loss: 5132.0889\n",
      "Epoch 500/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6823.9023 - val_loss: 5297.7861\n",
      "Epoch 501/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6299.3350 - val_loss: 5078.4189\n",
      "Epoch 502/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6560.7778 - val_loss: 5306.1792\n",
      "Epoch 503/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7154.9043 - val_loss: 5111.8335\n",
      "Epoch 504/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6197.9893 - val_loss: 5146.1440\n",
      "Epoch 505/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6911.3076 - val_loss: 5291.8096\n",
      "Epoch 506/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6258.8628 - val_loss: 5029.8862\n",
      "Epoch 507/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6778.0977 - val_loss: 5279.2070\n",
      "Epoch 508/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6459.0879 - val_loss: 4920.2925\n",
      "Epoch 509/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6812.4907 - val_loss: 5405.6216\n",
      "Epoch 510/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6436.1748 - val_loss: 4738.9277\n",
      "Epoch 511/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6924.7598 - val_loss: 5463.6147\n",
      "Epoch 512/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6602.9170 - val_loss: 5139.2144\n",
      "Epoch 513/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6122.8306 - val_loss: 5207.1426\n",
      "Epoch 514/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6410.8350 - val_loss: 5007.2915\n",
      "Epoch 515/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6723.5894 - val_loss: 5252.2358\n",
      "Epoch 516/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6698.9229 - val_loss: 5254.5898\n",
      "Epoch 517/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6492.4785 - val_loss: 5253.3848\n",
      "Epoch 518/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6681.3184 - val_loss: 5306.1450\n",
      "Epoch 519/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6768.3594 - val_loss: 5295.9966\n",
      "Epoch 520/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6573.2158 - val_loss: 5017.3213\n",
      "Epoch 521/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6143.5483 - val_loss: 5285.6240\n",
      "Epoch 522/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6763.4458 - val_loss: 5460.2920\n",
      "Epoch 523/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6685.7744 - val_loss: 5109.5171\n",
      "Epoch 524/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6633.7188 - val_loss: 5356.0913\n",
      "Epoch 525/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6571.1685 - val_loss: 5377.4385\n",
      "Epoch 526/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6562.1455 - val_loss: 5223.4883\n",
      "Epoch 527/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6301.9326 - val_loss: 5139.6914\n",
      "Epoch 528/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6518.3135 - val_loss: 5419.2944\n",
      "Epoch 529/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6052.6973 - val_loss: 5432.1055\n",
      "Epoch 530/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6604.2681 - val_loss: 5728.5522\n",
      "Epoch 531/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6240.8745 - val_loss: 5156.3877\n",
      "Epoch 532/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6853.9556 - val_loss: 5268.8271\n",
      "Epoch 533/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6585.4702 - val_loss: 5832.3989\n",
      "Epoch 534/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6439.9341 - val_loss: 5013.6299\n",
      "Epoch 535/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6629.6094 - val_loss: 4976.0894\n",
      "Epoch 536/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6424.2041 - val_loss: 5535.7344\n",
      "Epoch 537/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6368.7666 - val_loss: 5746.8418\n",
      "Epoch 538/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6325.1484 - val_loss: 5144.6948\n",
      "Epoch 539/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6792.1436 - val_loss: 5460.0527\n",
      "Epoch 540/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6559.1030 - val_loss: 5168.4648\n",
      "Epoch 541/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6628.5244 - val_loss: 5361.3311\n",
      "Epoch 542/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6623.2271 - val_loss: 5419.2031\n",
      "Epoch 543/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6830.5566 - val_loss: 5319.3774\n",
      "Epoch 544/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6308.6865 - val_loss: 5649.2070\n",
      "Epoch 545/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6896.1299 - val_loss: 5214.9219\n",
      "Epoch 546/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6483.2559 - val_loss: 5415.9683\n",
      "Epoch 547/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6486.1362 - val_loss: 5637.0234\n",
      "Epoch 548/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6297.7402 - val_loss: 5138.9336\n",
      "Epoch 549/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5803.2153 - val_loss: 5512.8252\n",
      "Epoch 550/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6172.4199 - val_loss: 5431.0542\n",
      "Epoch 551/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6281.7959 - val_loss: 5466.7524\n",
      "Epoch 552/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6331.7681 - val_loss: 5630.9702\n",
      "Epoch 553/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6209.7705 - val_loss: 5572.5723\n",
      "Epoch 554/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6447.1343 - val_loss: 5493.0327\n",
      "Epoch 555/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6418.5181 - val_loss: 5386.3286\n",
      "Epoch 556/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6630.1279 - val_loss: 5392.9536\n",
      "Epoch 557/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6520.2905 - val_loss: 5765.7817\n",
      "Epoch 558/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6325.2021 - val_loss: 5751.5063\n",
      "Epoch 559/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6506.2241 - val_loss: 5434.1108\n",
      "Epoch 560/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6577.1221 - val_loss: 5704.3721\n",
      "Epoch 561/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6653.2402 - val_loss: 5527.4180\n",
      "Epoch 562/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6483.2319 - val_loss: 5782.6460\n",
      "Epoch 563/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5818.0859 - val_loss: 5371.0889\n",
      "Epoch 564/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6464.7690 - val_loss: 5601.7573\n",
      "Epoch 565/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6361.0249 - val_loss: 5648.3223\n",
      "Epoch 566/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5967.3569 - val_loss: 5576.1968\n",
      "Epoch 567/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6588.9023 - val_loss: 5737.8281\n",
      "Epoch 568/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6530.5645 - val_loss: 5781.8750\n",
      "Epoch 569/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6296.7891 - val_loss: 5689.2744\n",
      "Epoch 570/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6457.2017 - val_loss: 5847.9082\n",
      "Epoch 571/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6540.4517 - val_loss: 5692.2188\n",
      "Epoch 572/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6572.6606 - val_loss: 5646.5513\n",
      "Epoch 573/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6519.0620 - val_loss: 5977.4390\n",
      "Epoch 574/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6358.8052 - val_loss: 5894.2358\n",
      "Epoch 575/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6071.5693 - val_loss: 5741.5400\n",
      "Epoch 576/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6184.2505 - val_loss: 5738.4761\n",
      "Epoch 577/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6144.6636 - val_loss: 5837.8750\n",
      "Epoch 578/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6322.9414 - val_loss: 5676.0835\n",
      "Epoch 579/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5961.3745 - val_loss: 6002.6870\n",
      "Epoch 580/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6379.3320 - val_loss: 5880.3550\n",
      "Epoch 581/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6337.1157 - val_loss: 5545.9463\n",
      "Epoch 582/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6340.9614 - val_loss: 5654.4556\n",
      "Epoch 583/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6253.1479 - val_loss: 5686.5317\n",
      "Epoch 584/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6225.1421 - val_loss: 5594.7163\n",
      "Epoch 585/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6247.4028 - val_loss: 6048.5815\n",
      "Epoch 586/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6328.8999 - val_loss: 5941.5156\n",
      "Epoch 587/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5923.1499 - val_loss: 5849.9976\n",
      "Epoch 588/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6469.6992 - val_loss: 5859.9399\n",
      "Epoch 589/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6017.6108 - val_loss: 5832.1802\n",
      "Epoch 590/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6376.2412 - val_loss: 5886.6685\n",
      "Epoch 591/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6247.8813 - val_loss: 6078.4829\n",
      "Epoch 592/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6156.5112 - val_loss: 5561.3760\n",
      "Epoch 593/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6728.1914 - val_loss: 6143.8203\n",
      "Epoch 594/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6339.1685 - val_loss: 6221.5396\n",
      "Epoch 595/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6120.4038 - val_loss: 5627.8096\n",
      "Epoch 596/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5888.6104 - val_loss: 5969.9707\n",
      "Epoch 597/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5697.8096 - val_loss: 5931.4844\n",
      "Epoch 598/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6216.3364 - val_loss: 6132.8652\n",
      "Epoch 599/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6182.7612 - val_loss: 5978.0737\n",
      "Epoch 600/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6488.9185 - val_loss: 5594.7065\n",
      "Epoch 601/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6452.3901 - val_loss: 6196.5386\n",
      "Epoch 602/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6450.2056 - val_loss: 5801.2090\n",
      "Epoch 603/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6040.9673 - val_loss: 5879.2144\n",
      "Epoch 604/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6170.2471 - val_loss: 6040.5044\n",
      "Epoch 605/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6351.8872 - val_loss: 6015.1040\n",
      "Epoch 606/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6647.4316 - val_loss: 5715.9521\n",
      "Epoch 607/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6042.1455 - val_loss: 6473.2812\n",
      "Epoch 608/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6060.8120 - val_loss: 5898.6509\n",
      "Epoch 609/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6166.3779 - val_loss: 6052.0371\n",
      "Epoch 610/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6425.1123 - val_loss: 5969.6274\n",
      "Epoch 611/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6069.3564 - val_loss: 6172.4438\n",
      "Epoch 612/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6066.7749 - val_loss: 6069.9312\n",
      "Epoch 613/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6363.6650 - val_loss: 6147.3965\n",
      "Epoch 614/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6456.7505 - val_loss: 5960.4126\n",
      "Epoch 615/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6227.8223 - val_loss: 6500.3818\n",
      "Epoch 616/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6217.4985 - val_loss: 6055.5610\n",
      "Epoch 617/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6136.1250 - val_loss: 5755.9990\n",
      "Epoch 618/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6520.2422 - val_loss: 6170.4556\n",
      "Epoch 619/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5772.8589 - val_loss: 6125.0024\n",
      "Epoch 620/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5631.5073 - val_loss: 5641.6167\n",
      "Epoch 621/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6371.8198 - val_loss: 6338.9258\n",
      "Epoch 622/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6446.9121 - val_loss: 6022.8169\n",
      "Epoch 623/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6637.8086 - val_loss: 6072.9668\n",
      "Epoch 624/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6018.6191 - val_loss: 5822.4824\n",
      "Epoch 625/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6229.4136 - val_loss: 6337.0801\n",
      "Epoch 626/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6228.8394 - val_loss: 5860.4844\n",
      "Epoch 627/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6108.4014 - val_loss: 6123.2598\n",
      "Epoch 628/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6042.5923 - val_loss: 5988.8057\n",
      "Epoch 629/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6275.9580 - val_loss: 6342.8042\n",
      "Epoch 630/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6376.2349 - val_loss: 6282.8901\n",
      "Epoch 631/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6295.4756 - val_loss: 6488.6519\n",
      "Epoch 632/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6042.2188 - val_loss: 6151.0396\n",
      "Epoch 633/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6129.6587 - val_loss: 6252.9048\n",
      "Epoch 634/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5987.5923 - val_loss: 6254.4751\n",
      "Epoch 635/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6352.3936 - val_loss: 6152.0127\n",
      "Epoch 636/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6312.8452 - val_loss: 6402.7324\n",
      "Epoch 637/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6062.8086 - val_loss: 6781.0415\n",
      "Epoch 638/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6276.0381 - val_loss: 6401.8115\n",
      "Epoch 639/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6066.6528 - val_loss: 6586.7983\n",
      "Epoch 640/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5703.9111 - val_loss: 6264.0913\n",
      "Epoch 641/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6093.9263 - val_loss: 6662.4995\n",
      "Epoch 642/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6131.3608 - val_loss: 6233.1885\n",
      "Epoch 643/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6146.0864 - val_loss: 6293.7231\n",
      "Epoch 644/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6105.3179 - val_loss: 6466.8555\n",
      "Epoch 645/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6063.7637 - val_loss: 6247.1392\n",
      "Epoch 646/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6321.6729 - val_loss: 6378.8984\n",
      "Epoch 647/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5677.8794 - val_loss: 6326.4390\n",
      "Epoch 648/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6137.4780 - val_loss: 6411.9434\n",
      "Epoch 649/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6564.8022 - val_loss: 6536.2817\n",
      "Epoch 650/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6511.0693 - val_loss: 5965.9565\n",
      "Epoch 651/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6037.2407 - val_loss: 6832.0542\n",
      "Epoch 652/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6249.9863 - val_loss: 6534.5752\n",
      "Epoch 653/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5719.8477 - val_loss: 6455.7715\n",
      "Epoch 654/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5981.1616 - val_loss: 6504.2285\n",
      "Epoch 655/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6030.5938 - val_loss: 6539.1226\n",
      "Epoch 656/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6283.5400 - val_loss: 6268.1177\n",
      "Epoch 657/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5919.7637 - val_loss: 6767.8374\n",
      "Epoch 658/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5794.2173 - val_loss: 6675.1147\n",
      "Epoch 659/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5970.2368 - val_loss: 6137.6924\n",
      "Epoch 660/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6115.2656 - val_loss: 6590.8984\n",
      "Epoch 661/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5972.9287 - val_loss: 6218.7285\n",
      "Epoch 662/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5958.5928 - val_loss: 6821.1777\n",
      "Epoch 663/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5824.9966 - val_loss: 6546.4688\n",
      "Epoch 664/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5469.5400 - val_loss: 6664.1465\n",
      "Epoch 665/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5923.1069 - val_loss: 6464.5039\n",
      "Epoch 666/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6522.2056 - val_loss: 6441.0000\n",
      "Epoch 667/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5997.9087 - val_loss: 6531.2202\n",
      "Epoch 668/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5737.1377 - val_loss: 6409.9316\n",
      "Epoch 669/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6163.0391 - val_loss: 6387.4712\n",
      "Epoch 670/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5961.0615 - val_loss: 6636.6777\n",
      "Epoch 671/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5891.4985 - val_loss: 6200.5820\n",
      "Epoch 672/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5777.8936 - val_loss: 6461.2192\n",
      "Epoch 673/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5919.6885 - val_loss: 6266.9204\n",
      "Epoch 674/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5541.6567 - val_loss: 6681.0234\n",
      "Epoch 675/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5738.5513 - val_loss: 6498.5840\n",
      "Epoch 676/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5946.7148 - val_loss: 6587.6602\n",
      "Epoch 677/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5932.5342 - val_loss: 6769.3184\n",
      "Epoch 678/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6009.1270 - val_loss: 6385.9907\n",
      "Epoch 679/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6200.1602 - val_loss: 6328.5376\n",
      "Epoch 680/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5596.9858 - val_loss: 6734.0356\n",
      "Epoch 681/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5780.8672 - val_loss: 6590.3921\n",
      "Epoch 682/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6191.6265 - val_loss: 6575.3291\n",
      "Epoch 683/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5759.1074 - val_loss: 6473.0024\n",
      "Epoch 684/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5954.3452 - val_loss: 6599.2871\n",
      "Epoch 685/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5792.2505 - val_loss: 6455.6064\n",
      "Epoch 686/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6040.8213 - val_loss: 6475.5991\n",
      "Epoch 687/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5999.3135 - val_loss: 6325.5078\n",
      "Epoch 688/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5959.4043 - val_loss: 6739.9155\n",
      "Epoch 689/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5713.6465 - val_loss: 6589.5796\n",
      "Epoch 690/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6373.9995 - val_loss: 6578.5044\n",
      "Epoch 691/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6207.3086 - val_loss: 6715.7007\n",
      "Epoch 692/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6414.4956 - val_loss: 6470.3018\n",
      "Epoch 693/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6031.6714 - val_loss: 6220.2876\n",
      "Epoch 694/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6379.6650 - val_loss: 6205.2686\n",
      "Epoch 695/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5907.4463 - val_loss: 6742.0957\n",
      "Epoch 696/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6151.5771 - val_loss: 6152.6572\n",
      "Epoch 697/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5826.0938 - val_loss: 6798.4507\n",
      "Epoch 698/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5851.2998 - val_loss: 6263.7354\n",
      "Epoch 699/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5786.7358 - val_loss: 6826.1909\n",
      "Epoch 700/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6073.1851 - val_loss: 6546.5239\n",
      "Epoch 701/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5857.5684 - val_loss: 6403.9019\n",
      "Epoch 702/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5781.7314 - val_loss: 6445.1172\n",
      "Epoch 703/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5815.3462 - val_loss: 6592.6133\n",
      "Epoch 704/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5860.4458 - val_loss: 6371.3057\n",
      "Epoch 705/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5935.2417 - val_loss: 6744.5815\n",
      "Epoch 706/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6181.9121 - val_loss: 6661.0205\n",
      "Epoch 707/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5768.6538 - val_loss: 6589.8833\n",
      "Epoch 708/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5853.8096 - val_loss: 6649.0688\n",
      "Epoch 709/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5897.6440 - val_loss: 6545.3218\n",
      "Epoch 710/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6020.4644 - val_loss: 6992.0010\n",
      "Epoch 711/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5761.8179 - val_loss: 6515.1606\n",
      "Epoch 712/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6081.3091 - val_loss: 6766.0293\n",
      "Epoch 713/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5730.1064 - val_loss: 6662.7002\n",
      "Epoch 714/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5875.4067 - val_loss: 6532.5220\n",
      "Epoch 715/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6126.8184 - val_loss: 6390.3677\n",
      "Epoch 716/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5800.0220 - val_loss: 6453.8755\n",
      "Epoch 717/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6073.3379 - val_loss: 6432.1001\n",
      "Epoch 718/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6111.2856 - val_loss: 6701.9614\n",
      "Epoch 719/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5838.6870 - val_loss: 6896.4092\n",
      "Epoch 720/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5986.0566 - val_loss: 6496.0562\n",
      "Epoch 721/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5958.7559 - val_loss: 6952.5132\n",
      "Epoch 722/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5693.9531 - val_loss: 6848.4722\n",
      "Epoch 723/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6110.9609 - val_loss: 6798.7119\n",
      "Epoch 724/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5864.1045 - val_loss: 7033.7510\n",
      "Epoch 725/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6024.9150 - val_loss: 6873.2930\n",
      "Epoch 726/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5949.6641 - val_loss: 6987.6455\n",
      "Epoch 727/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6055.0928 - val_loss: 7162.9668\n",
      "Epoch 728/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5887.7681 - val_loss: 6601.3936\n",
      "Epoch 729/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5989.7026 - val_loss: 6832.3247\n",
      "Epoch 730/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5845.2070 - val_loss: 6773.3584\n",
      "Epoch 731/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5989.3306 - val_loss: 6982.9287\n",
      "Epoch 732/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5763.3423 - val_loss: 6873.2466\n",
      "Epoch 733/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5967.2554 - val_loss: 6761.9067\n",
      "Epoch 734/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6137.6758 - val_loss: 7005.7910\n",
      "Epoch 735/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5635.2246 - val_loss: 6952.5894\n",
      "Epoch 736/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5889.8711 - val_loss: 6330.0562\n",
      "Epoch 737/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6101.7100 - val_loss: 6945.6323\n",
      "Epoch 738/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5639.1763 - val_loss: 6795.1426\n",
      "Epoch 739/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5546.8574 - val_loss: 6783.0132\n",
      "Epoch 740/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5822.8228 - val_loss: 6730.1279\n",
      "Epoch 741/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6248.1245 - val_loss: 6849.5400\n",
      "Epoch 742/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6320.0728 - val_loss: 7113.6094\n",
      "Epoch 743/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5810.1025 - val_loss: 6832.3921\n",
      "Epoch 744/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6082.0522 - val_loss: 7207.5576\n",
      "Epoch 745/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6035.8936 - val_loss: 6832.0732\n",
      "Epoch 746/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5750.5776 - val_loss: 7149.6748\n",
      "Epoch 747/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6139.3276 - val_loss: 6917.1919\n",
      "Epoch 748/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5729.9702 - val_loss: 6688.9360\n",
      "Epoch 749/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5770.5439 - val_loss: 6753.7231\n",
      "Epoch 750/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6102.8779 - val_loss: 6922.4429\n",
      "Epoch 751/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5690.2549 - val_loss: 6631.5493\n",
      "Epoch 752/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5689.0713 - val_loss: 6852.6406\n",
      "Epoch 753/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5364.6016 - val_loss: 6977.5708\n",
      "Epoch 754/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5880.9497 - val_loss: 6940.3022\n",
      "Epoch 755/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5750.8794 - val_loss: 6750.3633\n",
      "Epoch 756/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5666.2441 - val_loss: 7264.8418\n",
      "Epoch 757/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5830.1797 - val_loss: 6529.4248\n",
      "Epoch 758/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6152.3687 - val_loss: 7207.5767\n",
      "Epoch 759/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5889.9497 - val_loss: 6726.3711\n",
      "Epoch 760/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5838.9014 - val_loss: 6735.0532\n",
      "Epoch 761/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5749.5059 - val_loss: 7061.6040\n",
      "Epoch 762/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5867.0781 - val_loss: 7082.2656\n",
      "Epoch 763/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5798.2842 - val_loss: 6814.1172\n",
      "Epoch 764/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5387.5801 - val_loss: 6632.4873\n",
      "Epoch 765/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5527.0059 - val_loss: 6955.2788\n",
      "Epoch 766/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5720.4419 - val_loss: 6893.2471\n",
      "Epoch 767/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5911.1221 - val_loss: 6896.0542\n",
      "Epoch 768/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5753.0474 - val_loss: 6613.7866\n",
      "Epoch 769/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6045.9595 - val_loss: 6706.2607\n",
      "Epoch 770/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5945.7227 - val_loss: 7085.3843\n",
      "Epoch 771/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6019.8091 - val_loss: 7021.7939\n",
      "Epoch 772/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5722.4766 - val_loss: 7184.5459\n",
      "Epoch 773/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5749.0522 - val_loss: 6943.2744\n",
      "Epoch 774/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5729.4653 - val_loss: 6883.5908\n",
      "Epoch 775/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5494.9824 - val_loss: 7006.3882\n",
      "Epoch 776/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5381.1260 - val_loss: 6703.6235\n",
      "Epoch 777/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5730.3462 - val_loss: 7216.7432\n",
      "Epoch 778/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5764.4849 - val_loss: 6567.6870\n",
      "Epoch 779/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5766.5142 - val_loss: 7222.3794\n",
      "Epoch 780/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5639.1763 - val_loss: 6707.9609\n",
      "Epoch 781/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5589.2319 - val_loss: 6982.7627\n",
      "Epoch 782/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5826.3525 - val_loss: 6717.5654\n",
      "Epoch 783/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5998.7778 - val_loss: 6818.8120\n",
      "Epoch 784/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5636.3579 - val_loss: 6863.2715\n",
      "Epoch 785/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5607.8638 - val_loss: 6762.5366\n",
      "Epoch 786/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5726.0142 - val_loss: 7054.6709\n",
      "Epoch 787/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5632.8047 - val_loss: 7309.4307\n",
      "Epoch 788/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5335.6865 - val_loss: 6854.9106\n",
      "Epoch 789/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5899.7656 - val_loss: 6759.2817\n",
      "Epoch 790/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5779.4941 - val_loss: 6833.0259\n",
      "Epoch 791/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5808.9971 - val_loss: 6948.5552\n",
      "Epoch 792/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6020.6177 - val_loss: 6719.6992\n",
      "Epoch 793/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5929.4141 - val_loss: 6932.3823\n",
      "Epoch 794/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5481.8389 - val_loss: 6612.0356\n",
      "Epoch 795/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5904.9395 - val_loss: 7274.5742\n",
      "Epoch 796/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5478.3345 - val_loss: 6917.4741\n",
      "Epoch 797/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6219.4243 - val_loss: 6901.5215\n",
      "Epoch 798/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5891.1528 - val_loss: 6891.7422\n",
      "Epoch 799/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5650.3179 - val_loss: 6722.3853\n",
      "Epoch 800/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5629.7295 - val_loss: 6952.7979\n",
      "Epoch 801/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5713.5098 - val_loss: 6629.3760\n",
      "Epoch 802/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5662.5327 - val_loss: 6775.7090\n",
      "Epoch 803/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5963.3950 - val_loss: 7075.1982\n",
      "Epoch 804/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5922.3218 - val_loss: 6774.3267\n",
      "Epoch 805/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5902.3584 - val_loss: 7121.5249\n",
      "Epoch 806/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5754.4434 - val_loss: 7023.0469\n",
      "Epoch 807/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5518.5640 - val_loss: 7024.9351\n",
      "Epoch 808/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5508.8818 - val_loss: 7181.3008\n",
      "Epoch 809/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5698.6562 - val_loss: 7305.3667\n",
      "Epoch 810/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6039.4912 - val_loss: 7051.2915\n",
      "Epoch 811/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5506.9448 - val_loss: 7220.7476\n",
      "Epoch 812/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5587.9106 - val_loss: 7173.7598\n",
      "Epoch 813/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6025.8662 - val_loss: 6982.1235\n",
      "Epoch 814/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5562.0859 - val_loss: 7325.8984\n",
      "Epoch 815/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5397.5356 - val_loss: 7237.0269\n",
      "Epoch 816/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5367.1040 - val_loss: 6939.5635\n",
      "Epoch 817/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5704.0352 - val_loss: 7069.7666\n",
      "Epoch 818/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6145.9263 - val_loss: 7128.6758\n",
      "Epoch 819/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5695.9604 - val_loss: 7122.3608\n",
      "Epoch 820/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5754.6660 - val_loss: 6943.3740\n",
      "Epoch 821/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5913.2627 - val_loss: 7493.3760\n",
      "Epoch 822/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5833.2148 - val_loss: 7078.7651\n",
      "Epoch 823/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5884.3887 - val_loss: 7102.8574\n",
      "Epoch 824/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5812.5225 - val_loss: 7369.1157\n",
      "Epoch 825/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5605.2681 - val_loss: 7119.6343\n",
      "Epoch 826/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6004.2188 - val_loss: 6931.8633\n",
      "Epoch 827/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5580.2505 - val_loss: 7362.3149\n",
      "Epoch 828/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5585.5952 - val_loss: 6976.9600\n",
      "Epoch 829/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5323.6724 - val_loss: 7520.4136\n",
      "Epoch 830/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6052.7788 - val_loss: 6641.5601\n",
      "Epoch 831/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5906.9126 - val_loss: 6987.3945\n",
      "Epoch 832/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6099.0371 - val_loss: 6827.4731\n",
      "Epoch 833/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5545.4365 - val_loss: 7096.3657\n",
      "Epoch 834/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5640.4795 - val_loss: 7263.3535\n",
      "Epoch 835/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5811.5723 - val_loss: 7568.2349\n",
      "Epoch 836/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5700.1206 - val_loss: 7271.1660\n",
      "Epoch 837/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5871.9688 - val_loss: 6876.7544\n",
      "Epoch 838/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5616.0669 - val_loss: 6781.0527\n",
      "Epoch 839/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6047.0034 - val_loss: 7224.1333\n",
      "Epoch 840/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5707.4595 - val_loss: 7083.1675\n",
      "Epoch 841/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5578.8481 - val_loss: 6861.5425\n",
      "Epoch 842/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5597.7295 - val_loss: 7346.6860\n",
      "Epoch 843/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5673.5254 - val_loss: 7123.3501\n",
      "Epoch 844/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5853.9556 - val_loss: 6964.1348\n",
      "Epoch 845/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5650.0845 - val_loss: 7136.4019\n",
      "Epoch 846/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5818.6992 - val_loss: 7241.8960\n",
      "Epoch 847/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5645.6431 - val_loss: 7167.7832\n",
      "Epoch 848/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5607.8247 - val_loss: 7463.7041\n",
      "Epoch 849/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5681.7153 - val_loss: 6831.1685\n",
      "Epoch 850/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5807.2495 - val_loss: 7307.5952\n",
      "Epoch 851/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5440.4336 - val_loss: 7215.3281\n",
      "Epoch 852/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5450.1465 - val_loss: 7024.9106\n",
      "Epoch 853/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6049.0044 - val_loss: 6791.3901\n",
      "Epoch 854/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5502.8188 - val_loss: 7323.3433\n",
      "Epoch 855/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5885.2700 - val_loss: 6899.0327\n",
      "Epoch 856/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5751.4385 - val_loss: 7383.3184\n",
      "Epoch 857/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5752.5454 - val_loss: 7140.9766\n",
      "Epoch 858/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5694.4810 - val_loss: 7058.4419\n",
      "Epoch 859/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5593.8540 - val_loss: 7627.3223\n",
      "Epoch 860/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5768.5112 - val_loss: 7198.1426\n",
      "Epoch 861/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5542.7695 - val_loss: 7392.2432\n",
      "Epoch 862/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5527.5562 - val_loss: 7121.9409\n",
      "Epoch 863/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5469.7310 - val_loss: 6841.2734\n",
      "Epoch 864/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5679.8970 - val_loss: 7167.8867\n",
      "Epoch 865/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5510.8755 - val_loss: 6844.5005\n",
      "Epoch 866/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5758.0718 - val_loss: 7091.6064\n",
      "Epoch 867/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5406.2212 - val_loss: 7003.7485\n",
      "Epoch 868/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5926.4946 - val_loss: 7059.4375\n",
      "Epoch 869/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5833.2080 - val_loss: 7440.7031\n",
      "Epoch 870/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5606.8008 - val_loss: 7386.9834\n",
      "Epoch 871/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5428.8579 - val_loss: 7053.6294\n",
      "Epoch 872/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5841.0347 - val_loss: 7481.2891\n",
      "Epoch 873/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5607.0698 - val_loss: 7066.5352\n",
      "Epoch 874/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5563.9536 - val_loss: 7108.3452\n",
      "Epoch 875/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5702.6211 - val_loss: 6855.7715\n",
      "Epoch 876/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5824.8354 - val_loss: 6748.8989\n",
      "Epoch 877/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5772.8198 - val_loss: 6839.6577\n",
      "Epoch 878/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5428.5391 - val_loss: 6617.7466\n",
      "Epoch 879/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5450.4888 - val_loss: 6861.8813\n",
      "Epoch 880/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5830.4707 - val_loss: 7403.0259\n",
      "Epoch 881/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5691.3652 - val_loss: 7146.5015\n",
      "Epoch 882/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5735.0752 - val_loss: 7305.0542\n",
      "Epoch 883/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5247.5586 - val_loss: 7138.1909\n",
      "Epoch 884/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5543.7402 - val_loss: 7010.0376\n",
      "Epoch 885/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5940.1802 - val_loss: 7372.3511\n",
      "Epoch 886/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5393.0312 - val_loss: 7371.6685\n",
      "Epoch 887/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5619.9526 - val_loss: 7508.1177\n",
      "Epoch 888/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5701.2500 - val_loss: 7489.0386\n",
      "Epoch 889/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5537.6602 - val_loss: 6960.7842\n",
      "Epoch 890/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5381.5630 - val_loss: 7144.4331\n",
      "Epoch 891/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5502.9819 - val_loss: 7562.1968\n",
      "Epoch 892/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5485.2417 - val_loss: 6810.5898\n",
      "Epoch 893/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5904.2935 - val_loss: 7283.8423\n",
      "Epoch 894/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5731.3740 - val_loss: 7089.0493\n",
      "Epoch 895/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5986.9814 - val_loss: 7321.8159\n",
      "Epoch 896/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5259.2480 - val_loss: 7181.2051\n",
      "Epoch 897/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5632.5903 - val_loss: 7403.8774\n",
      "Epoch 898/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5486.2217 - val_loss: 6959.3320\n",
      "Epoch 899/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5615.2783 - val_loss: 7510.8892\n",
      "Epoch 900/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5614.6973 - val_loss: 6982.4517\n",
      "Epoch 901/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5952.2134 - val_loss: 7414.4233\n",
      "Epoch 902/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5415.3159 - val_loss: 7220.2158\n",
      "Epoch 903/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5515.5991 - val_loss: 6576.8511\n",
      "Epoch 904/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5506.5308 - val_loss: 7435.5176\n",
      "Epoch 905/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5552.8926 - val_loss: 7013.0376\n",
      "Epoch 906/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5548.8130 - val_loss: 7262.2476\n",
      "Epoch 907/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5550.4219 - val_loss: 7304.8901\n",
      "Epoch 908/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5627.8359 - val_loss: 7042.6118\n",
      "Epoch 909/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5456.3970 - val_loss: 7011.4517\n",
      "Epoch 910/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5589.9800 - val_loss: 7062.9468\n",
      "Epoch 911/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5534.2212 - val_loss: 6943.1162\n",
      "Epoch 912/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5576.8013 - val_loss: 6841.1982\n",
      "Epoch 913/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5439.4277 - val_loss: 7106.9849\n",
      "Epoch 914/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5765.1641 - val_loss: 7061.7334\n",
      "Epoch 915/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5605.3760 - val_loss: 6510.4429\n",
      "Epoch 916/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5521.9888 - val_loss: 6848.9858\n",
      "Epoch 917/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5738.0977 - val_loss: 7126.8335\n",
      "Epoch 918/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5413.7051 - val_loss: 6808.6187\n",
      "Epoch 919/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5882.9873 - val_loss: 7311.5073\n",
      "Epoch 920/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5579.4360 - val_loss: 6455.5215\n",
      "Epoch 921/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5570.5537 - val_loss: 6691.1450\n",
      "Epoch 922/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5623.1006 - val_loss: 7047.4751\n",
      "Epoch 923/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5624.5884 - val_loss: 7159.6665\n",
      "Epoch 924/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5692.7974 - val_loss: 6770.5142\n",
      "Epoch 925/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5670.8179 - val_loss: 6745.8633\n",
      "Epoch 926/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5736.9248 - val_loss: 7343.2300\n",
      "Epoch 927/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5657.5967 - val_loss: 7152.1084\n",
      "Epoch 928/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5631.0278 - val_loss: 7310.9790\n",
      "Epoch 929/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5483.9829 - val_loss: 7172.9150\n",
      "Epoch 930/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5560.1558 - val_loss: 7262.3667\n",
      "Epoch 931/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5420.2280 - val_loss: 7603.8359\n",
      "Epoch 932/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5562.9199 - val_loss: 7797.3267\n",
      "Epoch 933/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5471.2202 - val_loss: 7210.2441\n",
      "Epoch 934/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5572.3594 - val_loss: 7409.9585\n",
      "Epoch 935/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5662.3452 - val_loss: 7120.1094\n",
      "Epoch 936/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5602.6338 - val_loss: 7719.9458\n",
      "Epoch 937/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5537.6870 - val_loss: 6658.5205\n",
      "Epoch 938/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5616.1807 - val_loss: 7423.2900\n",
      "Epoch 939/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5614.8242 - val_loss: 7084.3999\n",
      "Epoch 940/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5887.9321 - val_loss: 7692.8867\n",
      "Epoch 941/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5500.3105 - val_loss: 7238.6348\n",
      "Epoch 942/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5689.4067 - val_loss: 7124.7300\n",
      "Epoch 943/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5693.5356 - val_loss: 6876.6143\n",
      "Epoch 944/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5815.4067 - val_loss: 7417.8193\n",
      "Epoch 945/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5479.0234 - val_loss: 7362.2285\n",
      "Epoch 946/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5431.5586 - val_loss: 7409.0864\n",
      "Epoch 947/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5696.2007 - val_loss: 7711.3018\n",
      "Epoch 948/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5919.2749 - val_loss: 7583.1948\n",
      "Epoch 949/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5415.3379 - val_loss: 7269.7607\n",
      "Epoch 950/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5445.6157 - val_loss: 7338.2759\n",
      "Epoch 951/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5524.3223 - val_loss: 7421.4492\n",
      "Epoch 952/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5637.3345 - val_loss: 7802.8882\n",
      "Epoch 953/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5407.6123 - val_loss: 7498.5898\n",
      "Epoch 954/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5861.5977 - val_loss: 7049.1216\n",
      "Epoch 955/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5481.5918 - val_loss: 7017.4385\n",
      "Epoch 956/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5635.6006 - val_loss: 6993.0557\n",
      "Epoch 957/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5615.7344 - val_loss: 6831.6016\n",
      "Epoch 958/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5731.8828 - val_loss: 6940.5298\n",
      "Epoch 959/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5669.5439 - val_loss: 7577.6333\n",
      "Epoch 960/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5585.2114 - val_loss: 7087.6377\n",
      "Epoch 961/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5567.8936 - val_loss: 6875.0923\n",
      "Epoch 962/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5719.1694 - val_loss: 7142.1226\n",
      "Epoch 963/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5688.5845 - val_loss: 7197.8833\n",
      "Epoch 964/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5661.8516 - val_loss: 6959.5864\n",
      "Epoch 965/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5403.3560 - val_loss: 6704.4849\n",
      "Epoch 966/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5437.5913 - val_loss: 7257.8511\n",
      "Epoch 967/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5745.3311 - val_loss: 7167.9858\n",
      "Epoch 968/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5430.1831 - val_loss: 6641.7856\n",
      "Epoch 969/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5793.8970 - val_loss: 6576.1802\n",
      "Epoch 970/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5605.1484 - val_loss: 7645.9624\n",
      "Epoch 971/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5664.7227 - val_loss: 6940.5898\n",
      "Epoch 972/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5521.5244 - val_loss: 6539.7285\n",
      "Epoch 973/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5661.6538 - val_loss: 7316.0781\n",
      "Epoch 974/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5769.4722 - val_loss: 6169.8848\n",
      "Epoch 975/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5635.7007 - val_loss: 6843.2466\n",
      "Epoch 976/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5510.7075 - val_loss: 6203.9248\n",
      "Epoch 977/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5737.5869 - val_loss: 6414.1196\n",
      "Epoch 978/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5386.1992 - val_loss: 7027.0552\n",
      "Epoch 979/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5381.9229 - val_loss: 6676.9189\n",
      "Epoch 980/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5636.6211 - val_loss: 6382.7939\n",
      "Epoch 981/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5491.0869 - val_loss: 6624.8022\n",
      "Epoch 982/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5493.0225 - val_loss: 6734.2627\n",
      "Epoch 983/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5577.6274 - val_loss: 6843.8447\n",
      "Epoch 984/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5608.5552 - val_loss: 6837.3623\n",
      "Epoch 985/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5389.1455 - val_loss: 7303.0215\n",
      "Epoch 986/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5476.6606 - val_loss: 7112.3843\n",
      "Epoch 987/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5287.0791 - val_loss: 7217.0781\n",
      "Epoch 988/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5548.4565 - val_loss: 6914.3018\n",
      "Epoch 989/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5576.1665 - val_loss: 6599.9736\n",
      "Epoch 990/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5422.5381 - val_loss: 7051.0283\n",
      "Epoch 991/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5322.2896 - val_loss: 6600.9233\n",
      "Epoch 992/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5766.7534 - val_loss: 6795.3750\n",
      "Epoch 993/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5601.5674 - val_loss: 5994.1753\n",
      "Epoch 994/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5698.8057 - val_loss: 6735.3794\n",
      "Epoch 995/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5345.3623 - val_loss: 6860.2603\n",
      "Epoch 996/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5546.7720 - val_loss: 6916.5049\n",
      "Epoch 997/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5619.8716 - val_loss: 7316.6689\n",
      "Epoch 998/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5327.5776 - val_loss: 7134.5317\n",
      "Epoch 999/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5521.2188 - val_loss: 7318.5552\n",
      "Epoch 1000/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5736.5454 - val_loss: 7044.7314\n",
      "Epoch 1001/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5609.6655 - val_loss: 7245.0815\n",
      "Epoch 1002/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5471.9976 - val_loss: 6397.6265\n",
      "Epoch 1003/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5679.8892 - val_loss: 6779.5308\n",
      "Epoch 1004/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5501.8652 - val_loss: 6926.7759\n",
      "Epoch 1005/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5445.3237 - val_loss: 7211.1665\n",
      "Epoch 1006/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5354.5898 - val_loss: 7030.6777\n",
      "Epoch 1007/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5642.3203 - val_loss: 6925.2515\n",
      "Epoch 1008/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5409.0806 - val_loss: 7067.1919\n",
      "Epoch 1009/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5634.0220 - val_loss: 6681.4248\n",
      "Epoch 1010/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5439.0396 - val_loss: 6528.4902\n",
      "Epoch 1011/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5632.2065 - val_loss: 7082.4126\n",
      "Epoch 1012/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5641.0645 - val_loss: 6935.8057\n",
      "Epoch 1013/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5613.6763 - val_loss: 6606.4312\n",
      "Epoch 1014/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5425.6914 - val_loss: 6349.5879\n",
      "Epoch 1015/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5516.2866 - val_loss: 6935.6357\n",
      "Epoch 1016/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5285.2568 - val_loss: 6445.7432\n",
      "Epoch 1017/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5745.9731 - val_loss: 6999.5732\n",
      "Epoch 1018/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5449.0645 - val_loss: 6878.4976\n",
      "Epoch 1019/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5367.5977 - val_loss: 6756.8989\n",
      "Epoch 1020/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5604.5815 - val_loss: 7322.3760\n",
      "Epoch 1021/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5636.0562 - val_loss: 7185.8643\n",
      "Epoch 1022/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5841.9849 - val_loss: 7104.4360\n",
      "Epoch 1023/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5436.0625 - val_loss: 6997.0332\n",
      "Epoch 1024/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5604.5249 - val_loss: 6683.5664\n",
      "Epoch 1025/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5619.1323 - val_loss: 6820.8335\n",
      "Epoch 1026/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5691.5356 - val_loss: 6610.3511\n",
      "Epoch 1027/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5633.6323 - val_loss: 6777.9536\n",
      "Epoch 1028/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5450.1011 - val_loss: 6500.5073\n",
      "Epoch 1029/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5450.0708 - val_loss: 7070.6899\n",
      "Epoch 1030/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5535.5903 - val_loss: 7482.7451\n",
      "Epoch 1031/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5390.3076 - val_loss: 6962.6685\n",
      "Epoch 1032/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5463.4644 - val_loss: 6849.6489\n",
      "Epoch 1033/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5770.1274 - val_loss: 6458.2144\n",
      "Epoch 1034/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5490.6011 - val_loss: 7174.5190\n",
      "Epoch 1035/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5450.8218 - val_loss: 6727.5405\n",
      "Epoch 1036/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5447.4155 - val_loss: 7486.7041\n",
      "Epoch 1037/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5514.6587 - val_loss: 7443.7749\n",
      "Epoch 1038/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5729.2280 - val_loss: 6618.6943\n",
      "Epoch 1039/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5555.7441 - val_loss: 6892.0029\n",
      "Epoch 1040/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5462.0835 - val_loss: 6740.8706\n",
      "Epoch 1041/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5390.2026 - val_loss: 6622.8735\n",
      "Epoch 1042/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5610.1094 - val_loss: 6917.1528\n",
      "Epoch 1043/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5463.2441 - val_loss: 6772.0303\n",
      "Epoch 1044/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5414.9194 - val_loss: 6407.2544\n",
      "Epoch 1045/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5683.7725 - val_loss: 6142.2739\n",
      "Epoch 1046/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5418.6689 - val_loss: 6308.5356\n",
      "Epoch 1047/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5414.0391 - val_loss: 6316.1377\n",
      "Epoch 1048/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5650.8115 - val_loss: 6933.1948\n",
      "Epoch 1049/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5389.7437 - val_loss: 6298.4658\n",
      "Epoch 1050/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5484.3428 - val_loss: 5683.4438\n",
      "Epoch 1051/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5427.2202 - val_loss: 6234.4268\n",
      "Epoch 1052/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5620.8560 - val_loss: 7074.2358\n",
      "Epoch 1053/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5423.4961 - val_loss: 6746.2939\n",
      "Epoch 1054/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5727.9355 - val_loss: 6075.7998\n",
      "Epoch 1055/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5640.5850 - val_loss: 6836.0679\n",
      "Epoch 1056/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5433.7544 - val_loss: 6444.8906\n",
      "Epoch 1057/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5737.7568 - val_loss: 7907.5151\n",
      "Epoch 1058/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5567.4097 - val_loss: 6867.5483\n",
      "Epoch 1059/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5505.0605 - val_loss: 6765.3682\n",
      "Epoch 1060/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5490.7349 - val_loss: 7373.8101\n",
      "Epoch 1061/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5417.7476 - val_loss: 7783.2886\n",
      "Epoch 1062/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5371.3950 - val_loss: 7550.4175\n",
      "Epoch 1063/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5475.3271 - val_loss: 7208.6216\n",
      "Epoch 1064/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5383.0591 - val_loss: 7040.9360\n",
      "Epoch 1065/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5661.0049 - val_loss: 7008.1216\n",
      "Epoch 1066/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5298.6372 - val_loss: 6774.0376\n",
      "Epoch 1067/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5335.9912 - val_loss: 6682.9902\n",
      "Epoch 1068/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5416.9341 - val_loss: 7538.2949\n",
      "Epoch 1069/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5263.6709 - val_loss: 6518.5234\n",
      "Epoch 1070/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5473.9834 - val_loss: 6847.9077\n",
      "Epoch 1071/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5667.4556 - val_loss: 7300.2026\n",
      "Epoch 1072/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5655.2954 - val_loss: 6189.0122\n",
      "Epoch 1073/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5340.4995 - val_loss: 6782.5327\n",
      "Epoch 1074/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5301.6567 - val_loss: 7208.6636\n",
      "Epoch 1075/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5823.4448 - val_loss: 6644.1108\n",
      "Epoch 1076/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5478.4849 - val_loss: 6160.0005\n",
      "Epoch 1077/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5400.9111 - val_loss: 5815.0332\n",
      "Epoch 1078/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5530.8926 - val_loss: 6734.1201\n",
      "Epoch 1079/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5463.8628 - val_loss: 6622.9932\n",
      "Epoch 1080/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5584.4873 - val_loss: 5989.8760\n",
      "Epoch 1081/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5518.0791 - val_loss: 6813.4268\n",
      "Epoch 1082/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5589.7969 - val_loss: 6684.7080\n",
      "Epoch 1083/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5344.7749 - val_loss: 6721.5156\n",
      "Epoch 1084/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5398.6836 - val_loss: 6832.1860\n",
      "Epoch 1085/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5541.0205 - val_loss: 6655.7822\n",
      "Epoch 1086/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5364.8218 - val_loss: 6315.2070\n",
      "Epoch 1087/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5549.2949 - val_loss: 6639.3311\n",
      "Epoch 1088/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5361.4209 - val_loss: 6699.2998\n",
      "Epoch 1089/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5488.5142 - val_loss: 6665.0542\n",
      "Epoch 1090/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5439.8784 - val_loss: 7250.6191\n",
      "Epoch 1091/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5443.5791 - val_loss: 6693.7124\n",
      "Epoch 1092/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5431.6807 - val_loss: 6252.5317\n",
      "Epoch 1093/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5578.9258 - val_loss: 6563.4043\n",
      "Epoch 1094/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5663.5767 - val_loss: 7073.2231\n",
      "Epoch 1095/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5738.4170 - val_loss: 7522.2534\n",
      "Epoch 1096/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5293.5571 - val_loss: 6301.1450\n",
      "Epoch 1097/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5445.7017 - val_loss: 6802.5356\n",
      "Epoch 1098/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5227.0327 - val_loss: 6829.0186\n",
      "Epoch 1099/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5608.5786 - val_loss: 6694.0122\n",
      "Epoch 1100/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5318.1416 - val_loss: 6632.4150\n",
      "Epoch 1101/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5294.5591 - val_loss: 7149.2666\n",
      "Epoch 1102/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5695.5298 - val_loss: 7097.5186\n",
      "Epoch 1103/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5533.8911 - val_loss: 6834.2061\n",
      "Epoch 1104/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5222.1230 - val_loss: 6250.1646\n",
      "Epoch 1105/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5751.8555 - val_loss: 6519.1929\n",
      "Epoch 1106/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5471.3667 - val_loss: 7005.0981\n",
      "Epoch 1107/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5700.9644 - val_loss: 6702.6724\n",
      "Epoch 1108/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5385.0464 - val_loss: 6613.5322\n",
      "Epoch 1109/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5460.1089 - val_loss: 7055.0625\n",
      "Epoch 1110/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5355.6699 - val_loss: 6587.4697\n",
      "Epoch 1111/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5528.6514 - val_loss: 6507.0508\n",
      "Epoch 1112/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5554.0537 - val_loss: 6900.3423\n",
      "Epoch 1113/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5548.3813 - val_loss: 7088.0669\n",
      "Epoch 1114/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5496.7188 - val_loss: 6859.5024\n",
      "Epoch 1115/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5507.4858 - val_loss: 6215.3984\n",
      "Epoch 1116/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5446.2598 - val_loss: 6364.8428\n",
      "Epoch 1117/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5295.4673 - val_loss: 6473.8853\n",
      "Epoch 1118/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5460.5391 - val_loss: 6537.9844\n",
      "Epoch 1119/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5586.2344 - val_loss: 6367.4360\n",
      "Epoch 1120/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5259.1001 - val_loss: 6735.9980\n",
      "Epoch 1121/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5484.2598 - val_loss: 6884.9302\n",
      "Epoch 1122/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5337.5815 - val_loss: 7003.4175\n",
      "Epoch 1123/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5582.3623 - val_loss: 6583.9292\n",
      "Epoch 1124/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5563.7588 - val_loss: 6539.1636\n",
      "Epoch 1125/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5549.6548 - val_loss: 6642.6597\n",
      "Epoch 1126/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5555.5869 - val_loss: 6530.8970\n",
      "Epoch 1127/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5606.8516 - val_loss: 6533.4507\n",
      "Epoch 1128/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5434.7915 - val_loss: 6060.1265\n",
      "Epoch 1129/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5246.2837 - val_loss: 7071.0776\n",
      "Epoch 1130/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5545.0342 - val_loss: 6585.7861\n",
      "Epoch 1131/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5388.0435 - val_loss: 6729.7549\n",
      "Epoch 1132/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5697.7256 - val_loss: 6592.1030\n",
      "Epoch 1133/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5485.1484 - val_loss: 6517.0972\n",
      "Epoch 1134/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5390.2739 - val_loss: 6659.6265\n",
      "Epoch 1135/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5579.4932 - val_loss: 6666.0933\n",
      "Epoch 1136/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5417.8125 - val_loss: 6548.3428\n",
      "Epoch 1137/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5175.9473 - val_loss: 6889.2397\n",
      "Epoch 1138/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5543.3599 - val_loss: 6858.9507\n",
      "Epoch 1139/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5318.4795 - val_loss: 6737.1792\n",
      "Epoch 1140/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5294.1177 - val_loss: 7449.4565\n",
      "Epoch 1141/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5567.7690 - val_loss: 7271.1636\n",
      "Epoch 1142/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5508.2373 - val_loss: 7135.1016\n",
      "Epoch 1143/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5804.5352 - val_loss: 6416.9785\n",
      "Epoch 1144/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5542.9131 - val_loss: 6471.7349\n",
      "Epoch 1145/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5403.4116 - val_loss: 6272.1860\n",
      "Epoch 1146/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5518.8203 - val_loss: 6533.7861\n",
      "Epoch 1147/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5317.6108 - val_loss: 6200.8882\n",
      "Epoch 1148/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5650.6089 - val_loss: 6559.3555\n",
      "Epoch 1149/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5374.0547 - val_loss: 6982.7808\n",
      "Epoch 1150/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5426.7427 - val_loss: 6734.8550\n",
      "Epoch 1151/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5719.6069 - val_loss: 6454.1318\n",
      "Epoch 1152/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5409.1777 - val_loss: 7180.2700\n",
      "Epoch 1153/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5418.9404 - val_loss: 6792.5864\n",
      "Epoch 1154/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5252.6118 - val_loss: 6900.1094\n",
      "Epoch 1155/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5653.9785 - val_loss: 7154.4048\n",
      "Epoch 1156/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5316.1128 - val_loss: 7053.4292\n",
      "Epoch 1157/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5546.3672 - val_loss: 6325.4497\n",
      "Epoch 1158/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5428.2461 - val_loss: 6702.4160\n",
      "Epoch 1159/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5287.6768 - val_loss: 6455.1689\n",
      "Epoch 1160/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5315.1577 - val_loss: 6541.2969\n",
      "Epoch 1161/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5662.4126 - val_loss: 6163.6948\n",
      "Epoch 1162/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5716.7095 - val_loss: 6563.8110\n",
      "Epoch 1163/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5437.4639 - val_loss: 6413.2344\n",
      "Epoch 1164/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5381.9785 - val_loss: 6272.1694\n",
      "Epoch 1165/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5429.0547 - val_loss: 6435.0518\n",
      "Epoch 1166/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5350.0044 - val_loss: 5881.8589\n",
      "Epoch 1167/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5484.7607 - val_loss: 6627.2222\n",
      "Epoch 1168/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5322.0474 - val_loss: 6149.4302\n",
      "Epoch 1169/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5329.5190 - val_loss: 6527.0903\n",
      "Epoch 1170/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5390.5181 - val_loss: 6321.5962\n",
      "Epoch 1171/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5477.9272 - val_loss: 6407.8506\n",
      "Epoch 1172/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5378.2119 - val_loss: 6043.5776\n",
      "Epoch 1173/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5426.2988 - val_loss: 6648.1475\n",
      "Epoch 1174/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5431.1772 - val_loss: 6934.6235\n",
      "Epoch 1175/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5608.2363 - val_loss: 6518.0210\n",
      "Epoch 1176/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5552.9482 - val_loss: 6611.7544\n",
      "Epoch 1177/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5631.2397 - val_loss: 6388.9487\n",
      "Epoch 1178/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5465.1772 - val_loss: 6464.4219\n",
      "Epoch 1179/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5474.9087 - val_loss: 6710.8286\n",
      "Epoch 1180/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5474.8770 - val_loss: 6378.3091\n",
      "Epoch 1181/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5489.1821 - val_loss: 6143.3145\n",
      "Epoch 1182/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5314.3838 - val_loss: 6143.8213\n",
      "Epoch 1183/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5376.3052 - val_loss: 6473.9600\n",
      "Epoch 1184/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5420.2178 - val_loss: 6139.0513\n",
      "Epoch 1185/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5568.0298 - val_loss: 6361.0718\n",
      "Epoch 1186/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5440.3979 - val_loss: 6312.1802\n",
      "Epoch 1187/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5482.2822 - val_loss: 6471.5625\n",
      "Epoch 1188/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5142.8745 - val_loss: 5966.7393\n",
      "Epoch 1189/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5601.0376 - val_loss: 5846.8540\n",
      "Epoch 1190/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5542.9717 - val_loss: 6001.1724\n",
      "Epoch 1191/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5410.4048 - val_loss: 6050.5938\n",
      "Epoch 1192/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5408.2969 - val_loss: 6030.1045\n",
      "Epoch 1193/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5548.3906 - val_loss: 5781.8257\n",
      "Epoch 1194/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5314.4019 - val_loss: 5727.3906\n",
      "Epoch 1195/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5528.3359 - val_loss: 6183.2241\n",
      "Epoch 1196/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5471.0903 - val_loss: 6171.9810\n",
      "Epoch 1197/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5514.1562 - val_loss: 6044.3882\n",
      "Epoch 1198/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5547.9736 - val_loss: 5831.9028\n",
      "Epoch 1199/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5568.0796 - val_loss: 6023.6743\n",
      "Epoch 1200/1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5361.5195 - val_loss: 6238.7402\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2115776acc0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train/fit neural network with validation data\n",
    "# see the instructions on the train/test -split above on how to split the data correctly\n",
    "model.fit(x=X_train, y=y_train, epochs=1200, validation_data=(X_val, y_val), callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance and error metrics in order to see if the model trained and works well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's use pandas for this (easy code)\n",
    "# try to look if the model is actually training \n",
    "# => the error is going downwards\n",
    "# if using validation data, you get two lines\n",
    "# in this case, see if the lines follow a similar trend \n",
    "# (they don't always overlap with complex data, the trend is more important)\n",
    "loss_df = pd.DataFrame(model.history.history)\n",
    "loss_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since we used ModelCheckpoint, we have to load the best model version again at this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the model from last epoch with best epoch from training history\n",
    "from keras.models import load_model\n",
    "model = load_model(\"best_model_regression1_energybill_kt.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data evaluation:\n",
      "4505.677734375\n",
      "\n",
      "Train data evaluation:\n",
      "3796.324951171875\n"
     ]
    }
   ],
   "source": [
    "# compare the final model loss/evaluation values\n",
    "print(\"Test data evaluation:\")\n",
    "print(model.evaluate(X_test, y_test, verbose=0))\n",
    "print(\"\\nTrain data evaluation:\")\n",
    "print(model.evaluate(X_train, y_train, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test True Y</th>\n",
       "      <th>Model Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>473.820453</td>\n",
       "      <td>557.353760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>658.964880</td>\n",
       "      <td>610.162903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>590.081794</td>\n",
       "      <td>529.237610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>718.222564</td>\n",
       "      <td>693.517639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>711.345373</td>\n",
       "      <td>763.540344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>630.197137</td>\n",
       "      <td>604.624390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>425.077564</td>\n",
       "      <td>532.661194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>418.783248</td>\n",
       "      <td>360.073181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>382.628898</td>\n",
       "      <td>411.822723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>356.982347</td>\n",
       "      <td>436.175842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Test True Y  Model Predictions\n",
       "0     473.820453         557.353760\n",
       "1     658.964880         610.162903\n",
       "2     590.081794         529.237610\n",
       "3     718.222564         693.517639\n",
       "4     711.345373         763.540344\n",
       "..           ...                ...\n",
       "145   630.197137         604.624390\n",
       "146   425.077564         532.661194\n",
       "147   418.783248         360.073181\n",
       "148   382.628898         411.822723\n",
       "149   356.982347         436.175842\n",
       "\n",
       "[150 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get test predictions\n",
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "# reshape the data for easier comparison table\n",
    "test_predictions = pd.Series(test_predictions.reshape(len(y_test),))\n",
    "pred_df = pd.DataFrame(np.asarray(y_test), columns=['Test True Y'])\n",
    "pred_df = pd.concat([pred_df, test_predictions], axis=1)\n",
    "pred_df.columns = ['Test True Y', 'Model Predictions']\n",
    "\n",
    "# print the comparison table - true values vs. model predicted values\n",
    "# we can nicely see here how far off our model is in some cases\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Test True Y', ylabel='Model Predictions'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# these values follow a linear diagonal line = good predictions\n",
    "# we basically compare the predicted values \n",
    "# to true test values and see the differences\n",
    "sns.scatterplot(x='Test True Y', y='Model Predictions', data=pred_df)\n",
    "\n",
    "# looks pretty decent!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The metrics are way better this time! (Compare to the original version from lecture 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE\n",
      "58.03 $\n",
      "\n",
      "MSE\n",
      "4499.73 $^2\n",
      "\n",
      "RMSE:\n",
      "67.08 $\n",
      "\n",
      "R-squared:\n",
      "0.86\n",
      "\n",
      "Explained variance score:\n",
      "0.86\n"
     ]
    }
   ],
   "source": [
    "# MAE - Mean average error\n",
    "print(\"MAE\")\n",
    "print(round(metrics.mean_absolute_error(y_test, test_predictions), 2), \"$\")\n",
    "\n",
    "# MSE - Mean square error\n",
    "print(\"\\nMSE\")\n",
    "print(round(metrics.mean_squared_error(y_test, test_predictions), 2), \"$^2\")\n",
    "\n",
    "# RMSE - Root mean square error\n",
    "print('\\nRMSE:')\n",
    "print(round(np.sqrt(metrics.mean_squared_error(y_test, test_predictions)), 2), \"$\")\n",
    "\n",
    "# R-squared. 0 = the model descibes the dataset poorly\n",
    "# 1 = model describes the dataset perfectly\n",
    "print('\\nR-squared:')\n",
    "print(round(metrics.r2_score(y_test, test_predictions), 2))\n",
    "\n",
    "# Explained Variance Score => 0 = the model descibes the dataset poorly\n",
    "# 1 = model describes the dataset perfectly\n",
    "# high variance score = model is a good fit for the data \n",
    "# low variance score = model is not a good fit for the data\n",
    "# the higher the score, the model is more able to explain the variation in the data\n",
    "# if score is low, we might need more and better data\n",
    "print(\"\\nExplained variance score:\")\n",
    "print(round(metrics.explained_variance_score(y_test, test_predictions), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From 109 RMSE  to ~64, quite decent optimization, even though there is still room for improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tuomas.valtanen\\AppData\\Local\\Temp\\ipykernel_2440\\3124900743.py:5: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot((y_test - test_predictions))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# if the prediction distribution are far from normal distribution\n",
    "# then the model is not probably good enough\n",
    "# distplot is deprecating in future pandas-version\n",
    "# unfortunately, there's no exact alternative to do this plot at the moment\n",
    "sns.distplot((y_test - test_predictions))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['num_rooms', 'num_people', 'housearea', 'is_ac', 'is_tv', 'is_flat',\n",
       "       'ave_monthly_income', 'num_children', 'is_urban', 'amount_paid'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying the model in practice with new imaginary house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try with some new imaginary data\n",
    "# this example uses the student performance index score dataset\n",
    "# modify this as needed regarding your own dataset\n",
    "tester_row = {\n",
    "    'num_rooms': 7, \n",
    "    'num_people': 2, \n",
    "    'housearea': 350, \n",
    "    'is_ac': 0, \n",
    "    'is_tv': 0, \n",
    "    'is_flat': 0,\n",
    "    'ave_monthly_income': 1500, \n",
    "    'num_children': 0, \n",
    "    'is_urban': 0\n",
    "}\n",
    "\n",
    "# convert to pandas-format\n",
    "tester_row = pd.DataFrame([tester_row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\n",
      "Estimated energy bill for this house:\n",
      "$ 227.8\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "# get the prediction from the model and print out the result\n",
    "result = model.predict(tester_row)[0]\n",
    "\n",
    "print()\n",
    "print(f\"Estimated energy bill for this house:\")\n",
    "print(f\"$ {round(float(result[0]), 2)}\")\n",
    "print(\"----------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
