{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN for classification, example 1, mobile phone price class classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is experimentation with Keras Tuner, see details below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "# pip install tensorflow\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# THIS IS OPTIONAL, so you can comment out the following code\n",
    "# if you don't wish to remove randomness\n",
    "# you might want to lock down the random seed throughout,\n",
    "# so you we get same results every time (given we change nothing in the data afterwards)\n",
    "\n",
    "# random seed locking code original from ChatGPT => has been tested that it works\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Set a fixed seed value\n",
    "SEED = 9876543\n",
    "\n",
    "# 1. Set Python's built-in random module seed\n",
    "random.seed(SEED)\n",
    "\n",
    "# 2. Set NumPy random seed\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# 3. Set TensorFlow seed\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# 4. Set environment variables (affects some backend randomness)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "# Optional: control inter-op and intra-op parallelism for determinism\n",
    "# (can slightly slow down training, but improves reproducibility)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "df = pd.read_csv(\"mobilepricerangeclass.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>756</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>905</td>\n",
       "      <td>1988</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1263</td>\n",
       "      <td>1716</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1216</td>\n",
       "      <td>1786</td>\n",
       "      <td>2769</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1208</td>\n",
       "      <td>1212</td>\n",
       "      <td>1411</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n",
       "0            842     0          2.2         0   1       0           7    0.6   \n",
       "1           1021     1          0.5         1   0       1          53    0.7   \n",
       "2            563     1          0.5         1   2       1          41    0.9   \n",
       "3            615     1          2.5         0   0       0          10    0.8   \n",
       "4           1821     1          1.2         0  13       1          44    0.6   \n",
       "\n",
       "   mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n",
       "0        188        2  ...         20       756  2549     9     7         19   \n",
       "1        136        3  ...        905      1988  2631    17     3          7   \n",
       "2        145        5  ...       1263      1716  2603    11     2          9   \n",
       "3        131        6  ...       1216      1786  2769    16     8         11   \n",
       "4        141        2  ...       1208      1212  1411     8     2         15   \n",
       "\n",
       "   three_g  touch_screen  wifi  price_range  \n",
       "0        0             0     1            1  \n",
       "1        1             1     0            2  \n",
       "2        1             1     0            2  \n",
       "3        1             0     0            2  \n",
       "4        1             1     0            1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the column explanations here\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price_range\n",
       "1    500\n",
       "2    500\n",
       "3    500\n",
       "0    500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# even distribution along the target classes\n",
    "df['price_range'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let' remove some of the variables that are probably not extremely important in this dataset\n",
    "# NOTE! we didn't spend much time analyzing/optimizing these, this just an example\n",
    "# on how you can use correlation matrix, SelectKBest etc. to choose your variables\n",
    "removables = ['touch_screen', 'dual_sim', 'clock_speed', 'm_dep', 'three_g', 'four_g', 'wifi', 'blue']\n",
    "df = df.drop(removables, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's assign actual names for the price classes\n",
    "# so we have nicer metrics and results later (after training model)\n",
    "df['price_range'] = df['price_range'].replace({\n",
    "    0: \"1: Cheap\",\n",
    "    1: \"2: Avg-\",\n",
    "    2: \"3: Avg+\",\n",
    "    3: \"4: Expensive\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1: Cheap', '2: Avg-', '3: Avg+', '4: Expensive']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# everything else except the target variable\n",
    "X = df.drop(\"price_range\", axis=1)\n",
    "\n",
    "# have only the target variable here (dependent variable)\n",
    "y_temp = df['price_range']\n",
    "\n",
    "# since we are doing classification, we have to process our target values with an encoder\n",
    "# and convert them into a categorical TensorFlow/Keras -format \n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y_temp)\n",
    "\n",
    "# Converting the label into a matrix form\n",
    "y = tf.keras.utils.to_categorical(y_enc)\n",
    "\n",
    "# save the categories into a helper list for later purposes\n",
    "categories = list(le.classes_)\n",
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train/test/validation -split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this time, let's split the data into 65% (training data) and 35% (temporary data)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.35)\n",
    "\n",
    "# step 2, split the temporary data in HALF (0.5) => 17.5% test and 17.5% validation\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USE KERAS TUNER TO FIND OPTIMAL PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8 Complete [00h 01m 43s]\n",
      "val_accuracy: 0.930476168791453\n",
      "\n",
      "Best val_accuracy So Far: 0.9828571478525797\n",
      "Total elapsed time: 00h 12m 52s\n"
     ]
    }
   ],
   "source": [
    "# pip install keras-tuner\n",
    "import keras_tuner\n",
    "\n",
    "def build_model(hp):\n",
    "    # iniatlize sequential test neural network\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # first layer, batch normalization + input shape, same as in typical neural network\n",
    "    model.add(layers.BatchNormalization(input_shape=(len(X.columns),)),)\n",
    "    \n",
    "    # add the first actual layer including the regularizer\n",
    "    model.add(\n",
    "        layers.Dense(\n",
    "            # Tune number of units separately.\n",
    "            units=hp.Int(f\"units_0\", min_value=4, max_value=96, step=4),\n",
    "            activation=hp.Choice(\"activation\", [\"relu\"]),\n",
    "            kernel_regularizer=keras.regularizers.l1(hp.Float(\"l1\", min_value=0.025, max_value=0.35, sampling=\"log\"))\n",
    "        )\n",
    "    )\n",
    "        \n",
    "    # automate a dropout layer\n",
    "    if hp.Boolean(\"dropout\"):\n",
    "        model.add(layers.Dropout(\n",
    "            hp.Float(\"rate\", min_value=0.1, max_value=0.5, step=0.025)\n",
    "            ))\n",
    "\n",
    "    # try additional layers, 1-3 extra layers\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 3)):\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                # Tune number of units separately.\n",
    "                units=hp.Int(f\"units_{i + 1}\", min_value=8, max_value=96, step=4),\n",
    "                activation=hp.Choice(\"activation\", [\"relu\"]),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # output layer, only one node since this is regression\n",
    "    model.add(layers.Dense(len(categories), activation=\"softmax\"))\n",
    "\n",
    "    # automate learning rate tests\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-5, max_value=1e-1, sampling=\"log\")\n",
    "\n",
    "    # compile the test neural network\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='categorical_crossentropy', metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# build the model + use RandomSearch to actually search the best options for our neural network\n",
    "build_model(keras_tuner.HyperParameters())\n",
    "\n",
    "# use val_loss as the objective, because regression tasks do not have accuracy\n",
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=8,\n",
    "    executions_per_trial=3,\n",
    "    overwrite=True,\n",
    "    directory=\"optimizations1\",\n",
    "    project_name=\"classification1test\",\n",
    ")\n",
    "\n",
    "# start searching\n",
    "tuner.search(X_train, y_train, epochs=250, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in optimizations1\\classification1test\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 5 summary\n",
      "Hyperparameters:\n",
      "units_0: 24\n",
      "activation: relu\n",
      "l1: 0.19707949881317957\n",
      "dropout: False\n",
      "num_layers: 2\n",
      "units_1: 60\n",
      "lr: 0.00034721549512563293\n",
      "rate: 0.25\n",
      "units_2: 68\n",
      "units_3: 40\n",
      "Score: 0.9828571478525797\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "units_0: 96\n",
      "activation: relu\n",
      "l1: 0.027275375560326137\n",
      "dropout: False\n",
      "num_layers: 1\n",
      "units_1: 88\n",
      "lr: 0.05759030042816015\n",
      "Score: 0.9780952533086141\n",
      "\n",
      "Trial 6 summary\n",
      "Hyperparameters:\n",
      "units_0: 52\n",
      "activation: relu\n",
      "l1: 0.050134179146107384\n",
      "dropout: True\n",
      "num_layers: 2\n",
      "units_1: 60\n",
      "lr: 0.0006335170019462175\n",
      "rate: 0.275\n",
      "units_2: 76\n",
      "units_3: 36\n",
      "Score: 0.9704761902491251\n",
      "\n",
      "Trial 3 summary\n",
      "Hyperparameters:\n",
      "units_0: 60\n",
      "activation: relu\n",
      "l1: 0.18441645684515048\n",
      "dropout: False\n",
      "num_layers: 2\n",
      "units_1: 96\n",
      "lr: 0.0007755686960215541\n",
      "rate: 0.125\n",
      "units_2: 20\n",
      "Score: 0.9647618929545084\n",
      "\n",
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "units_0: 40\n",
      "activation: relu\n",
      "l1: 0.14504340853458975\n",
      "dropout: True\n",
      "num_layers: 1\n",
      "units_1: 72\n",
      "lr: 0.034364517978284416\n",
      "rate: 0.1\n",
      "Score: 0.9638095100720724\n",
      "\n",
      "Trial 2 summary\n",
      "Hyperparameters:\n",
      "units_0: 44\n",
      "activation: relu\n",
      "l1: 0.035958709947386064\n",
      "dropout: False\n",
      "num_layers: 2\n",
      "units_1: 12\n",
      "lr: 0.07707716367029467\n",
      "rate: 0.17500000000000002\n",
      "units_2: 8\n",
      "Score: 0.9609523812929789\n",
      "\n",
      "Trial 7 summary\n",
      "Hyperparameters:\n",
      "units_0: 64\n",
      "activation: relu\n",
      "l1: 0.03881751368985301\n",
      "dropout: True\n",
      "num_layers: 1\n",
      "units_1: 92\n",
      "lr: 0.06558381404419296\n",
      "rate: 0.17500000000000002\n",
      "units_2: 36\n",
      "units_3: 80\n",
      "Score: 0.930476168791453\n",
      "\n",
      "Trial 4 summary\n",
      "Hyperparameters:\n",
      "units_0: 80\n",
      "activation: relu\n",
      "l1: 0.21295436689184105\n",
      "dropout: True\n",
      "num_layers: 3\n",
      "units_1: 12\n",
      "lr: 0.007863874434778347\n",
      "rate: 0.325\n",
      "units_2: 44\n",
      "units_3: 8\n",
      "Score: 0.9285714228947958\n"
     ]
    }
   ],
   "source": [
    "# print out the result and suggestions\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tuomas.valtanen\\DL2025lecturenotes2\\DeepLearning2025\\.venv\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:142: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "c:\\Users\\tuomas.valtanen\\DL2025lecturenotes2\\DeepLearning2025\\.venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 22 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,148</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">276</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │            \u001b[38;5;34m48\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │           \u001b[38;5;34m312\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             │         \u001b[38;5;34m1,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m68\u001b[0m)             │         \u001b[38;5;34m4,148\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m276\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,284</span> (24.55 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,284\u001b[0m (24.55 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,260</span> (24.45 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,260\u001b[0m (24.45 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> (96.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m24\u001b[0m (96.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Get the top 2 models.\n",
    "models = tuner.get_best_models(num_models=1)\n",
    "best_model = models[0]\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfsa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdfsa\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'dfsa' is not defined"
     ]
    }
   ],
   "source": [
    "dfsa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the neural network structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: you can use all the same callback features as in regression: ModelCheckpoint, EarlyStop, ReduceLROnPlateau, Dropout-layers...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,148</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">276</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │            \u001b[38;5;34m48\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │           \u001b[38;5;34m312\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             │         \u001b[38;5;34m1,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m68\u001b[0m)             │         \u001b[38;5;34m4,148\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m276\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,284</span> (24.55 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,284\u001b[0m (24.55 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,260</span> (24.45 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,260\u001b[0m (24.45 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> (96.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m24\u001b[0m (96.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# needed imports for ModelCheckpoint etc. callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# for EarlyStop/ReduceLROnPlateau, see materials and Moodle\n",
    "# for examples on how to use and when to use (usually more useful with classification)\n",
    "\n",
    "# create a model checkpoint to a file, and only save the best one\n",
    "mc = ModelCheckpoint('best_model_classification1_kt.keras', monitor='val_accuracy', mode='max', save_best_only=True)\n",
    "\n",
    "# combine all active callbacks into a list\n",
    "# have only those you need, for example only ModelCheckpoint\n",
    "callback_list = [mc]\n",
    "\n",
    "# Trial 5 summary\n",
    "# Hyperparameters:\n",
    "# units_0: 24\n",
    "# activation: relu\n",
    "# l1: 0.19707949881317957\n",
    "# dropout: False\n",
    "# num_layers: 2\n",
    "# units_1: 60\n",
    "# lr: 0.00034721549512563293\n",
    "# rate: 0.25\n",
    "# units_2: 68\n",
    "# units_3: 40\n",
    "# Score: 0.9828571478525797\n",
    "\n",
    "# ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "# ┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n",
    "# ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "# │ batch_normalization             │ (None, 12)             │            48 │\n",
    "# │ (BatchNormalization)            │                        │               │\n",
    "# ├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "# │ dense (Dense)                   │ (None, 24)             │           312 │\n",
    "# ├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "# │ dense_1 (Dense)                 │ (None, 60)             │         1,500 │\n",
    "# ├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "# │ dense_2 (Dense)                 │ (None, 68)             │         4,148 │\n",
    "# ├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "# │ dense_3 (Dense)                 │ (None, 4)              │           276 │\n",
    "# └─────────────────────────────────┴────────────────────────┴───────────────┘\n",
    "\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.BatchNormalization(input_shape=(len(X.columns),)),\n",
    "        layers.Dense(24, activation=\"relu\", kernel_regularizer=keras.regularizers.l1(l1=0.19707949881317957)),\n",
    "        layers.Dense(60, activation=\"relu\"),\n",
    "        layers.Dense(68, activation=\"relu\"),\n",
    "        layers.Dense(len(categories), activation=\"softmax\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# save the learning rate to a variable for easier changes\n",
    "optimal_lr = 0.00034721549512563293\n",
    "\n",
    "# compile the model, this time we use categorical crossentropy for loss -function\n",
    "# and we also measure the accuracy of our model in the metrics\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=optimal_lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3823 - loss: 12.4318 - val_accuracy: 0.3000 - val_loss: 12.0865\n",
      "Epoch 2/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5177 - loss: 11.5698 - val_accuracy: 0.3257 - val_loss: 11.2023\n",
      "Epoch 3/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5438 - loss: 10.7096 - val_accuracy: 0.4343 - val_loss: 10.3238\n",
      "Epoch 4/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5854 - loss: 9.8662 - val_accuracy: 0.5371 - val_loss: 9.4690\n",
      "Epoch 5/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6362 - loss: 9.0706 - val_accuracy: 0.6457 - val_loss: 8.6622\n",
      "Epoch 6/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6785 - loss: 8.3268 - val_accuracy: 0.7029 - val_loss: 7.9201\n",
      "Epoch 7/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7092 - loss: 7.6267 - val_accuracy: 0.7457 - val_loss: 7.2256\n",
      "Epoch 8/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7331 - loss: 6.9592 - val_accuracy: 0.7943 - val_loss: 6.5684\n",
      "Epoch 9/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7454 - loss: 6.3273 - val_accuracy: 0.8086 - val_loss: 5.9526\n",
      "Epoch 10/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7531 - loss: 5.7337 - val_accuracy: 0.8114 - val_loss: 5.3763\n",
      "Epoch 11/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7708 - loss: 5.1764 - val_accuracy: 0.8200 - val_loss: 4.8384\n",
      "Epoch 12/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7854 - loss: 4.6589 - val_accuracy: 0.8400 - val_loss: 4.3373\n",
      "Epoch 13/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7938 - loss: 4.1776 - val_accuracy: 0.8514 - val_loss: 3.8753\n",
      "Epoch 14/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8077 - loss: 3.7357 - val_accuracy: 0.8514 - val_loss: 3.4536\n",
      "Epoch 15/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8108 - loss: 3.3295 - val_accuracy: 0.8543 - val_loss: 3.0587\n",
      "Epoch 16/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8162 - loss: 2.9508 - val_accuracy: 0.8714 - val_loss: 2.6980\n",
      "Epoch 17/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8246 - loss: 2.6132 - val_accuracy: 0.8943 - val_loss: 2.3753\n",
      "Epoch 18/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8308 - loss: 2.3062 - val_accuracy: 0.9143 - val_loss: 2.0765\n",
      "Epoch 19/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8300 - loss: 2.0262 - val_accuracy: 0.9229 - val_loss: 1.8082\n",
      "Epoch 20/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8323 - loss: 1.7749 - val_accuracy: 0.9229 - val_loss: 1.5670\n",
      "Epoch 21/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8369 - loss: 1.5474 - val_accuracy: 0.9314 - val_loss: 1.3495\n",
      "Epoch 22/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8400 - loss: 1.3444 - val_accuracy: 0.9514 - val_loss: 1.1521\n",
      "Epoch 23/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8408 - loss: 1.1630 - val_accuracy: 0.9571 - val_loss: 0.9812\n",
      "Epoch 24/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8423 - loss: 1.0070 - val_accuracy: 0.9600 - val_loss: 0.8334\n",
      "Epoch 25/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.8749 - val_accuracy: 0.9571 - val_loss: 0.7142\n",
      "Epoch 26/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8415 - loss: 0.7719 - val_accuracy: 0.9657 - val_loss: 0.6192\n",
      "Epoch 27/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8369 - loss: 0.6934 - val_accuracy: 0.9657 - val_loss: 0.5506\n",
      "Epoch 28/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8415 - loss: 0.6344 - val_accuracy: 0.9743 - val_loss: 0.4972\n",
      "Epoch 29/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8408 - loss: 0.5930 - val_accuracy: 0.9686 - val_loss: 0.4654\n",
      "Epoch 30/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.5695 - val_accuracy: 0.9686 - val_loss: 0.4452\n",
      "Epoch 31/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8392 - loss: 0.5542 - val_accuracy: 0.9714 - val_loss: 0.4320\n",
      "Epoch 32/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.5433 - val_accuracy: 0.9686 - val_loss: 0.4193\n",
      "Epoch 33/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.5348 - val_accuracy: 0.9686 - val_loss: 0.4104\n",
      "Epoch 34/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.5276 - val_accuracy: 0.9657 - val_loss: 0.4010\n",
      "Epoch 35/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.5217 - val_accuracy: 0.9600 - val_loss: 0.3942\n",
      "Epoch 36/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.5169 - val_accuracy: 0.9657 - val_loss: 0.3865\n",
      "Epoch 37/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.5121 - val_accuracy: 0.9629 - val_loss: 0.3810\n",
      "Epoch 38/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8392 - loss: 0.5074 - val_accuracy: 0.9629 - val_loss: 0.3745\n",
      "Epoch 39/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.5031 - val_accuracy: 0.9629 - val_loss: 0.3690\n",
      "Epoch 40/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.4991 - val_accuracy: 0.9629 - val_loss: 0.3634\n",
      "Epoch 41/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.4953 - val_accuracy: 0.9657 - val_loss: 0.3597\n",
      "Epoch 42/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4922 - val_accuracy: 0.9657 - val_loss: 0.3546\n",
      "Epoch 43/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4893 - val_accuracy: 0.9629 - val_loss: 0.3516\n",
      "Epoch 44/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4864 - val_accuracy: 0.9629 - val_loss: 0.3473\n",
      "Epoch 45/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4842 - val_accuracy: 0.9629 - val_loss: 0.3440\n",
      "Epoch 46/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4819 - val_accuracy: 0.9629 - val_loss: 0.3408\n",
      "Epoch 47/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4797 - val_accuracy: 0.9629 - val_loss: 0.3381\n",
      "Epoch 48/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4781 - val_accuracy: 0.9657 - val_loss: 0.3352\n",
      "Epoch 49/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.4760 - val_accuracy: 0.9629 - val_loss: 0.3331\n",
      "Epoch 50/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4743 - val_accuracy: 0.9657 - val_loss: 0.3305\n",
      "Epoch 51/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4727 - val_accuracy: 0.9629 - val_loss: 0.3278\n",
      "Epoch 52/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.4712 - val_accuracy: 0.9657 - val_loss: 0.3255\n",
      "Epoch 53/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4698 - val_accuracy: 0.9600 - val_loss: 0.3236\n",
      "Epoch 54/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4685 - val_accuracy: 0.9629 - val_loss: 0.3211\n",
      "Epoch 55/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.4670 - val_accuracy: 0.9629 - val_loss: 0.3196\n",
      "Epoch 56/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4658 - val_accuracy: 0.9629 - val_loss: 0.3172\n",
      "Epoch 57/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4644 - val_accuracy: 0.9629 - val_loss: 0.3158\n",
      "Epoch 58/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4635 - val_accuracy: 0.9657 - val_loss: 0.3136\n",
      "Epoch 59/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4620 - val_accuracy: 0.9629 - val_loss: 0.3124\n",
      "Epoch 60/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4609 - val_accuracy: 0.9657 - val_loss: 0.3105\n",
      "Epoch 61/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.4599 - val_accuracy: 0.9629 - val_loss: 0.3099\n",
      "Epoch 62/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.4590 - val_accuracy: 0.9657 - val_loss: 0.3074\n",
      "Epoch 63/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.4577 - val_accuracy: 0.9629 - val_loss: 0.3060\n",
      "Epoch 64/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.4569 - val_accuracy: 0.9657 - val_loss: 0.3047\n",
      "Epoch 65/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.4559 - val_accuracy: 0.9686 - val_loss: 0.3031\n",
      "Epoch 66/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.4552 - val_accuracy: 0.9657 - val_loss: 0.3023\n",
      "Epoch 67/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.4541 - val_accuracy: 0.9629 - val_loss: 0.3004\n",
      "Epoch 68/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8415 - loss: 0.4533 - val_accuracy: 0.9657 - val_loss: 0.2996\n",
      "Epoch 69/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.4525 - val_accuracy: 0.9657 - val_loss: 0.2984\n",
      "Epoch 70/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8415 - loss: 0.4518 - val_accuracy: 0.9657 - val_loss: 0.2975\n",
      "Epoch 71/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.4509 - val_accuracy: 0.9657 - val_loss: 0.2963\n",
      "Epoch 72/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.4502 - val_accuracy: 0.9657 - val_loss: 0.2952\n",
      "Epoch 73/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.4495 - val_accuracy: 0.9657 - val_loss: 0.2942\n",
      "Epoch 74/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.4488 - val_accuracy: 0.9657 - val_loss: 0.2926\n",
      "Epoch 75/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8415 - loss: 0.4479 - val_accuracy: 0.9657 - val_loss: 0.2919\n",
      "Epoch 76/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.4473 - val_accuracy: 0.9629 - val_loss: 0.2907\n",
      "Epoch 77/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.4466 - val_accuracy: 0.9657 - val_loss: 0.2900\n",
      "Epoch 78/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.4460 - val_accuracy: 0.9629 - val_loss: 0.2887\n",
      "Epoch 79/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.4451 - val_accuracy: 0.9686 - val_loss: 0.2886\n",
      "Epoch 80/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.4448 - val_accuracy: 0.9629 - val_loss: 0.2875\n",
      "Epoch 81/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4439 - val_accuracy: 0.9686 - val_loss: 0.2864\n",
      "Epoch 82/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4435 - val_accuracy: 0.9657 - val_loss: 0.2856\n",
      "Epoch 83/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4427 - val_accuracy: 0.9686 - val_loss: 0.2850\n",
      "Epoch 84/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4423 - val_accuracy: 0.9657 - val_loss: 0.2837\n",
      "Epoch 85/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4416 - val_accuracy: 0.9657 - val_loss: 0.2831\n",
      "Epoch 86/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4410 - val_accuracy: 0.9686 - val_loss: 0.2824\n",
      "Epoch 87/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4406 - val_accuracy: 0.9657 - val_loss: 0.2818\n",
      "Epoch 88/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4401 - val_accuracy: 0.9686 - val_loss: 0.2811\n",
      "Epoch 89/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4395 - val_accuracy: 0.9686 - val_loss: 0.2804\n",
      "Epoch 90/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4389 - val_accuracy: 0.9686 - val_loss: 0.2802\n",
      "Epoch 91/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4384 - val_accuracy: 0.9686 - val_loss: 0.2788\n",
      "Epoch 92/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.4380 - val_accuracy: 0.9686 - val_loss: 0.2783\n",
      "Epoch 93/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4374 - val_accuracy: 0.9686 - val_loss: 0.2780\n",
      "Epoch 94/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.4371 - val_accuracy: 0.9686 - val_loss: 0.2774\n",
      "Epoch 95/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.4365 - val_accuracy: 0.9686 - val_loss: 0.2763\n",
      "Epoch 96/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4359 - val_accuracy: 0.9686 - val_loss: 0.2756\n",
      "Epoch 97/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4355 - val_accuracy: 0.9714 - val_loss: 0.2751\n",
      "Epoch 98/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4351 - val_accuracy: 0.9686 - val_loss: 0.2745\n",
      "Epoch 99/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.4346 - val_accuracy: 0.9714 - val_loss: 0.2737\n",
      "Epoch 100/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.4340 - val_accuracy: 0.9686 - val_loss: 0.2734\n",
      "Epoch 101/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.4336 - val_accuracy: 0.9743 - val_loss: 0.2729\n",
      "Epoch 102/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.4333 - val_accuracy: 0.9743 - val_loss: 0.2720\n",
      "Epoch 103/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4328 - val_accuracy: 0.9743 - val_loss: 0.2711\n",
      "Epoch 104/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.4325 - val_accuracy: 0.9714 - val_loss: 0.2707\n",
      "Epoch 105/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.4320 - val_accuracy: 0.9743 - val_loss: 0.2701\n",
      "Epoch 106/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.4318 - val_accuracy: 0.9714 - val_loss: 0.2701\n",
      "Epoch 107/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4314 - val_accuracy: 0.9743 - val_loss: 0.2690\n",
      "Epoch 108/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.4309 - val_accuracy: 0.9771 - val_loss: 0.2684\n",
      "Epoch 109/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.4306 - val_accuracy: 0.9743 - val_loss: 0.2677\n",
      "Epoch 110/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.4303 - val_accuracy: 0.9771 - val_loss: 0.2678\n",
      "Epoch 111/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8431 - loss: 0.4299 - val_accuracy: 0.9771 - val_loss: 0.2667\n",
      "Epoch 112/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.4295 - val_accuracy: 0.9771 - val_loss: 0.2660\n",
      "Epoch 113/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.4292 - val_accuracy: 0.9771 - val_loss: 0.2659\n",
      "Epoch 114/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.4289 - val_accuracy: 0.9743 - val_loss: 0.2655\n",
      "Epoch 115/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.4286 - val_accuracy: 0.9743 - val_loss: 0.2651\n",
      "Epoch 116/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.4282 - val_accuracy: 0.9743 - val_loss: 0.2642\n",
      "Epoch 117/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8438 - loss: 0.4278 - val_accuracy: 0.9743 - val_loss: 0.2643\n",
      "Epoch 118/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.4274 - val_accuracy: 0.9771 - val_loss: 0.2633\n",
      "Epoch 119/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.4271 - val_accuracy: 0.9743 - val_loss: 0.2634\n",
      "Epoch 120/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.4267 - val_accuracy: 0.9771 - val_loss: 0.2623\n",
      "Epoch 121/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.4264 - val_accuracy: 0.9743 - val_loss: 0.2624\n",
      "Epoch 122/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.4262 - val_accuracy: 0.9743 - val_loss: 0.2618\n",
      "Epoch 123/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.4257 - val_accuracy: 0.9743 - val_loss: 0.2616\n",
      "Epoch 124/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8431 - loss: 0.4255 - val_accuracy: 0.9771 - val_loss: 0.2611\n",
      "Epoch 125/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.4252 - val_accuracy: 0.9771 - val_loss: 0.2609\n",
      "Epoch 126/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.4249 - val_accuracy: 0.9743 - val_loss: 0.2600\n",
      "Epoch 127/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.4246 - val_accuracy: 0.9743 - val_loss: 0.2598\n",
      "Epoch 128/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.4244 - val_accuracy: 0.9743 - val_loss: 0.2595\n",
      "Epoch 129/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4243 - val_accuracy: 0.9743 - val_loss: 0.2590\n",
      "Epoch 130/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.4239 - val_accuracy: 0.9743 - val_loss: 0.2584\n",
      "Epoch 131/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4236 - val_accuracy: 0.9771 - val_loss: 0.2587\n",
      "Epoch 132/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.4232 - val_accuracy: 0.9743 - val_loss: 0.2583\n",
      "Epoch 133/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.4231 - val_accuracy: 0.9743 - val_loss: 0.2577\n",
      "Epoch 134/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.4229 - val_accuracy: 0.9743 - val_loss: 0.2578\n",
      "Epoch 135/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4223 - val_accuracy: 0.9771 - val_loss: 0.2565\n",
      "Epoch 136/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4220 - val_accuracy: 0.9743 - val_loss: 0.2564\n",
      "Epoch 137/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4219 - val_accuracy: 0.9743 - val_loss: 0.2562\n",
      "Epoch 138/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4217 - val_accuracy: 0.9743 - val_loss: 0.2559\n",
      "Epoch 139/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4213 - val_accuracy: 0.9743 - val_loss: 0.2553\n",
      "Epoch 140/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4212 - val_accuracy: 0.9743 - val_loss: 0.2547\n",
      "Epoch 141/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.4208 - val_accuracy: 0.9743 - val_loss: 0.2554\n",
      "Epoch 142/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4206 - val_accuracy: 0.9771 - val_loss: 0.2541\n",
      "Epoch 143/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4203 - val_accuracy: 0.9743 - val_loss: 0.2545\n",
      "Epoch 144/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4202 - val_accuracy: 0.9743 - val_loss: 0.2545\n",
      "Epoch 145/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.4200 - val_accuracy: 0.9743 - val_loss: 0.2539\n",
      "Epoch 146/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4196 - val_accuracy: 0.9743 - val_loss: 0.2531\n",
      "Epoch 147/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4192 - val_accuracy: 0.9743 - val_loss: 0.2526\n",
      "Epoch 148/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4189 - val_accuracy: 0.9743 - val_loss: 0.2527\n",
      "Epoch 149/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4192 - val_accuracy: 0.9743 - val_loss: 0.2529\n",
      "Epoch 150/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4189 - val_accuracy: 0.9743 - val_loss: 0.2524\n",
      "Epoch 151/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.4185 - val_accuracy: 0.9743 - val_loss: 0.2522\n",
      "Epoch 152/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4183 - val_accuracy: 0.9743 - val_loss: 0.2520\n",
      "Epoch 153/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4181 - val_accuracy: 0.9743 - val_loss: 0.2512\n",
      "Epoch 154/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4178 - val_accuracy: 0.9743 - val_loss: 0.2513\n",
      "Epoch 155/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4176 - val_accuracy: 0.9743 - val_loss: 0.2511\n",
      "Epoch 156/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.4173 - val_accuracy: 0.9743 - val_loss: 0.2506\n",
      "Epoch 157/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8408 - loss: 0.4172 - val_accuracy: 0.9743 - val_loss: 0.2505\n",
      "Epoch 158/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.4170 - val_accuracy: 0.9743 - val_loss: 0.2505\n",
      "Epoch 159/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.4169 - val_accuracy: 0.9743 - val_loss: 0.2501\n",
      "Epoch 160/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.4166 - val_accuracy: 0.9743 - val_loss: 0.2501\n",
      "Epoch 161/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.4164 - val_accuracy: 0.9743 - val_loss: 0.2496\n",
      "Epoch 162/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.4162 - val_accuracy: 0.9743 - val_loss: 0.2493\n",
      "Epoch 163/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.4160 - val_accuracy: 0.9743 - val_loss: 0.2485\n",
      "Epoch 164/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.4155 - val_accuracy: 0.9743 - val_loss: 0.2483\n",
      "Epoch 165/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8408 - loss: 0.4154 - val_accuracy: 0.9743 - val_loss: 0.2487\n",
      "Epoch 166/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.4153 - val_accuracy: 0.9743 - val_loss: 0.2484\n",
      "Epoch 167/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.4152 - val_accuracy: 0.9743 - val_loss: 0.2479\n",
      "Epoch 168/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.4150 - val_accuracy: 0.9743 - val_loss: 0.2477\n",
      "Epoch 169/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8408 - loss: 0.4148 - val_accuracy: 0.9743 - val_loss: 0.2478\n",
      "Epoch 170/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.4145 - val_accuracy: 0.9743 - val_loss: 0.2470\n",
      "Epoch 171/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.4143 - val_accuracy: 0.9743 - val_loss: 0.2472\n",
      "Epoch 172/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.4143 - val_accuracy: 0.9743 - val_loss: 0.2470\n",
      "Epoch 173/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.4140 - val_accuracy: 0.9743 - val_loss: 0.2468\n",
      "Epoch 174/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.4140 - val_accuracy: 0.9743 - val_loss: 0.2466\n",
      "Epoch 175/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.4136 - val_accuracy: 0.9743 - val_loss: 0.2460\n",
      "Epoch 176/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4133 - val_accuracy: 0.9771 - val_loss: 0.2459\n",
      "Epoch 177/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4130 - val_accuracy: 0.9771 - val_loss: 0.2460\n",
      "Epoch 178/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4130 - val_accuracy: 0.9771 - val_loss: 0.2455\n",
      "Epoch 179/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4129 - val_accuracy: 0.9800 - val_loss: 0.2457\n",
      "Epoch 180/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.4128 - val_accuracy: 0.9800 - val_loss: 0.2452\n",
      "Epoch 181/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4125 - val_accuracy: 0.9800 - val_loss: 0.2452\n",
      "Epoch 182/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4123 - val_accuracy: 0.9771 - val_loss: 0.2449\n",
      "Epoch 183/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4122 - val_accuracy: 0.9800 - val_loss: 0.2452\n",
      "Epoch 184/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4121 - val_accuracy: 0.9800 - val_loss: 0.2445\n",
      "Epoch 185/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4118 - val_accuracy: 0.9800 - val_loss: 0.2443\n",
      "Epoch 186/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.4116 - val_accuracy: 0.9800 - val_loss: 0.2443\n",
      "Epoch 187/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8408 - loss: 0.4114 - val_accuracy: 0.9829 - val_loss: 0.2442\n",
      "Epoch 188/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.4113 - val_accuracy: 0.9800 - val_loss: 0.2437\n",
      "Epoch 189/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4110 - val_accuracy: 0.9829 - val_loss: 0.2442\n",
      "Epoch 190/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.4109 - val_accuracy: 0.9800 - val_loss: 0.2438\n",
      "Epoch 191/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.4106 - val_accuracy: 0.9829 - val_loss: 0.2437\n",
      "Epoch 192/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.4105 - val_accuracy: 0.9829 - val_loss: 0.2435\n",
      "Epoch 193/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4103 - val_accuracy: 0.9829 - val_loss: 0.2428\n",
      "Epoch 194/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.4103 - val_accuracy: 0.9829 - val_loss: 0.2431\n",
      "Epoch 195/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4102 - val_accuracy: 0.9800 - val_loss: 0.2426\n",
      "Epoch 196/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.4098 - val_accuracy: 0.9800 - val_loss: 0.2429\n",
      "Epoch 197/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.4099 - val_accuracy: 0.9800 - val_loss: 0.2426\n",
      "Epoch 198/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4094 - val_accuracy: 0.9800 - val_loss: 0.2422\n",
      "Epoch 199/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.4093 - val_accuracy: 0.9800 - val_loss: 0.2420\n",
      "Epoch 200/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4091 - val_accuracy: 0.9800 - val_loss: 0.2422\n",
      "Epoch 201/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.4089 - val_accuracy: 0.9800 - val_loss: 0.2419\n",
      "Epoch 202/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4088 - val_accuracy: 0.9800 - val_loss: 0.2418\n",
      "Epoch 203/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4086 - val_accuracy: 0.9800 - val_loss: 0.2417\n",
      "Epoch 204/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.4085 - val_accuracy: 0.9829 - val_loss: 0.2415\n",
      "Epoch 205/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.4084 - val_accuracy: 0.9829 - val_loss: 0.2410\n",
      "Epoch 206/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.4080 - val_accuracy: 0.9829 - val_loss: 0.2409\n",
      "Epoch 207/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.4080 - val_accuracy: 0.9829 - val_loss: 0.2414\n",
      "Epoch 208/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.4081 - val_accuracy: 0.9800 - val_loss: 0.2406\n",
      "Epoch 209/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.4077 - val_accuracy: 0.9829 - val_loss: 0.2407\n",
      "Epoch 210/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8408 - loss: 0.4077 - val_accuracy: 0.9800 - val_loss: 0.2404\n",
      "Epoch 211/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.4075 - val_accuracy: 0.9771 - val_loss: 0.2411\n",
      "Epoch 212/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.4075 - val_accuracy: 0.9800 - val_loss: 0.2403\n",
      "Epoch 213/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.4071 - val_accuracy: 0.9771 - val_loss: 0.2404\n",
      "Epoch 214/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.4070 - val_accuracy: 0.9771 - val_loss: 0.2404\n",
      "Epoch 215/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.4069 - val_accuracy: 0.9771 - val_loss: 0.2404\n",
      "Epoch 216/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8431 - loss: 0.4068 - val_accuracy: 0.9771 - val_loss: 0.2397\n",
      "Epoch 217/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.4065 - val_accuracy: 0.9771 - val_loss: 0.2403\n",
      "Epoch 218/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.4066 - val_accuracy: 0.9771 - val_loss: 0.2398\n",
      "Epoch 219/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8438 - loss: 0.4063 - val_accuracy: 0.9743 - val_loss: 0.2398\n",
      "Epoch 220/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.4062 - val_accuracy: 0.9771 - val_loss: 0.2397\n",
      "Epoch 221/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.4060 - val_accuracy: 0.9771 - val_loss: 0.2398\n",
      "Epoch 222/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8438 - loss: 0.4058 - val_accuracy: 0.9743 - val_loss: 0.2394\n",
      "Epoch 223/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4055 - val_accuracy: 0.9771 - val_loss: 0.2393\n",
      "Epoch 224/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4054 - val_accuracy: 0.9771 - val_loss: 0.2387\n",
      "Epoch 225/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4053 - val_accuracy: 0.9771 - val_loss: 0.2391\n",
      "Epoch 226/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4052 - val_accuracy: 0.9771 - val_loss: 0.2388\n",
      "Epoch 227/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4050 - val_accuracy: 0.9771 - val_loss: 0.2384\n",
      "Epoch 228/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.4047 - val_accuracy: 0.9771 - val_loss: 0.2380\n",
      "Epoch 229/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4045 - val_accuracy: 0.9771 - val_loss: 0.2386\n",
      "Epoch 230/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.4047 - val_accuracy: 0.9771 - val_loss: 0.2383\n",
      "Epoch 231/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4044 - val_accuracy: 0.9743 - val_loss: 0.2382\n",
      "Epoch 232/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4043 - val_accuracy: 0.9771 - val_loss: 0.2379\n",
      "Epoch 233/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4042 - val_accuracy: 0.9771 - val_loss: 0.2376\n",
      "Epoch 234/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4039 - val_accuracy: 0.9771 - val_loss: 0.2380\n",
      "Epoch 235/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.4039 - val_accuracy: 0.9771 - val_loss: 0.2374\n",
      "Epoch 236/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.4037 - val_accuracy: 0.9771 - val_loss: 0.2372\n",
      "Epoch 237/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.4036 - val_accuracy: 0.9771 - val_loss: 0.2367\n",
      "Epoch 238/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.4034 - val_accuracy: 0.9771 - val_loss: 0.2370\n",
      "Epoch 239/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.4032 - val_accuracy: 0.9771 - val_loss: 0.2366\n",
      "Epoch 240/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.4030 - val_accuracy: 0.9771 - val_loss: 0.2365\n",
      "Epoch 241/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4029 - val_accuracy: 0.9771 - val_loss: 0.2363\n",
      "Epoch 242/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4030 - val_accuracy: 0.9771 - val_loss: 0.2363\n",
      "Epoch 243/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4028 - val_accuracy: 0.9771 - val_loss: 0.2360\n",
      "Epoch 244/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.4026 - val_accuracy: 0.9743 - val_loss: 0.2362\n",
      "Epoch 245/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4024 - val_accuracy: 0.9771 - val_loss: 0.2359\n",
      "Epoch 246/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4023 - val_accuracy: 0.9771 - val_loss: 0.2358\n",
      "Epoch 247/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4020 - val_accuracy: 0.9771 - val_loss: 0.2359\n",
      "Epoch 248/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.4021 - val_accuracy: 0.9771 - val_loss: 0.2355\n",
      "Epoch 249/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4019 - val_accuracy: 0.9771 - val_loss: 0.2354\n",
      "Epoch 250/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.4018 - val_accuracy: 0.9771 - val_loss: 0.2351\n",
      "Epoch 251/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.4016 - val_accuracy: 0.9743 - val_loss: 0.2352\n",
      "Epoch 252/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8431 - loss: 0.4015 - val_accuracy: 0.9771 - val_loss: 0.2350\n",
      "Epoch 253/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.4015 - val_accuracy: 0.9771 - val_loss: 0.2347\n",
      "Epoch 254/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.4013 - val_accuracy: 0.9771 - val_loss: 0.2345\n",
      "Epoch 255/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.4012 - val_accuracy: 0.9771 - val_loss: 0.2343\n",
      "Epoch 256/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.4009 - val_accuracy: 0.9771 - val_loss: 0.2343\n",
      "Epoch 257/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.4009 - val_accuracy: 0.9771 - val_loss: 0.2343\n",
      "Epoch 258/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.4008 - val_accuracy: 0.9771 - val_loss: 0.2344\n",
      "Epoch 259/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.4007 - val_accuracy: 0.9771 - val_loss: 0.2338\n",
      "Epoch 260/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8438 - loss: 0.4003 - val_accuracy: 0.9771 - val_loss: 0.2340\n",
      "Epoch 261/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.4004 - val_accuracy: 0.9771 - val_loss: 0.2340\n",
      "Epoch 262/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.4005 - val_accuracy: 0.9771 - val_loss: 0.2336\n",
      "Epoch 263/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.4003 - val_accuracy: 0.9743 - val_loss: 0.2336\n",
      "Epoch 264/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8431 - loss: 0.4000 - val_accuracy: 0.9771 - val_loss: 0.2332\n",
      "Epoch 265/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.3999 - val_accuracy: 0.9771 - val_loss: 0.2335\n",
      "Epoch 266/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.4001 - val_accuracy: 0.9771 - val_loss: 0.2329\n",
      "Epoch 267/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3996 - val_accuracy: 0.9743 - val_loss: 0.2330\n",
      "Epoch 268/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.3997 - val_accuracy: 0.9771 - val_loss: 0.2329\n",
      "Epoch 269/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.3996 - val_accuracy: 0.9771 - val_loss: 0.2327\n",
      "Epoch 270/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3995 - val_accuracy: 0.9771 - val_loss: 0.2329\n",
      "Epoch 271/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.3995 - val_accuracy: 0.9771 - val_loss: 0.2327\n",
      "Epoch 272/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3991 - val_accuracy: 0.9771 - val_loss: 0.2324\n",
      "Epoch 273/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3992 - val_accuracy: 0.9771 - val_loss: 0.2324\n",
      "Epoch 274/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3992 - val_accuracy: 0.9771 - val_loss: 0.2322\n",
      "Epoch 275/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3989 - val_accuracy: 0.9771 - val_loss: 0.2320\n",
      "Epoch 276/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3988 - val_accuracy: 0.9771 - val_loss: 0.2319\n",
      "Epoch 277/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.3985 - val_accuracy: 0.9743 - val_loss: 0.2321\n",
      "Epoch 278/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3988 - val_accuracy: 0.9743 - val_loss: 0.2320\n",
      "Epoch 279/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3988 - val_accuracy: 0.9771 - val_loss: 0.2314\n",
      "Epoch 280/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3985 - val_accuracy: 0.9714 - val_loss: 0.2319\n",
      "Epoch 281/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3985 - val_accuracy: 0.9743 - val_loss: 0.2314\n",
      "Epoch 282/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3981 - val_accuracy: 0.9771 - val_loss: 0.2314\n",
      "Epoch 283/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.3984 - val_accuracy: 0.9743 - val_loss: 0.2314\n",
      "Epoch 284/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.3978 - val_accuracy: 0.9771 - val_loss: 0.2311\n",
      "Epoch 285/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3980 - val_accuracy: 0.9714 - val_loss: 0.2309\n",
      "Epoch 286/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3979 - val_accuracy: 0.9771 - val_loss: 0.2306\n",
      "Epoch 287/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3979 - val_accuracy: 0.9714 - val_loss: 0.2306\n",
      "Epoch 288/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3977 - val_accuracy: 0.9743 - val_loss: 0.2306\n",
      "Epoch 289/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.3978 - val_accuracy: 0.9714 - val_loss: 0.2306\n",
      "Epoch 290/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3975 - val_accuracy: 0.9743 - val_loss: 0.2307\n",
      "Epoch 291/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3976 - val_accuracy: 0.9714 - val_loss: 0.2304\n",
      "Epoch 292/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3973 - val_accuracy: 0.9743 - val_loss: 0.2306\n",
      "Epoch 293/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3972 - val_accuracy: 0.9743 - val_loss: 0.2302\n",
      "Epoch 294/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3971 - val_accuracy: 0.9714 - val_loss: 0.2299\n",
      "Epoch 295/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.3969 - val_accuracy: 0.9743 - val_loss: 0.2302\n",
      "Epoch 296/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.3969 - val_accuracy: 0.9743 - val_loss: 0.2300\n",
      "Epoch 297/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.3968 - val_accuracy: 0.9743 - val_loss: 0.2299\n",
      "Epoch 298/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3967 - val_accuracy: 0.9743 - val_loss: 0.2294\n",
      "Epoch 299/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3966 - val_accuracy: 0.9743 - val_loss: 0.2296\n",
      "Epoch 300/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8446 - loss: 0.3966 - val_accuracy: 0.9743 - val_loss: 0.2294\n",
      "Epoch 301/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8446 - loss: 0.3965 - val_accuracy: 0.9743 - val_loss: 0.2296\n",
      "Epoch 302/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.3966 - val_accuracy: 0.9743 - val_loss: 0.2298\n",
      "Epoch 303/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.3963 - val_accuracy: 0.9714 - val_loss: 0.2290\n",
      "Epoch 304/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3962 - val_accuracy: 0.9743 - val_loss: 0.2290\n",
      "Epoch 305/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3962 - val_accuracy: 0.9714 - val_loss: 0.2288\n",
      "Epoch 306/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3961 - val_accuracy: 0.9743 - val_loss: 0.2284\n",
      "Epoch 307/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3961 - val_accuracy: 0.9714 - val_loss: 0.2287\n",
      "Epoch 308/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3960 - val_accuracy: 0.9743 - val_loss: 0.2286\n",
      "Epoch 309/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3960 - val_accuracy: 0.9714 - val_loss: 0.2286\n",
      "Epoch 310/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8446 - loss: 0.3957 - val_accuracy: 0.9743 - val_loss: 0.2287\n",
      "Epoch 311/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.3956 - val_accuracy: 0.9743 - val_loss: 0.2287\n",
      "Epoch 312/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3956 - val_accuracy: 0.9743 - val_loss: 0.2283\n",
      "Epoch 313/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3954 - val_accuracy: 0.9743 - val_loss: 0.2283\n",
      "Epoch 314/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3954 - val_accuracy: 0.9743 - val_loss: 0.2282\n",
      "Epoch 315/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3955 - val_accuracy: 0.9743 - val_loss: 0.2283\n",
      "Epoch 316/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3954 - val_accuracy: 0.9743 - val_loss: 0.2281\n",
      "Epoch 317/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3952 - val_accuracy: 0.9743 - val_loss: 0.2278\n",
      "Epoch 318/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3951 - val_accuracy: 0.9743 - val_loss: 0.2279\n",
      "Epoch 319/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3950 - val_accuracy: 0.9743 - val_loss: 0.2278\n",
      "Epoch 320/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3950 - val_accuracy: 0.9743 - val_loss: 0.2276\n",
      "Epoch 321/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3949 - val_accuracy: 0.9714 - val_loss: 0.2280\n",
      "Epoch 322/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3946 - val_accuracy: 0.9743 - val_loss: 0.2272\n",
      "Epoch 323/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3948 - val_accuracy: 0.9686 - val_loss: 0.2278\n",
      "Epoch 324/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3946 - val_accuracy: 0.9743 - val_loss: 0.2272\n",
      "Epoch 325/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3947 - val_accuracy: 0.9743 - val_loss: 0.2273\n",
      "Epoch 326/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3947 - val_accuracy: 0.9743 - val_loss: 0.2273\n",
      "Epoch 327/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3946 - val_accuracy: 0.9743 - val_loss: 0.2270\n",
      "Epoch 328/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3943 - val_accuracy: 0.9743 - val_loss: 0.2270\n",
      "Epoch 329/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3941 - val_accuracy: 0.9714 - val_loss: 0.2270\n",
      "Epoch 330/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3944 - val_accuracy: 0.9714 - val_loss: 0.2268\n",
      "Epoch 331/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3942 - val_accuracy: 0.9714 - val_loss: 0.2268\n",
      "Epoch 332/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3941 - val_accuracy: 0.9686 - val_loss: 0.2267\n",
      "Epoch 333/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3941 - val_accuracy: 0.9686 - val_loss: 0.2266\n",
      "Epoch 334/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3939 - val_accuracy: 0.9743 - val_loss: 0.2264\n",
      "Epoch 335/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3937 - val_accuracy: 0.9743 - val_loss: 0.2264\n",
      "Epoch 336/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3938 - val_accuracy: 0.9743 - val_loss: 0.2263\n",
      "Epoch 337/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3936 - val_accuracy: 0.9714 - val_loss: 0.2263\n",
      "Epoch 338/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3938 - val_accuracy: 0.9743 - val_loss: 0.2259\n",
      "Epoch 339/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3936 - val_accuracy: 0.9686 - val_loss: 0.2267\n",
      "Epoch 340/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3937 - val_accuracy: 0.9686 - val_loss: 0.2262\n",
      "Epoch 341/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3934 - val_accuracy: 0.9714 - val_loss: 0.2261\n",
      "Epoch 342/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8454 - loss: 0.3933 - val_accuracy: 0.9714 - val_loss: 0.2259\n",
      "Epoch 343/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3933 - val_accuracy: 0.9743 - val_loss: 0.2259\n",
      "Epoch 344/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3932 - val_accuracy: 0.9743 - val_loss: 0.2258\n",
      "Epoch 345/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3932 - val_accuracy: 0.9743 - val_loss: 0.2256\n",
      "Epoch 346/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3930 - val_accuracy: 0.9743 - val_loss: 0.2258\n",
      "Epoch 347/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3930 - val_accuracy: 0.9714 - val_loss: 0.2257\n",
      "Epoch 348/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3930 - val_accuracy: 0.9714 - val_loss: 0.2253\n",
      "Epoch 349/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3929 - val_accuracy: 0.9714 - val_loss: 0.2254\n",
      "Epoch 350/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8469 - loss: 0.3928 - val_accuracy: 0.9743 - val_loss: 0.2253\n",
      "Epoch 351/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3927 - val_accuracy: 0.9714 - val_loss: 0.2251\n",
      "Epoch 352/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3929 - val_accuracy: 0.9743 - val_loss: 0.2252\n",
      "Epoch 353/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3927 - val_accuracy: 0.9714 - val_loss: 0.2249\n",
      "Epoch 354/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3926 - val_accuracy: 0.9743 - val_loss: 0.2245\n",
      "Epoch 355/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3923 - val_accuracy: 0.9714 - val_loss: 0.2251\n",
      "Epoch 356/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3925 - val_accuracy: 0.9743 - val_loss: 0.2248\n",
      "Epoch 357/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.3923 - val_accuracy: 0.9714 - val_loss: 0.2247\n",
      "Epoch 358/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8469 - loss: 0.3922 - val_accuracy: 0.9714 - val_loss: 0.2250\n",
      "Epoch 359/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3924 - val_accuracy: 0.9686 - val_loss: 0.2248\n",
      "Epoch 360/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3922 - val_accuracy: 0.9714 - val_loss: 0.2248\n",
      "Epoch 361/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3922 - val_accuracy: 0.9714 - val_loss: 0.2242\n",
      "Epoch 362/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3921 - val_accuracy: 0.9686 - val_loss: 0.2244\n",
      "Epoch 363/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3919 - val_accuracy: 0.9714 - val_loss: 0.2248\n",
      "Epoch 364/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3920 - val_accuracy: 0.9686 - val_loss: 0.2243\n",
      "Epoch 365/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3918 - val_accuracy: 0.9686 - val_loss: 0.2244\n",
      "Epoch 366/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3918 - val_accuracy: 0.9714 - val_loss: 0.2244\n",
      "Epoch 367/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3919 - val_accuracy: 0.9714 - val_loss: 0.2243\n",
      "Epoch 368/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3917 - val_accuracy: 0.9714 - val_loss: 0.2241\n",
      "Epoch 369/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3916 - val_accuracy: 0.9714 - val_loss: 0.2244\n",
      "Epoch 370/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3914 - val_accuracy: 0.9686 - val_loss: 0.2243\n",
      "Epoch 371/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3915 - val_accuracy: 0.9714 - val_loss: 0.2237\n",
      "Epoch 372/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3914 - val_accuracy: 0.9714 - val_loss: 0.2235\n",
      "Epoch 373/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3914 - val_accuracy: 0.9714 - val_loss: 0.2237\n",
      "Epoch 374/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3912 - val_accuracy: 0.9714 - val_loss: 0.2238\n",
      "Epoch 375/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3911 - val_accuracy: 0.9714 - val_loss: 0.2236\n",
      "Epoch 376/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3911 - val_accuracy: 0.9686 - val_loss: 0.2234\n",
      "Epoch 377/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3911 - val_accuracy: 0.9714 - val_loss: 0.2233\n",
      "Epoch 378/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3909 - val_accuracy: 0.9714 - val_loss: 0.2232\n",
      "Epoch 379/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3908 - val_accuracy: 0.9714 - val_loss: 0.2233\n",
      "Epoch 380/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3910 - val_accuracy: 0.9714 - val_loss: 0.2231\n",
      "Epoch 381/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3908 - val_accuracy: 0.9714 - val_loss: 0.2234\n",
      "Epoch 382/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3909 - val_accuracy: 0.9714 - val_loss: 0.2228\n",
      "Epoch 383/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3907 - val_accuracy: 0.9714 - val_loss: 0.2233\n",
      "Epoch 384/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3908 - val_accuracy: 0.9714 - val_loss: 0.2235\n",
      "Epoch 385/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3905 - val_accuracy: 0.9714 - val_loss: 0.2227\n",
      "Epoch 386/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3904 - val_accuracy: 0.9714 - val_loss: 0.2230\n",
      "Epoch 387/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3903 - val_accuracy: 0.9714 - val_loss: 0.2230\n",
      "Epoch 388/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8469 - loss: 0.3903 - val_accuracy: 0.9714 - val_loss: 0.2228\n",
      "Epoch 389/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3903 - val_accuracy: 0.9714 - val_loss: 0.2223\n",
      "Epoch 390/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3902 - val_accuracy: 0.9714 - val_loss: 0.2231\n",
      "Epoch 391/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3902 - val_accuracy: 0.9714 - val_loss: 0.2224\n",
      "Epoch 392/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3902 - val_accuracy: 0.9714 - val_loss: 0.2221\n",
      "Epoch 393/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3900 - val_accuracy: 0.9714 - val_loss: 0.2222\n",
      "Epoch 394/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3901 - val_accuracy: 0.9714 - val_loss: 0.2219\n",
      "Epoch 395/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8454 - loss: 0.3900 - val_accuracy: 0.9714 - val_loss: 0.2221\n",
      "Epoch 396/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3898 - val_accuracy: 0.9714 - val_loss: 0.2222\n",
      "Epoch 397/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3899 - val_accuracy: 0.9714 - val_loss: 0.2218\n",
      "Epoch 398/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3896 - val_accuracy: 0.9714 - val_loss: 0.2218\n",
      "Epoch 399/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3896 - val_accuracy: 0.9714 - val_loss: 0.2216\n",
      "Epoch 400/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3896 - val_accuracy: 0.9714 - val_loss: 0.2219\n",
      "Epoch 401/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3898 - val_accuracy: 0.9714 - val_loss: 0.2219\n",
      "Epoch 402/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3896 - val_accuracy: 0.9714 - val_loss: 0.2216\n",
      "Epoch 403/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3896 - val_accuracy: 0.9686 - val_loss: 0.2216\n",
      "Epoch 404/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3893 - val_accuracy: 0.9714 - val_loss: 0.2215\n",
      "Epoch 405/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3895 - val_accuracy: 0.9714 - val_loss: 0.2213\n",
      "Epoch 406/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3892 - val_accuracy: 0.9714 - val_loss: 0.2215\n",
      "Epoch 407/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3892 - val_accuracy: 0.9714 - val_loss: 0.2210\n",
      "Epoch 408/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3891 - val_accuracy: 0.9714 - val_loss: 0.2209\n",
      "Epoch 409/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3889 - val_accuracy: 0.9714 - val_loss: 0.2209\n",
      "Epoch 410/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3889 - val_accuracy: 0.9714 - val_loss: 0.2208\n",
      "Epoch 411/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3888 - val_accuracy: 0.9714 - val_loss: 0.2210\n",
      "Epoch 412/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3888 - val_accuracy: 0.9714 - val_loss: 0.2209\n",
      "Epoch 413/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3888 - val_accuracy: 0.9714 - val_loss: 0.2210\n",
      "Epoch 414/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3888 - val_accuracy: 0.9714 - val_loss: 0.2208\n",
      "Epoch 415/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3884 - val_accuracy: 0.9714 - val_loss: 0.2209\n",
      "Epoch 416/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3888 - val_accuracy: 0.9714 - val_loss: 0.2209\n",
      "Epoch 417/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3885 - val_accuracy: 0.9714 - val_loss: 0.2207\n",
      "Epoch 418/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3886 - val_accuracy: 0.9714 - val_loss: 0.2202\n",
      "Epoch 419/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3882 - val_accuracy: 0.9714 - val_loss: 0.2207\n",
      "Epoch 420/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3885 - val_accuracy: 0.9743 - val_loss: 0.2204\n",
      "Epoch 421/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3882 - val_accuracy: 0.9714 - val_loss: 0.2207\n",
      "Epoch 422/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3885 - val_accuracy: 0.9714 - val_loss: 0.2209\n",
      "Epoch 423/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3882 - val_accuracy: 0.9714 - val_loss: 0.2202\n",
      "Epoch 424/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3881 - val_accuracy: 0.9714 - val_loss: 0.2203\n",
      "Epoch 425/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3883 - val_accuracy: 0.9743 - val_loss: 0.2202\n",
      "Epoch 426/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3880 - val_accuracy: 0.9743 - val_loss: 0.2200\n",
      "Epoch 427/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3879 - val_accuracy: 0.9714 - val_loss: 0.2201\n",
      "Epoch 428/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3881 - val_accuracy: 0.9743 - val_loss: 0.2199\n",
      "Epoch 429/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3879 - val_accuracy: 0.9743 - val_loss: 0.2197\n",
      "Epoch 430/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3879 - val_accuracy: 0.9743 - val_loss: 0.2197\n",
      "Epoch 431/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3878 - val_accuracy: 0.9714 - val_loss: 0.2199\n",
      "Epoch 432/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3879 - val_accuracy: 0.9714 - val_loss: 0.2195\n",
      "Epoch 433/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3876 - val_accuracy: 0.9743 - val_loss: 0.2197\n",
      "Epoch 434/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3877 - val_accuracy: 0.9743 - val_loss: 0.2195\n",
      "Epoch 435/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3875 - val_accuracy: 0.9714 - val_loss: 0.2195\n",
      "Epoch 436/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3876 - val_accuracy: 0.9743 - val_loss: 0.2198\n",
      "Epoch 437/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3876 - val_accuracy: 0.9743 - val_loss: 0.2197\n",
      "Epoch 438/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3875 - val_accuracy: 0.9743 - val_loss: 0.2194\n",
      "Epoch 439/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8454 - loss: 0.3872 - val_accuracy: 0.9743 - val_loss: 0.2192\n",
      "Epoch 440/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3874 - val_accuracy: 0.9743 - val_loss: 0.2194\n",
      "Epoch 441/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3874 - val_accuracy: 0.9743 - val_loss: 0.2187\n",
      "Epoch 442/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3872 - val_accuracy: 0.9743 - val_loss: 0.2189\n",
      "Epoch 443/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3872 - val_accuracy: 0.9743 - val_loss: 0.2190\n",
      "Epoch 444/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3872 - val_accuracy: 0.9743 - val_loss: 0.2190\n",
      "Epoch 445/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3870 - val_accuracy: 0.9743 - val_loss: 0.2191\n",
      "Epoch 446/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3869 - val_accuracy: 0.9743 - val_loss: 0.2191\n",
      "Epoch 447/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3871 - val_accuracy: 0.9743 - val_loss: 0.2192\n",
      "Epoch 448/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8469 - loss: 0.3870 - val_accuracy: 0.9743 - val_loss: 0.2190\n",
      "Epoch 449/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3867 - val_accuracy: 0.9743 - val_loss: 0.2189\n",
      "Epoch 450/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3870 - val_accuracy: 0.9743 - val_loss: 0.2190\n",
      "Epoch 451/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3867 - val_accuracy: 0.9743 - val_loss: 0.2185\n",
      "Epoch 452/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3868 - val_accuracy: 0.9743 - val_loss: 0.2184\n",
      "Epoch 453/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3867 - val_accuracy: 0.9743 - val_loss: 0.2184\n",
      "Epoch 454/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3865 - val_accuracy: 0.9743 - val_loss: 0.2186\n",
      "Epoch 455/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3866 - val_accuracy: 0.9743 - val_loss: 0.2187\n",
      "Epoch 456/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3865 - val_accuracy: 0.9743 - val_loss: 0.2188\n",
      "Epoch 457/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3866 - val_accuracy: 0.9743 - val_loss: 0.2183\n",
      "Epoch 458/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3863 - val_accuracy: 0.9743 - val_loss: 0.2185\n",
      "Epoch 459/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3865 - val_accuracy: 0.9743 - val_loss: 0.2180\n",
      "Epoch 460/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3861 - val_accuracy: 0.9743 - val_loss: 0.2184\n",
      "Epoch 461/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3861 - val_accuracy: 0.9743 - val_loss: 0.2182\n",
      "Epoch 462/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3862 - val_accuracy: 0.9743 - val_loss: 0.2183\n",
      "Epoch 463/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3860 - val_accuracy: 0.9743 - val_loss: 0.2187\n",
      "Epoch 464/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3862 - val_accuracy: 0.9743 - val_loss: 0.2179\n",
      "Epoch 465/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3860 - val_accuracy: 0.9771 - val_loss: 0.2177\n",
      "Epoch 466/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3860 - val_accuracy: 0.9743 - val_loss: 0.2181\n",
      "Epoch 467/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3861 - val_accuracy: 0.9743 - val_loss: 0.2177\n",
      "Epoch 468/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3859 - val_accuracy: 0.9743 - val_loss: 0.2177\n",
      "Epoch 469/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3859 - val_accuracy: 0.9743 - val_loss: 0.2175\n",
      "Epoch 470/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3858 - val_accuracy: 0.9743 - val_loss: 0.2179\n",
      "Epoch 471/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3858 - val_accuracy: 0.9771 - val_loss: 0.2177\n",
      "Epoch 472/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3857 - val_accuracy: 0.9743 - val_loss: 0.2178\n",
      "Epoch 473/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3858 - val_accuracy: 0.9743 - val_loss: 0.2171\n",
      "Epoch 474/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3857 - val_accuracy: 0.9743 - val_loss: 0.2177\n",
      "Epoch 475/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3856 - val_accuracy: 0.9743 - val_loss: 0.2172\n",
      "Epoch 476/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3855 - val_accuracy: 0.9743 - val_loss: 0.2177\n",
      "Epoch 477/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3855 - val_accuracy: 0.9743 - val_loss: 0.2177\n",
      "Epoch 478/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3856 - val_accuracy: 0.9743 - val_loss: 0.2173\n",
      "Epoch 479/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3854 - val_accuracy: 0.9743 - val_loss: 0.2172\n",
      "Epoch 480/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3855 - val_accuracy: 0.9743 - val_loss: 0.2172\n",
      "Epoch 481/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3854 - val_accuracy: 0.9743 - val_loss: 0.2172\n",
      "Epoch 482/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3853 - val_accuracy: 0.9743 - val_loss: 0.2171\n",
      "Epoch 483/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3852 - val_accuracy: 0.9743 - val_loss: 0.2171\n",
      "Epoch 484/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3851 - val_accuracy: 0.9743 - val_loss: 0.2169\n",
      "Epoch 485/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3849 - val_accuracy: 0.9743 - val_loss: 0.2168\n",
      "Epoch 486/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3851 - val_accuracy: 0.9743 - val_loss: 0.2167\n",
      "Epoch 487/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3850 - val_accuracy: 0.9743 - val_loss: 0.2173\n",
      "Epoch 488/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3850 - val_accuracy: 0.9743 - val_loss: 0.2166\n",
      "Epoch 489/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3849 - val_accuracy: 0.9743 - val_loss: 0.2168\n",
      "Epoch 490/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3849 - val_accuracy: 0.9743 - val_loss: 0.2166\n",
      "Epoch 491/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3848 - val_accuracy: 0.9743 - val_loss: 0.2164\n",
      "Epoch 492/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3849 - val_accuracy: 0.9743 - val_loss: 0.2164\n",
      "Epoch 493/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3846 - val_accuracy: 0.9743 - val_loss: 0.2164\n",
      "Epoch 494/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3845 - val_accuracy: 0.9743 - val_loss: 0.2163\n",
      "Epoch 495/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8469 - loss: 0.3845 - val_accuracy: 0.9743 - val_loss: 0.2162\n",
      "Epoch 496/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3846 - val_accuracy: 0.9771 - val_loss: 0.2162\n",
      "Epoch 497/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8485 - loss: 0.3844 - val_accuracy: 0.9743 - val_loss: 0.2166\n",
      "Epoch 498/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3846 - val_accuracy: 0.9743 - val_loss: 0.2162\n",
      "Epoch 499/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3844 - val_accuracy: 0.9743 - val_loss: 0.2162\n",
      "Epoch 500/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3845 - val_accuracy: 0.9743 - val_loss: 0.2163\n",
      "Epoch 501/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3843 - val_accuracy: 0.9743 - val_loss: 0.2163\n",
      "Epoch 502/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3843 - val_accuracy: 0.9743 - val_loss: 0.2159\n",
      "Epoch 503/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3843 - val_accuracy: 0.9714 - val_loss: 0.2162\n",
      "Epoch 504/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3841 - val_accuracy: 0.9743 - val_loss: 0.2155\n",
      "Epoch 505/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3842 - val_accuracy: 0.9714 - val_loss: 0.2159\n",
      "Epoch 506/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3839 - val_accuracy: 0.9743 - val_loss: 0.2156\n",
      "Epoch 507/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3840 - val_accuracy: 0.9714 - val_loss: 0.2154\n",
      "Epoch 508/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3839 - val_accuracy: 0.9743 - val_loss: 0.2159\n",
      "Epoch 509/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3841 - val_accuracy: 0.9743 - val_loss: 0.2160\n",
      "Epoch 510/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3840 - val_accuracy: 0.9743 - val_loss: 0.2155\n",
      "Epoch 511/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3837 - val_accuracy: 0.9743 - val_loss: 0.2153\n",
      "Epoch 512/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3840 - val_accuracy: 0.9743 - val_loss: 0.2154\n",
      "Epoch 513/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3837 - val_accuracy: 0.9743 - val_loss: 0.2156\n",
      "Epoch 514/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3839 - val_accuracy: 0.9743 - val_loss: 0.2155\n",
      "Epoch 515/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3838 - val_accuracy: 0.9743 - val_loss: 0.2152\n",
      "Epoch 516/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3837 - val_accuracy: 0.9743 - val_loss: 0.2153\n",
      "Epoch 517/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3835 - val_accuracy: 0.9743 - val_loss: 0.2152\n",
      "Epoch 518/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3836 - val_accuracy: 0.9743 - val_loss: 0.2152\n",
      "Epoch 519/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3834 - val_accuracy: 0.9714 - val_loss: 0.2151\n",
      "Epoch 520/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3833 - val_accuracy: 0.9743 - val_loss: 0.2147\n",
      "Epoch 521/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3835 - val_accuracy: 0.9743 - val_loss: 0.2152\n",
      "Epoch 522/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3833 - val_accuracy: 0.9743 - val_loss: 0.2148\n",
      "Epoch 523/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3833 - val_accuracy: 0.9743 - val_loss: 0.2147\n",
      "Epoch 524/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3832 - val_accuracy: 0.9743 - val_loss: 0.2148\n",
      "Epoch 525/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3831 - val_accuracy: 0.9743 - val_loss: 0.2148\n",
      "Epoch 526/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3833 - val_accuracy: 0.9714 - val_loss: 0.2152\n",
      "Epoch 527/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3831 - val_accuracy: 0.9714 - val_loss: 0.2151\n",
      "Epoch 528/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3831 - val_accuracy: 0.9771 - val_loss: 0.2144\n",
      "Epoch 529/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3831 - val_accuracy: 0.9714 - val_loss: 0.2148\n",
      "Epoch 530/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3829 - val_accuracy: 0.9686 - val_loss: 0.2141\n",
      "Epoch 531/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3828 - val_accuracy: 0.9743 - val_loss: 0.2144\n",
      "Epoch 532/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3830 - val_accuracy: 0.9714 - val_loss: 0.2145\n",
      "Epoch 533/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3827 - val_accuracy: 0.9743 - val_loss: 0.2142\n",
      "Epoch 534/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3828 - val_accuracy: 0.9714 - val_loss: 0.2147\n",
      "Epoch 535/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3828 - val_accuracy: 0.9714 - val_loss: 0.2147\n",
      "Epoch 536/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3826 - val_accuracy: 0.9743 - val_loss: 0.2142\n",
      "Epoch 537/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3827 - val_accuracy: 0.9714 - val_loss: 0.2143\n",
      "Epoch 538/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3826 - val_accuracy: 0.9714 - val_loss: 0.2143\n",
      "Epoch 539/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3826 - val_accuracy: 0.9686 - val_loss: 0.2145\n",
      "Epoch 540/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3824 - val_accuracy: 0.9743 - val_loss: 0.2142\n",
      "Epoch 541/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3826 - val_accuracy: 0.9686 - val_loss: 0.2143\n",
      "Epoch 542/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8477 - loss: 0.3823 - val_accuracy: 0.9714 - val_loss: 0.2144\n",
      "Epoch 543/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3824 - val_accuracy: 0.9686 - val_loss: 0.2138\n",
      "Epoch 544/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3823 - val_accuracy: 0.9657 - val_loss: 0.2142\n",
      "Epoch 545/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3822 - val_accuracy: 0.9714 - val_loss: 0.2141\n",
      "Epoch 546/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3822 - val_accuracy: 0.9686 - val_loss: 0.2139\n",
      "Epoch 547/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3821 - val_accuracy: 0.9686 - val_loss: 0.2138\n",
      "Epoch 548/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3822 - val_accuracy: 0.9743 - val_loss: 0.2137\n",
      "Epoch 549/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3820 - val_accuracy: 0.9714 - val_loss: 0.2143\n",
      "Epoch 550/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3822 - val_accuracy: 0.9743 - val_loss: 0.2141\n",
      "Epoch 551/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3820 - val_accuracy: 0.9686 - val_loss: 0.2142\n",
      "Epoch 552/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8485 - loss: 0.3819 - val_accuracy: 0.9686 - val_loss: 0.2138\n",
      "Epoch 553/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3819 - val_accuracy: 0.9743 - val_loss: 0.2131\n",
      "Epoch 554/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3819 - val_accuracy: 0.9657 - val_loss: 0.2139\n",
      "Epoch 555/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3819 - val_accuracy: 0.9714 - val_loss: 0.2140\n",
      "Epoch 556/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3819 - val_accuracy: 0.9657 - val_loss: 0.2134\n",
      "Epoch 557/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3817 - val_accuracy: 0.9743 - val_loss: 0.2134\n",
      "Epoch 558/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3817 - val_accuracy: 0.9686 - val_loss: 0.2133\n",
      "Epoch 559/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3816 - val_accuracy: 0.9686 - val_loss: 0.2138\n",
      "Epoch 560/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8485 - loss: 0.3816 - val_accuracy: 0.9686 - val_loss: 0.2139\n",
      "Epoch 561/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3816 - val_accuracy: 0.9743 - val_loss: 0.2137\n",
      "Epoch 562/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3816 - val_accuracy: 0.9686 - val_loss: 0.2139\n",
      "Epoch 563/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3815 - val_accuracy: 0.9657 - val_loss: 0.2139\n",
      "Epoch 564/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8485 - loss: 0.3816 - val_accuracy: 0.9686 - val_loss: 0.2143\n",
      "Epoch 565/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3817 - val_accuracy: 0.9657 - val_loss: 0.2144\n",
      "Epoch 566/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3814 - val_accuracy: 0.9657 - val_loss: 0.2145\n",
      "Epoch 567/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3815 - val_accuracy: 0.9686 - val_loss: 0.2141\n",
      "Epoch 568/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8485 - loss: 0.3815 - val_accuracy: 0.9657 - val_loss: 0.2144\n",
      "Epoch 569/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8485 - loss: 0.3812 - val_accuracy: 0.9657 - val_loss: 0.2137\n",
      "Epoch 570/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3814 - val_accuracy: 0.9686 - val_loss: 0.2144\n",
      "Epoch 571/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3815 - val_accuracy: 0.9657 - val_loss: 0.2142\n",
      "Epoch 572/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8485 - loss: 0.3815 - val_accuracy: 0.9629 - val_loss: 0.2145\n",
      "Epoch 573/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8485 - loss: 0.3811 - val_accuracy: 0.9657 - val_loss: 0.2140\n",
      "Epoch 574/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8485 - loss: 0.3811 - val_accuracy: 0.9657 - val_loss: 0.2137\n",
      "Epoch 575/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3811 - val_accuracy: 0.9657 - val_loss: 0.2136\n",
      "Epoch 576/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3812 - val_accuracy: 0.9657 - val_loss: 0.2139\n",
      "Epoch 577/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3811 - val_accuracy: 0.9629 - val_loss: 0.2141\n",
      "Epoch 578/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3812 - val_accuracy: 0.9657 - val_loss: 0.2141\n",
      "Epoch 579/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3812 - val_accuracy: 0.9657 - val_loss: 0.2142\n",
      "Epoch 580/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3810 - val_accuracy: 0.9657 - val_loss: 0.2135\n",
      "Epoch 581/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3812 - val_accuracy: 0.9657 - val_loss: 0.2139\n",
      "Epoch 582/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8485 - loss: 0.3811 - val_accuracy: 0.9657 - val_loss: 0.2142\n",
      "Epoch 583/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3810 - val_accuracy: 0.9657 - val_loss: 0.2138\n",
      "Epoch 584/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3811 - val_accuracy: 0.9657 - val_loss: 0.2137\n",
      "Epoch 585/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8477 - loss: 0.3807 - val_accuracy: 0.9657 - val_loss: 0.2131\n",
      "Epoch 586/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3809 - val_accuracy: 0.9629 - val_loss: 0.2134\n",
      "Epoch 587/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3809 - val_accuracy: 0.9657 - val_loss: 0.2138\n",
      "Epoch 588/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3807 - val_accuracy: 0.9657 - val_loss: 0.2136\n",
      "Epoch 589/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3810 - val_accuracy: 0.9657 - val_loss: 0.2139\n",
      "Epoch 590/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3807 - val_accuracy: 0.9657 - val_loss: 0.2131\n",
      "Epoch 591/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3806 - val_accuracy: 0.9657 - val_loss: 0.2132\n",
      "Epoch 592/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3806 - val_accuracy: 0.9657 - val_loss: 0.2135\n",
      "Epoch 593/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3806 - val_accuracy: 0.9657 - val_loss: 0.2136\n",
      "Epoch 594/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3806 - val_accuracy: 0.9657 - val_loss: 0.2134\n",
      "Epoch 595/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8485 - loss: 0.3805 - val_accuracy: 0.9657 - val_loss: 0.2134\n",
      "Epoch 596/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3808 - val_accuracy: 0.9657 - val_loss: 0.2134\n",
      "Epoch 597/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3804 - val_accuracy: 0.9657 - val_loss: 0.2131\n",
      "Epoch 598/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8485 - loss: 0.3802 - val_accuracy: 0.9657 - val_loss: 0.2125\n",
      "Epoch 599/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3803 - val_accuracy: 0.9657 - val_loss: 0.2133\n",
      "Epoch 600/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3804 - val_accuracy: 0.9657 - val_loss: 0.2132\n",
      "Epoch 601/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3805 - val_accuracy: 0.9657 - val_loss: 0.2132\n",
      "Epoch 602/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3803 - val_accuracy: 0.9657 - val_loss: 0.2135\n",
      "Epoch 603/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3803 - val_accuracy: 0.9657 - val_loss: 0.2130\n",
      "Epoch 604/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3803 - val_accuracy: 0.9657 - val_loss: 0.2135\n",
      "Epoch 605/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8485 - loss: 0.3801 - val_accuracy: 0.9657 - val_loss: 0.2127\n",
      "Epoch 606/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3802 - val_accuracy: 0.9657 - val_loss: 0.2133\n",
      "Epoch 607/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3799 - val_accuracy: 0.9657 - val_loss: 0.2130\n",
      "Epoch 608/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3802 - val_accuracy: 0.9657 - val_loss: 0.2130\n",
      "Epoch 609/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3800 - val_accuracy: 0.9657 - val_loss: 0.2127\n",
      "Epoch 610/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3800 - val_accuracy: 0.9657 - val_loss: 0.2131\n",
      "Epoch 611/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3800 - val_accuracy: 0.9657 - val_loss: 0.2127\n",
      "Epoch 612/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3799 - val_accuracy: 0.9657 - val_loss: 0.2132\n",
      "Epoch 613/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3802 - val_accuracy: 0.9657 - val_loss: 0.2130\n",
      "Epoch 614/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3800 - val_accuracy: 0.9657 - val_loss: 0.2129\n",
      "Epoch 615/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3798 - val_accuracy: 0.9657 - val_loss: 0.2121\n",
      "Epoch 616/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3798 - val_accuracy: 0.9657 - val_loss: 0.2128\n",
      "Epoch 617/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3797 - val_accuracy: 0.9657 - val_loss: 0.2127\n",
      "Epoch 618/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3799 - val_accuracy: 0.9657 - val_loss: 0.2129\n",
      "Epoch 619/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3796 - val_accuracy: 0.9657 - val_loss: 0.2125\n",
      "Epoch 620/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3797 - val_accuracy: 0.9657 - val_loss: 0.2128\n",
      "Epoch 621/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3798 - val_accuracy: 0.9657 - val_loss: 0.2130\n",
      "Epoch 622/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3793 - val_accuracy: 0.9657 - val_loss: 0.2123\n",
      "Epoch 623/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3796 - val_accuracy: 0.9657 - val_loss: 0.2126\n",
      "Epoch 624/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3795 - val_accuracy: 0.9657 - val_loss: 0.2127\n",
      "Epoch 625/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8477 - loss: 0.3795 - val_accuracy: 0.9657 - val_loss: 0.2129\n",
      "Epoch 626/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3796 - val_accuracy: 0.9629 - val_loss: 0.2131\n",
      "Epoch 627/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3794 - val_accuracy: 0.9657 - val_loss: 0.2115\n",
      "Epoch 628/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3795 - val_accuracy: 0.9657 - val_loss: 0.2129\n",
      "Epoch 629/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3795 - val_accuracy: 0.9657 - val_loss: 0.2125\n",
      "Epoch 630/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8462 - loss: 0.3794 - val_accuracy: 0.9629 - val_loss: 0.2125\n",
      "Epoch 631/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3791 - val_accuracy: 0.9657 - val_loss: 0.2116\n",
      "Epoch 632/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3795 - val_accuracy: 0.9657 - val_loss: 0.2127\n",
      "Epoch 633/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3794 - val_accuracy: 0.9657 - val_loss: 0.2123\n",
      "Epoch 634/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3793 - val_accuracy: 0.9629 - val_loss: 0.2130\n",
      "Epoch 635/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3792 - val_accuracy: 0.9657 - val_loss: 0.2119\n",
      "Epoch 636/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8462 - loss: 0.3790 - val_accuracy: 0.9629 - val_loss: 0.2128\n",
      "Epoch 637/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8469 - loss: 0.3791 - val_accuracy: 0.9657 - val_loss: 0.2124\n",
      "Epoch 638/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3787 - val_accuracy: 0.9629 - val_loss: 0.2113\n",
      "Epoch 639/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3791 - val_accuracy: 0.9686 - val_loss: 0.2121\n",
      "Epoch 640/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3790 - val_accuracy: 0.9629 - val_loss: 0.2118\n",
      "Epoch 641/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3788 - val_accuracy: 0.9657 - val_loss: 0.2123\n",
      "Epoch 642/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3789 - val_accuracy: 0.9657 - val_loss: 0.2117\n",
      "Epoch 643/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3790 - val_accuracy: 0.9629 - val_loss: 0.2124\n",
      "Epoch 644/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3788 - val_accuracy: 0.9657 - val_loss: 0.2121\n",
      "Epoch 645/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3784 - val_accuracy: 0.9657 - val_loss: 0.2109\n",
      "Epoch 646/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3787 - val_accuracy: 0.9657 - val_loss: 0.2119\n",
      "Epoch 647/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3787 - val_accuracy: 0.9657 - val_loss: 0.2116\n",
      "Epoch 648/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3785 - val_accuracy: 0.9657 - val_loss: 0.2118\n",
      "Epoch 649/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3784 - val_accuracy: 0.9657 - val_loss: 0.2116\n",
      "Epoch 650/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3785 - val_accuracy: 0.9657 - val_loss: 0.2118\n",
      "Epoch 651/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3785 - val_accuracy: 0.9657 - val_loss: 0.2118\n",
      "Epoch 652/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3786 - val_accuracy: 0.9657 - val_loss: 0.2121\n",
      "Epoch 653/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3785 - val_accuracy: 0.9657 - val_loss: 0.2115\n",
      "Epoch 654/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3782 - val_accuracy: 0.9657 - val_loss: 0.2116\n",
      "Epoch 655/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3784 - val_accuracy: 0.9657 - val_loss: 0.2117\n",
      "Epoch 656/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3782 - val_accuracy: 0.9657 - val_loss: 0.2115\n",
      "Epoch 657/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3783 - val_accuracy: 0.9657 - val_loss: 0.2121\n",
      "Epoch 658/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3781 - val_accuracy: 0.9657 - val_loss: 0.2108\n",
      "Epoch 659/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3781 - val_accuracy: 0.9629 - val_loss: 0.2116\n",
      "Epoch 660/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3781 - val_accuracy: 0.9657 - val_loss: 0.2120\n",
      "Epoch 661/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3780 - val_accuracy: 0.9657 - val_loss: 0.2115\n",
      "Epoch 662/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3777 - val_accuracy: 0.9686 - val_loss: 0.2113\n",
      "Epoch 663/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3781 - val_accuracy: 0.9657 - val_loss: 0.2117\n",
      "Epoch 664/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3779 - val_accuracy: 0.9686 - val_loss: 0.2114\n",
      "Epoch 665/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3777 - val_accuracy: 0.9657 - val_loss: 0.2117\n",
      "Epoch 666/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3780 - val_accuracy: 0.9686 - val_loss: 0.2113\n",
      "Epoch 667/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3775 - val_accuracy: 0.9657 - val_loss: 0.2110\n",
      "Epoch 668/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3781 - val_accuracy: 0.9657 - val_loss: 0.2115\n",
      "Epoch 669/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3778 - val_accuracy: 0.9629 - val_loss: 0.2112\n",
      "Epoch 670/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3777 - val_accuracy: 0.9657 - val_loss: 0.2114\n",
      "Epoch 671/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3776 - val_accuracy: 0.9657 - val_loss: 0.2110\n",
      "Epoch 672/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3776 - val_accuracy: 0.9657 - val_loss: 0.2119\n",
      "Epoch 673/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8462 - loss: 0.3775 - val_accuracy: 0.9629 - val_loss: 0.2110\n",
      "Epoch 674/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3776 - val_accuracy: 0.9657 - val_loss: 0.2116\n",
      "Epoch 675/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3775 - val_accuracy: 0.9657 - val_loss: 0.2105\n",
      "Epoch 676/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3775 - val_accuracy: 0.9629 - val_loss: 0.2116\n",
      "Epoch 677/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3776 - val_accuracy: 0.9629 - val_loss: 0.2120\n",
      "Epoch 678/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3777 - val_accuracy: 0.9657 - val_loss: 0.2115\n",
      "Epoch 679/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8462 - loss: 0.3775 - val_accuracy: 0.9657 - val_loss: 0.2113\n",
      "Epoch 680/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3776 - val_accuracy: 0.9629 - val_loss: 0.2115\n",
      "Epoch 681/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3773 - val_accuracy: 0.9657 - val_loss: 0.2108\n",
      "Epoch 682/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3774 - val_accuracy: 0.9629 - val_loss: 0.2110\n",
      "Epoch 683/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3772 - val_accuracy: 0.9686 - val_loss: 0.2108\n",
      "Epoch 684/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3772 - val_accuracy: 0.9657 - val_loss: 0.2102\n",
      "Epoch 685/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3770 - val_accuracy: 0.9657 - val_loss: 0.2111\n",
      "Epoch 686/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3772 - val_accuracy: 0.9657 - val_loss: 0.2113\n",
      "Epoch 687/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3770 - val_accuracy: 0.9657 - val_loss: 0.2106\n",
      "Epoch 688/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3775 - val_accuracy: 0.9657 - val_loss: 0.2112\n",
      "Epoch 689/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3773 - val_accuracy: 0.9657 - val_loss: 0.2114\n",
      "Epoch 690/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3771 - val_accuracy: 0.9657 - val_loss: 0.2108\n",
      "Epoch 691/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3769 - val_accuracy: 0.9657 - val_loss: 0.2105\n",
      "Epoch 692/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3771 - val_accuracy: 0.9657 - val_loss: 0.2112\n",
      "Epoch 693/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3772 - val_accuracy: 0.9657 - val_loss: 0.2112\n",
      "Epoch 694/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3769 - val_accuracy: 0.9657 - val_loss: 0.2112\n",
      "Epoch 695/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3768 - val_accuracy: 0.9629 - val_loss: 0.2105\n",
      "Epoch 696/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3772 - val_accuracy: 0.9686 - val_loss: 0.2107\n",
      "Epoch 697/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3770 - val_accuracy: 0.9657 - val_loss: 0.2111\n",
      "Epoch 698/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3770 - val_accuracy: 0.9657 - val_loss: 0.2111\n",
      "Epoch 699/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3771 - val_accuracy: 0.9657 - val_loss: 0.2110\n",
      "Epoch 700/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3769 - val_accuracy: 0.9657 - val_loss: 0.2108\n",
      "Epoch 701/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3772 - val_accuracy: 0.9657 - val_loss: 0.2109\n",
      "Epoch 702/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3769 - val_accuracy: 0.9657 - val_loss: 0.2107\n",
      "Epoch 703/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3768 - val_accuracy: 0.9657 - val_loss: 0.2109\n",
      "Epoch 704/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3767 - val_accuracy: 0.9657 - val_loss: 0.2104\n",
      "Epoch 705/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3767 - val_accuracy: 0.9657 - val_loss: 0.2110\n",
      "Epoch 706/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3766 - val_accuracy: 0.9657 - val_loss: 0.2104\n",
      "Epoch 707/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3768 - val_accuracy: 0.9657 - val_loss: 0.2111\n",
      "Epoch 708/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3770 - val_accuracy: 0.9657 - val_loss: 0.2106\n",
      "Epoch 709/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3766 - val_accuracy: 0.9657 - val_loss: 0.2111\n",
      "Epoch 710/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3768 - val_accuracy: 0.9629 - val_loss: 0.2104\n",
      "Epoch 711/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3765 - val_accuracy: 0.9657 - val_loss: 0.2101\n",
      "Epoch 712/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3766 - val_accuracy: 0.9657 - val_loss: 0.2108\n",
      "Epoch 713/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8454 - loss: 0.3766 - val_accuracy: 0.9629 - val_loss: 0.2106\n",
      "Epoch 714/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3765 - val_accuracy: 0.9657 - val_loss: 0.2103\n",
      "Epoch 715/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3766 - val_accuracy: 0.9657 - val_loss: 0.2104\n",
      "Epoch 716/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3766 - val_accuracy: 0.9629 - val_loss: 0.2108\n",
      "Epoch 717/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3765 - val_accuracy: 0.9657 - val_loss: 0.2102\n",
      "Epoch 718/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3765 - val_accuracy: 0.9657 - val_loss: 0.2106\n",
      "Epoch 719/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3766 - val_accuracy: 0.9657 - val_loss: 0.2100\n",
      "Epoch 720/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8454 - loss: 0.3765 - val_accuracy: 0.9657 - val_loss: 0.2102\n",
      "Epoch 721/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3764 - val_accuracy: 0.9657 - val_loss: 0.2104\n",
      "Epoch 722/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3765 - val_accuracy: 0.9657 - val_loss: 0.2099\n",
      "Epoch 723/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3763 - val_accuracy: 0.9657 - val_loss: 0.2103\n",
      "Epoch 724/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3762 - val_accuracy: 0.9629 - val_loss: 0.2100\n",
      "Epoch 725/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3761 - val_accuracy: 0.9657 - val_loss: 0.2103\n",
      "Epoch 726/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3764 - val_accuracy: 0.9657 - val_loss: 0.2100\n",
      "Epoch 727/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3763 - val_accuracy: 0.9657 - val_loss: 0.2101\n",
      "Epoch 728/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8446 - loss: 0.3763 - val_accuracy: 0.9657 - val_loss: 0.2095\n",
      "Epoch 729/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3760 - val_accuracy: 0.9629 - val_loss: 0.2101\n",
      "Epoch 730/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3760 - val_accuracy: 0.9657 - val_loss: 0.2091\n",
      "Epoch 731/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3759 - val_accuracy: 0.9629 - val_loss: 0.2102\n",
      "Epoch 732/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3762 - val_accuracy: 0.9629 - val_loss: 0.2105\n",
      "Epoch 733/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3761 - val_accuracy: 0.9657 - val_loss: 0.2104\n",
      "Epoch 734/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3759 - val_accuracy: 0.9657 - val_loss: 0.2092\n",
      "Epoch 735/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3760 - val_accuracy: 0.9657 - val_loss: 0.2098\n",
      "Epoch 736/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3760 - val_accuracy: 0.9657 - val_loss: 0.2095\n",
      "Epoch 737/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3758 - val_accuracy: 0.9629 - val_loss: 0.2100\n",
      "Epoch 738/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3757 - val_accuracy: 0.9657 - val_loss: 0.2090\n",
      "Epoch 739/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3754 - val_accuracy: 0.9629 - val_loss: 0.2093\n",
      "Epoch 740/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3754 - val_accuracy: 0.9657 - val_loss: 0.2097\n",
      "Epoch 741/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3756 - val_accuracy: 0.9657 - val_loss: 0.2095\n",
      "Epoch 742/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.3751 - val_accuracy: 0.9629 - val_loss: 0.2100\n",
      "Epoch 743/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3757 - val_accuracy: 0.9629 - val_loss: 0.2095\n",
      "Epoch 744/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3755 - val_accuracy: 0.9657 - val_loss: 0.2100\n",
      "Epoch 745/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3758 - val_accuracy: 0.9629 - val_loss: 0.2095\n",
      "Epoch 746/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3751 - val_accuracy: 0.9629 - val_loss: 0.2096\n",
      "Epoch 747/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3754 - val_accuracy: 0.9657 - val_loss: 0.2094\n",
      "Epoch 748/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3756 - val_accuracy: 0.9657 - val_loss: 0.2093\n",
      "Epoch 749/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3750 - val_accuracy: 0.9629 - val_loss: 0.2094\n",
      "Epoch 750/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3752 - val_accuracy: 0.9629 - val_loss: 0.2097\n",
      "Epoch 751/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3749 - val_accuracy: 0.9657 - val_loss: 0.2090\n",
      "Epoch 752/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3751 - val_accuracy: 0.9657 - val_loss: 0.2093\n",
      "Epoch 753/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3749 - val_accuracy: 0.9657 - val_loss: 0.2090\n",
      "Epoch 754/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3753 - val_accuracy: 0.9657 - val_loss: 0.2093\n",
      "Epoch 755/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3747 - val_accuracy: 0.9686 - val_loss: 0.2087\n",
      "Epoch 756/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3751 - val_accuracy: 0.9686 - val_loss: 0.2092\n",
      "Epoch 757/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.3751 - val_accuracy: 0.9657 - val_loss: 0.2093\n",
      "Epoch 758/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3750 - val_accuracy: 0.9657 - val_loss: 0.2091\n",
      "Epoch 759/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3746 - val_accuracy: 0.9657 - val_loss: 0.2085\n",
      "Epoch 760/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3751 - val_accuracy: 0.9657 - val_loss: 0.2094\n",
      "Epoch 761/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3747 - val_accuracy: 0.9657 - val_loss: 0.2088\n",
      "Epoch 762/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8454 - loss: 0.3746 - val_accuracy: 0.9629 - val_loss: 0.2089\n",
      "Epoch 763/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3746 - val_accuracy: 0.9629 - val_loss: 0.2087\n",
      "Epoch 764/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3748 - val_accuracy: 0.9657 - val_loss: 0.2088\n",
      "Epoch 765/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3745 - val_accuracy: 0.9629 - val_loss: 0.2079\n",
      "Epoch 766/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.3747 - val_accuracy: 0.9657 - val_loss: 0.2083\n",
      "Epoch 767/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3742 - val_accuracy: 0.9629 - val_loss: 0.2088\n",
      "Epoch 768/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3746 - val_accuracy: 0.9657 - val_loss: 0.2082\n",
      "Epoch 769/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3745 - val_accuracy: 0.9629 - val_loss: 0.2086\n",
      "Epoch 770/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.3742 - val_accuracy: 0.9629 - val_loss: 0.2084\n",
      "Epoch 771/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3744 - val_accuracy: 0.9657 - val_loss: 0.2084\n",
      "Epoch 772/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8446 - loss: 0.3745 - val_accuracy: 0.9657 - val_loss: 0.2084\n",
      "Epoch 773/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8446 - loss: 0.3740 - val_accuracy: 0.9629 - val_loss: 0.2090\n",
      "Epoch 774/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3744 - val_accuracy: 0.9629 - val_loss: 0.2085\n",
      "Epoch 775/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3744 - val_accuracy: 0.9629 - val_loss: 0.2094\n",
      "Epoch 776/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3743 - val_accuracy: 0.9657 - val_loss: 0.2084\n",
      "Epoch 777/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3743 - val_accuracy: 0.9657 - val_loss: 0.2088\n",
      "Epoch 778/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3741 - val_accuracy: 0.9714 - val_loss: 0.2081\n",
      "Epoch 779/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3745 - val_accuracy: 0.9657 - val_loss: 0.2081\n",
      "Epoch 780/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3742 - val_accuracy: 0.9657 - val_loss: 0.2086\n",
      "Epoch 781/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.3740 - val_accuracy: 0.9686 - val_loss: 0.2086\n",
      "Epoch 782/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3740 - val_accuracy: 0.9629 - val_loss: 0.2081\n",
      "Epoch 783/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3741 - val_accuracy: 0.9657 - val_loss: 0.2076\n",
      "Epoch 784/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3742 - val_accuracy: 0.9657 - val_loss: 0.2087\n",
      "Epoch 785/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3740 - val_accuracy: 0.9657 - val_loss: 0.2078\n",
      "Epoch 786/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3738 - val_accuracy: 0.9657 - val_loss: 0.2084\n",
      "Epoch 787/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3741 - val_accuracy: 0.9657 - val_loss: 0.2077\n",
      "Epoch 788/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3739 - val_accuracy: 0.9657 - val_loss: 0.2081\n",
      "Epoch 789/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3742 - val_accuracy: 0.9657 - val_loss: 0.2083\n",
      "Epoch 790/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3740 - val_accuracy: 0.9657 - val_loss: 0.2077\n",
      "Epoch 791/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3741 - val_accuracy: 0.9657 - val_loss: 0.2077\n",
      "Epoch 792/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3736 - val_accuracy: 0.9714 - val_loss: 0.2075\n",
      "Epoch 793/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3740 - val_accuracy: 0.9657 - val_loss: 0.2078\n",
      "Epoch 794/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.3736 - val_accuracy: 0.9686 - val_loss: 0.2070\n",
      "Epoch 795/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3739 - val_accuracy: 0.9657 - val_loss: 0.2074\n",
      "Epoch 796/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3736 - val_accuracy: 0.9657 - val_loss: 0.2074\n",
      "Epoch 797/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3734 - val_accuracy: 0.9686 - val_loss: 0.2078\n",
      "Epoch 798/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3738 - val_accuracy: 0.9686 - val_loss: 0.2067\n",
      "Epoch 799/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3735 - val_accuracy: 0.9657 - val_loss: 0.2074\n",
      "Epoch 800/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3738 - val_accuracy: 0.9657 - val_loss: 0.2074\n",
      "Epoch 801/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3732 - val_accuracy: 0.9714 - val_loss: 0.2064\n",
      "Epoch 802/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3739 - val_accuracy: 0.9686 - val_loss: 0.2081\n",
      "Epoch 803/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8438 - loss: 0.3736 - val_accuracy: 0.9657 - val_loss: 0.2071\n",
      "Epoch 804/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3731 - val_accuracy: 0.9686 - val_loss: 0.2069\n",
      "Epoch 805/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.3729 - val_accuracy: 0.9714 - val_loss: 0.2063\n",
      "Epoch 806/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3737 - val_accuracy: 0.9657 - val_loss: 0.2077\n",
      "Epoch 807/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.3736 - val_accuracy: 0.9657 - val_loss: 0.2076\n",
      "Epoch 808/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8446 - loss: 0.3732 - val_accuracy: 0.9657 - val_loss: 0.2076\n",
      "Epoch 809/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3737 - val_accuracy: 0.9657 - val_loss: 0.2075\n",
      "Epoch 810/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3734 - val_accuracy: 0.9629 - val_loss: 0.2070\n",
      "Epoch 811/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3733 - val_accuracy: 0.9657 - val_loss: 0.2073\n",
      "Epoch 812/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3737 - val_accuracy: 0.9657 - val_loss: 0.2072\n",
      "Epoch 813/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3732 - val_accuracy: 0.9629 - val_loss: 0.2063\n",
      "Epoch 814/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8446 - loss: 0.3731 - val_accuracy: 0.9657 - val_loss: 0.2073\n",
      "Epoch 815/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3735 - val_accuracy: 0.9657 - val_loss: 0.2065\n",
      "Epoch 816/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3731 - val_accuracy: 0.9714 - val_loss: 0.2073\n",
      "Epoch 817/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3734 - val_accuracy: 0.9629 - val_loss: 0.2070\n",
      "Epoch 818/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3733 - val_accuracy: 0.9686 - val_loss: 0.2067\n",
      "Epoch 819/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3731 - val_accuracy: 0.9629 - val_loss: 0.2068\n",
      "Epoch 820/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.3732 - val_accuracy: 0.9629 - val_loss: 0.2072\n",
      "Epoch 821/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3727 - val_accuracy: 0.9686 - val_loss: 0.2060\n",
      "Epoch 822/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3731 - val_accuracy: 0.9629 - val_loss: 0.2075\n",
      "Epoch 823/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3732 - val_accuracy: 0.9743 - val_loss: 0.2061\n",
      "Epoch 824/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.3728 - val_accuracy: 0.9629 - val_loss: 0.2068\n",
      "Epoch 825/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3728 - val_accuracy: 0.9657 - val_loss: 0.2068\n",
      "Epoch 826/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3732 - val_accuracy: 0.9657 - val_loss: 0.2069\n",
      "Epoch 827/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3727 - val_accuracy: 0.9714 - val_loss: 0.2056\n",
      "Epoch 828/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3729 - val_accuracy: 0.9629 - val_loss: 0.2072\n",
      "Epoch 829/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.3731 - val_accuracy: 0.9714 - val_loss: 0.2062\n",
      "Epoch 830/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3725 - val_accuracy: 0.9657 - val_loss: 0.2058\n",
      "Epoch 831/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3729 - val_accuracy: 0.9657 - val_loss: 0.2065\n",
      "Epoch 832/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3724 - val_accuracy: 0.9686 - val_loss: 0.2063\n",
      "Epoch 833/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3723 - val_accuracy: 0.9657 - val_loss: 0.2064\n",
      "Epoch 834/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3727 - val_accuracy: 0.9629 - val_loss: 0.2058\n",
      "Epoch 835/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3728 - val_accuracy: 0.9686 - val_loss: 0.2070\n",
      "Epoch 836/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3726 - val_accuracy: 0.9714 - val_loss: 0.2061\n",
      "Epoch 837/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3725 - val_accuracy: 0.9657 - val_loss: 0.2064\n",
      "Epoch 838/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3726 - val_accuracy: 0.9686 - val_loss: 0.2067\n",
      "Epoch 839/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3727 - val_accuracy: 0.9686 - val_loss: 0.2061\n",
      "Epoch 840/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3723 - val_accuracy: 0.9629 - val_loss: 0.2065\n",
      "Epoch 841/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3724 - val_accuracy: 0.9657 - val_loss: 0.2055\n",
      "Epoch 842/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3724 - val_accuracy: 0.9657 - val_loss: 0.2067\n",
      "Epoch 843/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3721 - val_accuracy: 0.9657 - val_loss: 0.2060\n",
      "Epoch 844/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3720 - val_accuracy: 0.9743 - val_loss: 0.2057\n",
      "Epoch 845/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3723 - val_accuracy: 0.9714 - val_loss: 0.2056\n",
      "Epoch 846/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3719 - val_accuracy: 0.9686 - val_loss: 0.2053\n",
      "Epoch 847/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3727 - val_accuracy: 0.9743 - val_loss: 0.2057\n",
      "Epoch 848/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3722 - val_accuracy: 0.9743 - val_loss: 0.2057\n",
      "Epoch 849/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3721 - val_accuracy: 0.9686 - val_loss: 0.2052\n",
      "Epoch 850/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8446 - loss: 0.3723 - val_accuracy: 0.9714 - val_loss: 0.2061\n",
      "Epoch 851/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3720 - val_accuracy: 0.9714 - val_loss: 0.2049\n",
      "Epoch 852/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3717 - val_accuracy: 0.9743 - val_loss: 0.2059\n",
      "Epoch 853/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3718 - val_accuracy: 0.9743 - val_loss: 0.2052\n",
      "Epoch 854/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3723 - val_accuracy: 0.9743 - val_loss: 0.2057\n",
      "Epoch 855/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3721 - val_accuracy: 0.9686 - val_loss: 0.2061\n",
      "Epoch 856/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3717 - val_accuracy: 0.9743 - val_loss: 0.2049\n",
      "Epoch 857/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3721 - val_accuracy: 0.9743 - val_loss: 0.2055\n",
      "Epoch 858/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3717 - val_accuracy: 0.9714 - val_loss: 0.2053\n",
      "Epoch 859/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3718 - val_accuracy: 0.9714 - val_loss: 0.2057\n",
      "Epoch 860/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3717 - val_accuracy: 0.9743 - val_loss: 0.2058\n",
      "Epoch 861/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3718 - val_accuracy: 0.9743 - val_loss: 0.2051\n",
      "Epoch 862/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8446 - loss: 0.3720 - val_accuracy: 0.9714 - val_loss: 0.2059\n",
      "Epoch 863/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8438 - loss: 0.3716 - val_accuracy: 0.9714 - val_loss: 0.2041\n",
      "Epoch 864/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3721 - val_accuracy: 0.9714 - val_loss: 0.2059\n",
      "Epoch 865/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8438 - loss: 0.3717 - val_accuracy: 0.9686 - val_loss: 0.2047\n",
      "Epoch 866/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3716 - val_accuracy: 0.9743 - val_loss: 0.2054\n",
      "Epoch 867/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3716 - val_accuracy: 0.9686 - val_loss: 0.2050\n",
      "Epoch 868/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3719 - val_accuracy: 0.9743 - val_loss: 0.2049\n",
      "Epoch 869/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3715 - val_accuracy: 0.9743 - val_loss: 0.2055\n",
      "Epoch 870/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3716 - val_accuracy: 0.9686 - val_loss: 0.2057\n",
      "Epoch 871/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3714 - val_accuracy: 0.9743 - val_loss: 0.2052\n",
      "Epoch 872/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3715 - val_accuracy: 0.9714 - val_loss: 0.2051\n",
      "Epoch 873/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3717 - val_accuracy: 0.9743 - val_loss: 0.2056\n",
      "Epoch 874/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.3715 - val_accuracy: 0.9686 - val_loss: 0.2046\n",
      "Epoch 875/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3718 - val_accuracy: 0.9743 - val_loss: 0.2047\n",
      "Epoch 876/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3713 - val_accuracy: 0.9714 - val_loss: 0.2049\n",
      "Epoch 877/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3719 - val_accuracy: 0.9743 - val_loss: 0.2056\n",
      "Epoch 878/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3715 - val_accuracy: 0.9714 - val_loss: 0.2048\n",
      "Epoch 879/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3718 - val_accuracy: 0.9743 - val_loss: 0.2048\n",
      "Epoch 880/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3711 - val_accuracy: 0.9714 - val_loss: 0.2051\n",
      "Epoch 881/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3716 - val_accuracy: 0.9743 - val_loss: 0.2052\n",
      "Epoch 882/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.3714 - val_accuracy: 0.9743 - val_loss: 0.2048\n",
      "Epoch 883/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3714 - val_accuracy: 0.9714 - val_loss: 0.2051\n",
      "Epoch 884/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3714 - val_accuracy: 0.9743 - val_loss: 0.2049\n",
      "Epoch 885/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3709 - val_accuracy: 0.9714 - val_loss: 0.2043\n",
      "Epoch 886/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3716 - val_accuracy: 0.9714 - val_loss: 0.2065\n",
      "Epoch 887/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3716 - val_accuracy: 0.9743 - val_loss: 0.2051\n",
      "Epoch 888/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.3710 - val_accuracy: 0.9771 - val_loss: 0.2042\n",
      "Epoch 889/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3713 - val_accuracy: 0.9743 - val_loss: 0.2052\n",
      "Epoch 890/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.3711 - val_accuracy: 0.9771 - val_loss: 0.2040\n",
      "Epoch 891/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3712 - val_accuracy: 0.9743 - val_loss: 0.2052\n",
      "Epoch 892/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.3712 - val_accuracy: 0.9714 - val_loss: 0.2046\n",
      "Epoch 893/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.3710 - val_accuracy: 0.9714 - val_loss: 0.2050\n",
      "Epoch 894/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.3711 - val_accuracy: 0.9743 - val_loss: 0.2052\n",
      "Epoch 895/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.3707 - val_accuracy: 0.9743 - val_loss: 0.2037\n",
      "Epoch 896/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3710 - val_accuracy: 0.9714 - val_loss: 0.2055\n",
      "Epoch 897/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8431 - loss: 0.3710 - val_accuracy: 0.9743 - val_loss: 0.2043\n",
      "Epoch 898/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.3710 - val_accuracy: 0.9714 - val_loss: 0.2052\n",
      "Epoch 899/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.3707 - val_accuracy: 0.9686 - val_loss: 0.2044\n",
      "Epoch 900/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.3711 - val_accuracy: 0.9714 - val_loss: 0.2058\n",
      "Epoch 901/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8415 - loss: 0.3710 - val_accuracy: 0.9771 - val_loss: 0.2036\n",
      "Epoch 902/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3710 - val_accuracy: 0.9743 - val_loss: 0.2049\n",
      "Epoch 903/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.3707 - val_accuracy: 0.9771 - val_loss: 0.2048\n",
      "Epoch 904/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.3709 - val_accuracy: 0.9714 - val_loss: 0.2048\n",
      "Epoch 905/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.3707 - val_accuracy: 0.9771 - val_loss: 0.2036\n",
      "Epoch 906/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8431 - loss: 0.3713 - val_accuracy: 0.9743 - val_loss: 0.2054\n",
      "Epoch 907/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.3710 - val_accuracy: 0.9743 - val_loss: 0.2044\n",
      "Epoch 908/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.3704 - val_accuracy: 0.9743 - val_loss: 0.2039\n",
      "Epoch 909/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.3708 - val_accuracy: 0.9714 - val_loss: 0.2048\n",
      "Epoch 910/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.3706 - val_accuracy: 0.9771 - val_loss: 0.2051\n",
      "Epoch 911/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.3703 - val_accuracy: 0.9771 - val_loss: 0.2040\n",
      "Epoch 912/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3708 - val_accuracy: 0.9743 - val_loss: 0.2043\n",
      "Epoch 913/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.3705 - val_accuracy: 0.9771 - val_loss: 0.2043\n",
      "Epoch 914/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3707 - val_accuracy: 0.9743 - val_loss: 0.2044\n",
      "Epoch 915/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.3704 - val_accuracy: 0.9771 - val_loss: 0.2045\n",
      "Epoch 916/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.3706 - val_accuracy: 0.9714 - val_loss: 0.2051\n",
      "Epoch 917/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.3703 - val_accuracy: 0.9771 - val_loss: 0.2033\n",
      "Epoch 918/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3706 - val_accuracy: 0.9714 - val_loss: 0.2051\n",
      "Epoch 919/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.3705 - val_accuracy: 0.9743 - val_loss: 0.2039\n",
      "Epoch 920/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.3709 - val_accuracy: 0.9714 - val_loss: 0.2050\n",
      "Epoch 921/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3701 - val_accuracy: 0.9771 - val_loss: 0.2029\n",
      "Epoch 922/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3705 - val_accuracy: 0.9743 - val_loss: 0.2041\n",
      "Epoch 923/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.3707 - val_accuracy: 0.9743 - val_loss: 0.2044\n",
      "Epoch 924/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3704 - val_accuracy: 0.9743 - val_loss: 0.2042\n",
      "Epoch 925/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3701 - val_accuracy: 0.9771 - val_loss: 0.2045\n",
      "Epoch 926/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3707 - val_accuracy: 0.9743 - val_loss: 0.2037\n",
      "Epoch 927/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.3702 - val_accuracy: 0.9743 - val_loss: 0.2044\n",
      "Epoch 928/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.3701 - val_accuracy: 0.9743 - val_loss: 0.2049\n",
      "Epoch 929/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3703 - val_accuracy: 0.9771 - val_loss: 0.2035\n",
      "Epoch 930/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.3705 - val_accuracy: 0.9743 - val_loss: 0.2050\n",
      "Epoch 931/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.3703 - val_accuracy: 0.9743 - val_loss: 0.2044\n",
      "Epoch 932/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3703 - val_accuracy: 0.9714 - val_loss: 0.2045\n",
      "Epoch 933/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.3701 - val_accuracy: 0.9743 - val_loss: 0.2036\n",
      "Epoch 934/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.3702 - val_accuracy: 0.9743 - val_loss: 0.2043\n",
      "Epoch 935/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3699 - val_accuracy: 0.9771 - val_loss: 0.2039\n",
      "Epoch 936/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.3699 - val_accuracy: 0.9771 - val_loss: 0.2038\n",
      "Epoch 937/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.3702 - val_accuracy: 0.9743 - val_loss: 0.2040\n",
      "Epoch 938/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.3699 - val_accuracy: 0.9771 - val_loss: 0.2039\n",
      "Epoch 939/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8415 - loss: 0.3698 - val_accuracy: 0.9743 - val_loss: 0.2036\n",
      "Epoch 940/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8423 - loss: 0.3700 - val_accuracy: 0.9743 - val_loss: 0.2037\n",
      "Epoch 941/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.3700 - val_accuracy: 0.9743 - val_loss: 0.2036\n",
      "Epoch 942/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.3698 - val_accuracy: 0.9743 - val_loss: 0.2039\n",
      "Epoch 943/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.3697 - val_accuracy: 0.9743 - val_loss: 0.2031\n",
      "Epoch 944/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8415 - loss: 0.3695 - val_accuracy: 0.9743 - val_loss: 0.2030\n",
      "Epoch 945/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.3697 - val_accuracy: 0.9771 - val_loss: 0.2037\n",
      "Epoch 946/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.3701 - val_accuracy: 0.9743 - val_loss: 0.2032\n",
      "Epoch 947/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.3696 - val_accuracy: 0.9743 - val_loss: 0.2035\n",
      "Epoch 948/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.3697 - val_accuracy: 0.9743 - val_loss: 0.2038\n",
      "Epoch 949/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.3698 - val_accuracy: 0.9743 - val_loss: 0.2039\n",
      "Epoch 950/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.3695 - val_accuracy: 0.9743 - val_loss: 0.2037\n",
      "Epoch 951/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.3696 - val_accuracy: 0.9743 - val_loss: 0.2040\n",
      "Epoch 952/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.3695 - val_accuracy: 0.9743 - val_loss: 0.2032\n",
      "Epoch 953/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.3694 - val_accuracy: 0.9771 - val_loss: 0.2036\n",
      "Epoch 954/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.3693 - val_accuracy: 0.9743 - val_loss: 0.2039\n",
      "Epoch 955/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.3697 - val_accuracy: 0.9771 - val_loss: 0.2038\n",
      "Epoch 956/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3698 - val_accuracy: 0.9743 - val_loss: 0.2040\n",
      "Epoch 957/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.3697 - val_accuracy: 0.9743 - val_loss: 0.2037\n",
      "Epoch 958/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3693 - val_accuracy: 0.9743 - val_loss: 0.2034\n",
      "Epoch 959/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.3693 - val_accuracy: 0.9771 - val_loss: 0.2033\n",
      "Epoch 960/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.3694 - val_accuracy: 0.9771 - val_loss: 0.2035\n",
      "Epoch 961/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.3696 - val_accuracy: 0.9743 - val_loss: 0.2040\n",
      "Epoch 962/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3697 - val_accuracy: 0.9714 - val_loss: 0.2035\n",
      "Epoch 963/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.3691 - val_accuracy: 0.9771 - val_loss: 0.2026\n",
      "Epoch 964/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.3694 - val_accuracy: 0.9743 - val_loss: 0.2031\n",
      "Epoch 965/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.3693 - val_accuracy: 0.9743 - val_loss: 0.2030\n",
      "Epoch 966/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.3695 - val_accuracy: 0.9743 - val_loss: 0.2036\n",
      "Epoch 967/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3695 - val_accuracy: 0.9743 - val_loss: 0.2036\n",
      "Epoch 968/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.3687 - val_accuracy: 0.9771 - val_loss: 0.2034\n",
      "Epoch 969/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.3690 - val_accuracy: 0.9743 - val_loss: 0.2038\n",
      "Epoch 970/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3690 - val_accuracy: 0.9771 - val_loss: 0.2030\n",
      "Epoch 971/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3695 - val_accuracy: 0.9743 - val_loss: 0.2036\n",
      "Epoch 972/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.3692 - val_accuracy: 0.9743 - val_loss: 0.2036\n",
      "Epoch 973/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.3689 - val_accuracy: 0.9743 - val_loss: 0.2026\n",
      "Epoch 974/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3688 - val_accuracy: 0.9743 - val_loss: 0.2038\n",
      "Epoch 975/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.3686 - val_accuracy: 0.9771 - val_loss: 0.2034\n",
      "Epoch 976/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.3693 - val_accuracy: 0.9743 - val_loss: 0.2044\n",
      "Epoch 977/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.3690 - val_accuracy: 0.9771 - val_loss: 0.2033\n",
      "Epoch 978/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.3688 - val_accuracy: 0.9743 - val_loss: 0.2034\n",
      "Epoch 979/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.3689 - val_accuracy: 0.9743 - val_loss: 0.2039\n",
      "Epoch 980/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.3688 - val_accuracy: 0.9743 - val_loss: 0.2026\n",
      "Epoch 981/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.3688 - val_accuracy: 0.9743 - val_loss: 0.2033\n",
      "Epoch 982/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.3687 - val_accuracy: 0.9771 - val_loss: 0.2034\n",
      "Epoch 983/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.3688 - val_accuracy: 0.9743 - val_loss: 0.2042\n",
      "Epoch 984/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.3686 - val_accuracy: 0.9771 - val_loss: 0.2029\n",
      "Epoch 985/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.3687 - val_accuracy: 0.9743 - val_loss: 0.2037\n",
      "Epoch 986/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.3688 - val_accuracy: 0.9771 - val_loss: 0.2032\n",
      "Epoch 987/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.3689 - val_accuracy: 0.9743 - val_loss: 0.2036\n",
      "Epoch 988/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.3688 - val_accuracy: 0.9743 - val_loss: 0.2033\n",
      "Epoch 989/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.3685 - val_accuracy: 0.9771 - val_loss: 0.2023\n",
      "Epoch 990/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.3690 - val_accuracy: 0.9743 - val_loss: 0.2028\n",
      "Epoch 991/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8415 - loss: 0.3686 - val_accuracy: 0.9743 - val_loss: 0.2035\n",
      "Epoch 992/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.3689 - val_accuracy: 0.9743 - val_loss: 0.2036\n",
      "Epoch 993/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.3685 - val_accuracy: 0.9771 - val_loss: 0.2032\n",
      "Epoch 994/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8415 - loss: 0.3683 - val_accuracy: 0.9743 - val_loss: 0.2039\n",
      "Epoch 995/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.3686 - val_accuracy: 0.9771 - val_loss: 0.2028\n",
      "Epoch 996/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.3685 - val_accuracy: 0.9743 - val_loss: 0.2039\n",
      "Epoch 997/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.3684 - val_accuracy: 0.9771 - val_loss: 0.2026\n",
      "Epoch 998/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.3689 - val_accuracy: 0.9743 - val_loss: 0.2041\n",
      "Epoch 999/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.3685 - val_accuracy: 0.9743 - val_loss: 0.2024\n",
      "Epoch 1000/1000\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.3683 - val_accuracy: 0.9743 - val_loss: 0.2031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2269d13fe90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train/fit neural network with validation data\n",
    "# see the instructions on the train/test -split above on how to split the data correctly\n",
    "model.fit(x=X_train, y=y_train, epochs=1000, validation_data=(X_val, y_val), callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error and performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df = pd.DataFrame(model.history.history)\n",
    "loss_df[['loss', 'val_loss']].plot()\n",
    "\n",
    "# the model seems to learn fairly well according to loss, not overfitting\n",
    "# slight room for improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAATX9JREFUeJzt3Qd8VFX2wPGTXoCEEkgooSNFEBAEwa4oiiKWv4sVRGXF1V0FXRUVsKzi6oq4iqKu6FrBgl1BFkVFEJRio/dQkhBKAgHS5v0/577MZCakk8ybZH7fz2eYTHvz5jHz7nnnnntfiGVZlgAAADgk1Kk3BgAAUAQjAADAUQQjAADAUQQjAADAUQQjAADAUQQjAADAUQQjAADAUQQjAADAUeFSC7hcLtm5c6c0aNBAQkJCnF4dAABQATqv6oEDB6RFixYSGhpau4MRDUSSk5OdXg0AAFAFKSkp0qpVq9odjGhGxP1h4uLinF4dAABQAVlZWSaZ4G7Ha3Uw4u6a0UCEYAQAgNqlvBILClgBAICjKh2MfPfddzJ06FBTjKKRzkcffVTuaxYsWCAnnniiREVFSceOHeW1116r6voCAIBgD0ays7OlZ8+eMm3atAo9f/PmzXLhhRfKWWedJStXrpQ77rhDbrrpJpk7d25V1hcAANQxla4ZueCCC8yloqZPny7t2rWTp556ytzu2rWrLFy4UJ5++mkZPHhwZd8eAADUMTVeM7J48WIZNGiQz30ahOj9pcnJyTEVuN4XAABQN9V4MJKamiqJiYk+9+ltDTAOHz5c4msmT54s8fHxngtzjAAAUHcF5Gia8ePHS2Zmpuei84sAAIC6qcbnGUlKSpK0tDSf+/S2zhcSExNT4mt01I1eAABA3VfjmZEBAwbI/Pnzfe6bN2+euR8AAKDSwcjBgwfNEF29uIfu6t/btm3zdLGMGDHC8/wxY8bIpk2b5O6775Y1a9bI888/L++++66MHTu2Oj8HAAAIlmDk559/lt69e5uLGjdunPl74sSJ5vauXbs8gYnSYb2ff/65yYbo/CQ6xPc///kPw3oBAIARYun5fQOcjrzRUTVazMq5aQAAqB0q2n7XihPloZbYuUJk0XMi+UdE4pNFouNFBv5VJKq+/fiy10TS14js3yrSeYjIidc5vcYAgABAMIJjk7VLxJUnYrlEXjrz6MfzD4v0ulZkzwaRT28vun/tFyJRDUSOv8SvqwsACDx006Dq1n4p8s6Vx7aMi58jQwIAdRTdNMFgf4rIG5eIHMkSSThOpOeVInmHRL68W+SMe0T2bRFxFYgMfUbkh6ki4VEi+7eJdBpsd5PMf0gkvpVIv9GVf+8/PhR57/rSH7/0JZEl00X2bS66L7KByLkPirx/Q9F9n9wm8ss7Ilt/EImsLxIaJpLY3X5s72aRw/tEWp7ou+xdv4hE1hNp0tHeBgd2iST3K3pc4+tti0Sa9xLZtVKkzSlFj4WGi4RFioSEiqwvPFnj+f8UOXlM5bcBRI5kiswZL9L9MpHoRiJLXhA59xGRuOZlv+7wfvt1Pf5PpOM5lXvPn2eIpP4mMuQpkdCAnLcRweBgusjMa0Sydopc+75Is672/RkbRN6+QmTvJns/e+a9Il//Q2T9V0X7oMGPiaQsFWl9ssiOZfZrdXlnPyDyxV0iK94U6XGFyLBpItt/Eln+hv2a2MYi3zwq8t2TIudMsl+rv8F6TUVOv8t+ny0/iFz1tsjqT0WWviRy2csiB1JFvrrffv8O54g0aiNSr5nIt48X7a97DhcnkRmpjLzD9hej9QCRsAhn1iHnoMjGr0Xyc0Q+v1MkJ7PoMf2Su/KPfk2Xi0TWfOZ731n3219qdckLdgNdGdqQZKcX3Y5NEBn7u0hEyRPZ+cg7IvJYc7trJ1D86XWR/Fz775CQovs1aHF/ptzskl+rj+t3QyX3F2nQ3P4/yj1g7yTanGrfPrJfJOkEu+sqc4f9+TVAbH+WSJifjgtyD9kBWvLJ9jppsKeft1E7kcxt9jbQgLCifp1VtJN102Dy1HKG7msAuuF/9t+Xv2IHkJGx9rXWHBWn20r/L9QHN9rX/W8R6XqRSESsSFxLkd1r7KBU/z9057tzpR0U6c5ag3UNxGObiBTkiTTrUvHPiMCn32OtR9PG3fv3W5weyEiI/V1odZLItsX2PlP3f/q7PbTHDo71fg0O9PcZGlH0HSzIFbEK7Of/OF1k60L7seiGIhf/294Hz3/Y/i5WRUiYvXy3vjfYwbdqPVCky4VFQUV10yy1Bk/1mjjSfhOMVMZnY+0vxul/tyNYJ3x5j51xKE5/HPpD8bcbvhKpl2AHZw1bV/x1mtFI/dVeZy1s3bSg6LEh/xKJihP58M/27UEPijRqa/+tRyFz77P/HvpvkU//VhRcJXSy//5qot2wuumRgHYFpa0S+e4JqVG6nqfcbn9X3I47X2TdnNJfc+Z9ImfeI37xyV9Flr8u0u50kc3fSZ3T53o7Ezitf9kNwr0pItF0+dYZz/UTyVgrcuXbdoNdEs2mTT+1/GXpwaYGI8Hoxv+JJJ9UrYukm6YmuCNUTZEpfwYkZf2QtCFOPF5k6csimdtF9qwXadimqAEXy369dpNoI63dF7oj1iNHPVJsWJUTEYaI9LpGpHX/qn0efU/3+7Y/U+SrB0Sy99g/hJNuso9uNLOgR7gDby9Kx2vsnHPAPhLpM9L+bPu2ipx2V9Fz9PN985h9lLRzuch5j4rENLQzRJrN0eCnPKU11nqU1KZw9uDN39vv7xYebXeNeQciqqxARC14zL64aSCWU3im6oh6InnZImFR9lFaRbhfq8sp7bGyAhHNklTmO6HL0qNMDYi1u023XWVep0ejmtL25l6GZmpSfrT/Tuphf4/Lov+3Ffn/3b222ne6qCCXy6410wzWFa/5ZjKWvCjy0ysi135gfwd/fVfkh2fsfZlmuK5+186gqS/utrN8Iz6xAxE182r7+rgLRK56R2TeRHuUn75u4zcVWz8nApEmnez9tlvLPiJpf9iZPvdvwP2byFhvd003O97OtmbtKMpO629J90maRUlfZT+u+0PdZ+7daD9Ps4h6UKcHjzqyUWnGVveROqjAIWRGKuPBeN/bN87zrVWoiO3L7DoK7Sv3pinBhU/bXyb98ugP78BOkZhG9uNLXrLT+8WdcofIuQ9V9pMEN61Z0S6CE0eILHr26McvftZ+rKQC3Zu/F2l+gv237uS8RxBpEPXTf0p/35NGi/z0sgSc8Jii71ZMY5FbfhCJa+HfEVlTvLpNtItHs2Huhus/Z4sc3C3yl0Uin/xNZNVHx/6euvPV/2PtktKdeLeLxe92/SqSskSk741l175ol+yif4vsXifSuL3IqXeU3B267UeR7Ay768rbuq8KuwPPkBqlDZ5mbbWW6/hLS3+efo5phYHgGfeKnHF3Udeg9z7WuyvZbfibIl2H2l1tjyTY92k356YSAg0dxbfyTftv3ae2GSjy4/PH+CFLeI+EjiL/K/y+Fj9w0QBC6/i0/u22n+ys7oo3irpkxm8vCq6Wv25nLrXG44Q/Vez9dTu8eIbdtfmXH0XCK9nd7gd00/gjGNHI9M8L7C4KjVTrJ9k7Fe2XV3q/XvQLoxftm3w8uaifvFVf+2/tZ9QGUndMFXXPVvsHrEfOFPFVjjZwBTn2Dl2DPt0p6NGE7jz0/8g9L4q7Rsed/dDnuXccxbs9dAd82892hmfxc0d3I13whEj/m+3Mlb6PeznaPTXrWt9latZHj2hU5wtF1n4u0vY0u/uhPL+9b2dZouJF/lzKkaB7+ZoV0++eFgNnpojUT7QzTxHR4ndaR6RDxFXx77T+dtz1Nfp/l/abyIuFR4m3LrX/H6f2OLb3v+Z9u65Ejwzd2aPiWapjoXPu6HdJ61v0c+pytW5KaeZOixVLOtjQDOT3T4ks/2/RXfrccyba66rbRpepAcuT7e3Hr5pZVEypwcl/CguEx/zg+93WZesyNDOhR9+mJiKnaH31t6H/F/ocbVB1O+h3RovilcnUaQbzoJ0V04yxBk3qhrkiTTvbga6p9wmxf1v6Wv3Ov6dZTa/gU7vX9Hn/tmf2LlW/m0XOGm8HNDPOk2M24Lai3+vYVXbGeHKr0rtTB/ylaD9xeK9IXCv7u6q/aw1qv/y7vT9o2VdkxMf2d1M/s35+bQv092X2OVqLFnt0rVjOwWL/RxWg/3e6PH/VnVUSwUh108pkd6OhO62MdUUNVM+r7Ahcjwa0PkFHiLiNWSjyxqUi2bur9r66TE2rKf3C6xdVd0batQHn6dHgz6+KdBtmV6ibo9hnRRok2d1Y2rWnO+uTby19Z6GpaN1BaXW9pk77jrK7MHRnrulb7Xbofa1dSV8e3fHpe+oRmb6+rtKUu27rzufbt7cusotitSFwG/mZHRxqKt+7uDbtd/+vL8ousvcn/Q7ob0wnZtT9tY440d9LUuEoPq0t06BKa9B0fbXLRAtfNbNZXuZBC9m1m6n75eWPKAsSWQQj1ezLe+1hi2rSfpEp3exulGNhhpiGlXJEpKnFnnaBqBNHqkBttPJtkYVT7XqBJh3sjMvz/e1aHk37a3Hxq0NEdvxc9nLctTret6vKezll0bogbfyq8lpv3uta1mcoadla91TSaKbKBBq6DA2K3ZmuinCvW/F18vw/hNhH/94jTarq9l+86ulQ0yhgrW46Y6h7TgpNuZU1fKwiNH35txUi9ZuJ/KtTYeGRFAU7x7p8IBj1utq+uGkgr42Pt9HzfYeETtUaIB3e3NoukB35qX2k/M7VdhfZ8LeOrsOojNk3i/w6s+znaKN7+0p7f+Dtv0PtLJmm/DUbqnUhM8o4yahm0HRuCrc594n8OE3k7An2PBTe3rhMZKPXttCumTt+F/n9A5HP7jh6VInO16MFyqW59MWiWrhN34q8XkYdzglXigy4VeTF00TiW4uMLacw2U2nMyirLstNs5I6DYNmsK/7UOStK+xA6b5dR3e1IiCQGamIPz4q6uP80xt2sZtOduOeu0MnjGnczh7Vof2eWsuhqXv3GPTLCn882meok4xpv6ummN1zHegwV00l6zBXLbTSIzoA/qGjEzQY0dEEmkFx13K5565wj546lq48TfM37iByMM2uFdBhx2beFMvuLtDagpK61bILRxp5j/zRInjdj+gyNAuhtQtaeHwow64t8h6yrBkKDSB0/pvio7EO7bU/u2YwtG5I61h036NNwpbv7e6JPRvtURn6fq362XPKaA2JZii08Fi7jXV/pnVync71PYjSgERHw+ln0/2dvk67KnWSRp3LQ4OfHcvtz1+/acW2pXaDaHemrq92X+t21fon3Za6LXQEnRmF0t9+rvn/7GPXmOj+V/fT8Cu6aarT093tAj93YZZ+4XXSqrnj7YKqtl4zfLrpD+Hzu0S6DCl93DsAAHUY3TTVSQsQ3XQ+DxXf0p61szR6NHCJV7oUAACUiDGh5dGhcZquVXdvdnRSGAAA6iKCkfK4h/BqkVVFhlYCAIBKIRgpj3t+EH/OSAkAQBAhGCmP+0ytWr0NAACqHcFIeQhGAACoUQQjFQ5GKnm+AAAAUCEEI+UhMwIAQI0iGKlwMMIUwgAA1ASCkYpOeEY3DQAANYJgpDx00wAAUKMIRsqTd8i+1pNbAQCAakcwUpEzbioyIwAA1AiCkfIcTLev61XwFNcAAKBSCEbKc2CXfc108AAA1AiCkbLkHBTJybL/JhgBAKBGEIyUZeEU+zqygUhUA6fXBgCAOolgpCy7frWvo+OdXhMAAOosgpGyZO20r4c+4/SaAABQZxGMlOVAYTBCvQgAADWGYKQ0eYdFDu+z/45r7vTaAABQZxGMlCY7w74OjRCJbuj02gAAUGcRjJQ3DbzOvBoS4vTaAABQZxGMlIYT5AEAELjByLRp06Rt27YSHR0t/fv3l6VLl5b63Ly8PHn44YelQ4cO5vk9e/aUOXPmSMDjBHkAAARmMDJr1iwZN26cTJo0SZYvX26Ci8GDB0t6euE5XIp54IEH5MUXX5Rnn31WVq1aJWPGjJFLL71UVqxYIQEt191NQzACAEBABSNTpkyR0aNHy6hRo6Rbt24yffp0iY2NlRkzZpT4/DfeeEPuu+8+GTJkiLRv315uueUW8/dTTz0lAS2vsJsmgm4aAAACJhjJzc2VZcuWyaBBg4oWEBpqbi9evLjE1+Tk5JjuGW8xMTGycOHCUt9HX5OVleVz8TsyIwAABF4wkpGRIQUFBZKYmOhzv95OTU0t8TXahaPZlPXr14vL5ZJ58+bJ7NmzZdeuwrPhlmDy5MkSHx/vuSQnJ4vfUTMCAEDdGE3zzDPPSKdOnaRLly4SGRkpt912m+ni0YxKacaPHy+ZmZmeS0pKivgdo2kAAAi8YCQhIUHCwsIkLS3N5369nZSUVOJrmjZtKh999JFkZ2fL1q1bZc2aNVK/fn1TP1KaqKgoiYuL87n4HZkRAAACLxjRzEafPn1k/vz5nvu060VvDxgwoMzXat1Iy5YtJT8/Xz744AMZNmyYBDRPZoRgBACAmhRe2RfosN6RI0dK3759pV+/fjJ16lST9dCuFzVixAgTdGjdh1qyZIns2LFDevXqZa4ffPBBE8DcfffdEtA8mRG6aQAACKhgZPjw4bJ7926ZOHGiKVrVIEMnMXMXtW7bts2nHuTIkSNmrpFNmzaZ7hkd1qvDfRs2DPDzvTCaBgAAvwixLMuSAKdDe3VUjRaz+q1+ZNa1Iqs/FRnyL5F+o/3zngAA1CEVbb85N025mRG6aQAAqEkEI6VhNA0AAH5BMFIa5hkBAMAvCEZKQ2YEAAC/IBgpDaNpAADwC4KR0nDWXgAA/IJgpDRkRgAA8AuCkZIU5Im48uy/qRkBAKBGEYyUJOdA0d9RDZxcEwAA6jyCkbKCkfAYkbAIp9cGAIA6jWCkrGCErAgAADWOYKQkuQft66j6Tq8JAAB1HsFISciMAADgNwQjJcnJsq+j/HSGYAAAghjBSEly3N00ZEYAAKhpBCMlOZRhXxOMAABQ4whGisvcITL/Yfvv5r2cXhsAAOq8cKdXIOBsmFf0d7dhTq4JaimXyxJLRMJCQ456zLIsCQk5+v6yFLisEpdVmWXrOoUWW0ZJ91XnZ3Wvk2WJuFdL/9b31NetSz8gu/YfkTM7N/Xcn5vvEpdlSWRYqGe5OfkFEh5qHzeFFT7H+/30b91Gyn2v3jqcVyCrd2VJdHiYdEqsLzl5LlmwLl06JzWQNbsOSJfmDeSnzXulSf0oSc08Iv3aNZbuLePN3yu27ZOBHRIkJjJMcgtcEhYSIgdz8mXhht1mXXQZ7RPqybKt+yQ2MlyObxHnWV9dF+/1yCtwSVR4aKX+b0r6/9drfVplvz9AbUAwUtyhPfb1ceeLxLd0em0QoNalHZCtew5JZHio9GnTSDIO5Mgv2/fLy99vkt93FBZAe0moH2WuMw7mSIv4aOnTtrHs2HdIftmeKQPaN5HL+7SU9Kwc+X1nlhzOzZfl2/bLn09vb5b7n4WbzWv/PrizuX71h82S77LknC6JsnTLHjmlQ4Ks2LZf0g8ckXO6JsrBI/nmecmNY2T4Scny6Oer5dt1u+WUjgly0QnNpX5UhMz6OUWWb91nbp/bLVHmrUqTAR2aSIem9eVQboFpbFem7JeWDaPl9cVbJfNwnjSKjZRzujaT2Mgwyc4pkE9/2SnvLdtu3kvX9aXvNnk+r26TP/VtJfd88JvPdmgQFS4Hcuz1K65/u8bmPXPyXZ77mjaIMu+tAYhu6y5JDcy2P5LnMgGOBjHVRZfXpF6U+T+qqqS4aEk7cOSo9WrVKMZ8Fv1/UhpU9G3T2AQ7+n+jTmzd0NzeknFITmgVL5szsmVNqj2yz/25C2OuEt0/pKu0aRIrP23ZK8clNpCuzeOkbUI9qR8V7gkM9bvZoVk9E0Dp8nfsOyxN6kea57qf89uOTBN4ndi6kURHhMmG9APmu6nrvyvziLRsFCMpew9J79aNJD6mcpNC7jmYI/sO5UrHZlXrAtf31cCsRcOYKr0egSvE0m9fgMvKypL4+HjJzMyUuLgaHuEy5z6RH6eJDPybyHmPeO4+kldgGgD9YeuRzMyfUqR/+8Zm511ZWUfyJC664j9iPSLatveQxEWHy8crd5qjMN0pfb9+t9lZ6NGZe4d2/cC20iA6XJ79eoNPA/D38ztLaEiIaWROatvY7HT2ZOd6GkmlOyA9AtQdovsz62u0EThWe7NzzfJueWu5NIyJMDtAbYS14dEjR93BaAPWLsHeUe4/lGuOSBPqRZntpY1PUny0WVZ2Tr450tT11W3TuF6k52hR/2+yc/OlQXSEWca+Q3kSHhoiURGhkldgmW2TX2DJJyt3SN+2jc1OLS3riGlYn1+w0SzjxlPbeT5zRGiIzP0jTdamHZDEuChJy6p6Q4XA1axBlKQfyAmaz9coNsL8NrzpfRqIegeD5dH9hwZW9aLCZWjPFmYZD326ygTCmok6oVVDk9nSwF33YW592zQymanEBtE+wakGuuvTDsrnv+0yt28/p5NEhIXIDxv2mN/1r9szzf1X9WttfuuLNmVIm8b1ZMJF3czBwCvfb5auzRtIyr7D5netAdOv2/eb/ZgGX266n9EA78vfU82+p3l8tPRMbihN60fJd+t2y6bC52qwlV/gkuzcAp/P/cCFXeWTX3Z61ufini3k5jPam2B6WK+WMn91mtk2egCgdF+1LztXkhvHmu2h29i7DTiSV2D2d6W1C7qP1P1ew9jIcv9PdFn6fN0H1qb2m2CkuNk3i/w6U2TQQyKn3uH5z71k2g/mxzz3jtNl9vLtMvnLNaZxWnLfIPNFu2/2byY4+b8+rUyDrrbvOyyrdmXJ9n2H5IUFGyUxLto0fl+vSTdHQad2airrUg/IBT2SzJf2n1+ukdSsI6bB1NfqEUTK3sPmB6FHhzVBj6S0cdYf/JY9h8yPUn/os35KkR37D5v72zTRACHMHCnp7U27s+X045qaoxzdJroT+n1HpjliGtK9uU9KflfWEbnh1Z9MY14RGjho0FeaDk3rycbdRTsVpT/6Q7n5Zod4JLeg1CNvfxpzRgfZuifb7OxKov/HBwozGNVJ/180yNOd0ccrdxy1rdy0ASnrKLs66Hs0j48x3yO3S3u3NIGz/j+PPfc4c6T91R+p5qhbMzOdExtIo3qRJoOgn0G/d/r/qzvw3QdyTKDaMDbCBKHanaINifs7ozv4z3/dZYLpIT2am2zE9G83muVoFuK0Tglm2f+au1b2HMyVk9s3lsHHJ0l0ZJj0Tm4oC9buNg2Y/hbdvze93b5pfRPYakNTLzJcTm7fxPwm565KNUGxZone/HGrnNWlqfm82mj8sHGPpGcdkfO6JUqPVg3lyblrZF1a4Sg9L4O6NpOd+4+Y/URp9L3uOu84eXXRFvPbK40G5Rr0I3Dofr5js/oye/mOo/Zr7u9t95Zxnmxq2yaxJkjU71/7pvXMfT1axpvvngZ0eqCkGcTv12eY7Kb+1jXw04M1PYD6Y2eWrNqZaQ68ujWPk4jwUElsECVfrUozy9JsZbuE+mZf/UvKfvN70ffXg9TWjWPlij7Jx9x1WxzBSFW9ebnIhv+JDJsm0vtac5fuvJ77pijT4E0bbj3KLh45BzPdKWpaXYO02kJ/0Br4uWnDpTamH5TWTWIlREJMLYM2Tse3iDdZGk3J927d0BzxffFbqjky06OfO8/rLLec2cGzLG1IdWehOx89Qstz2UdAesT113dWmL8fu6yH2V5Zh/NMY9ug8HHtPtEfqDaumYfypH50uGmAtSvBndXalXlY8vIt8xm86wn0p62fSXdSemR8KK/A1DKYuovCozBdXxUWFiKrd2bJlj3ZclaXZua9tHHXz6QN9qGcAhMwaNCnr3fvNRoVNoAaXNnBg90loP//+rndR2d6+0h+QaUygnWJd8auPPr/9tmvu8w20++hHg3r/6Hev3zbPvlpyz7Jy3fJRT1bmCN8bxrY6f+h/v+cd3ySLFy/W15ZuNkckevBzbldk8xB06KNe0yweEXfZHNApAdM/do1MffFx0aY76nW1Xy4Yoc5YNEuIn3945edYH4H+n+uDeKPm/aY70OnZg1MPY47WNJG+MzOzUw30IqUfabrSb9z2pCqJZv3etZZG1hdhgammu3d75WxKX4gpt/jUzsleL77enCkmcsN6QclOiLUfP+iw0NNI6+/ty7N40wmWbuZ3l++Xc44rqkkN4oxWeFmDaJlTWqWeU2By2W6tPR57qyM0vdxZ5GDwT8v7yHDT2pdrcskGKmql84U2blC5KqZIp0vkGVb98rlLyw+pkVqN4kW05V2xK87Gt3xtGwYY7ov3Kk/txtOaSetG8fIipT9cnW/1qbITlOOmmXRozD9kWv3kWZe3LZkZJssS9ekOLMTXJ9+UD7z6uNXuuPRwCHjYOk/NO1L1iLA4upp3UAlArBzujST+WvSzd/a2OoOp0m9SJl2zYmm0evZKt7sFH7estdkUV79YYs58tUGVtdRd7q6w9MuG93x6FG0Zmx0h6Op5SWb9piGWqP7pZv3SrcWerSRadZRgwY9QtWGU3d47iMQXb5uOz0q0B2TBhr6/6A7bgA1R2s/NGPmzoR5+3pNmsmM3THouAoVbmvmWoOl7i3iq/2o3k0zY3oAoPuoZ79eb/a1F/ZoLk//b518vy5DwsNCTEZD68HyXJbJ4mnWTOusdN+l+3U9UND79OBBHz//+CTZeyjXBFxLN+81mY/Sugrd+8yapAXZX95xmkSF29301YVgpKqe7SOyZ4PI9V+ItD1FHvr0D9MwasNZWnSs3/+HhnWXYb1amCPPn7fuM0WE+kM6q3MzE2y4f1T6w9E6D00zu6vsNaWmR5H1IsPNj8m7Gr+6f1zuERd6pKYH0do4a6OtRYz6TdDAQAcuzF+dbmpL9GhYG21NE+oRkh4d6SgDPWrXL86qnVkmIOrfvonM+T3VHGHp59L3iIuJMHUumkps5hUo6eebtypVBnRIqHQBHAAEoqqMlCtrdJWr8OA112s0lrvdiAiz2xRtN1wuu135fkOGOejSAzT3euS79LVhnmVZxUZo6bM0KFywNt1ksmriQIxgpKqe6iJyYJfIn78VadFLLnjme5MZmPKnnnLne7+Ypyy692yTidA+f01Xaho/WNPPAAAca/vN0N7icgsrviPrm2hzfWHhpRatfX/3WeZvLVJT2v/LEDMAAI4NwYg3TRLl2hXvVmSsXPnSj6bOQ7todJQJkw0BAFD9mA7eW36OiGUXZaYcDDF1Eur87kkEIgAA1BCCEW95RZPybNxfNPHPbWd3dGiFAACo+whGvBV20Uh4tGzcYw+xGtIjyVMjAgAAqh/BiLfcwtkNI+uZcfBK57IAAAA1h2CkpGAkop5ncixGywAAULMIRrzlFJ4/JbKemb1UNfearAsAAFQ/ghFvB+2TCUn9Zp7MiPtMsQAAoGYQjHjL2mGuChq0MOchUAQjAADULIIRb1n22Rr3hDYx8581io0wE54BAICaQzDibf82c7XT1dBcd0pswGRnAADUMIIRt7wjIlsWmj8XZrc218e3qOGT8gEAgKoFI9OmTZO2bdtKdHS09O/fX5YuXVrm86dOnSqdO3eWmJgYSU5OlrFjx8qRI3aBaMDYs14kL1skppHM3JFg7tJTKgMAgAALRmbNmiXjxo2TSZMmyfLly6Vnz54yePBgSU9PL/H5b7/9ttx7773m+atXr5ZXXnnFLOO+++6TgHLYPg+N1Gsquw/mmj/bJzDhGQAAAReMTJkyRUaPHi2jRo2Sbt26yfTp0yU2NlZmzJhR4vMXLVokp5xyilx99dUmm3LeeefJVVddVW42xe+OZJorV1Sc5OTb56WJj41weKUAAKj7KhWM5ObmyrJly2TQoEFFCwgNNbcXL15c4msGDhxoXuMOPjZt2iRffPGFDBkypNT3ycnJkaysLJ9LjTtiZ0byIuLNdWiISP3I8Jp/XwAAglylWtuMjAwpKCiQxMREn/v19po1a0p8jWZE9HWnnnqqWJYl+fn5MmbMmDK7aSZPniwPPfSQOJEZyQmvb67jYiIkVCMSAABQu0fTLFiwQB577DF5/vnnTY3J7Nmz5fPPP5dHHnmk1NeMHz9eMjMzPZeUlBS/BSOHwxuY6/gYumgAAAi4zEhCQoKEhYVJWlrhtOmF9HZSUlKJr5kwYYJcd911ctNNN5nbPXr0kOzsbPnzn/8s999/v+nmKS4qKspcnChgPRRiZ0YIRgAACMDMSGRkpPTp00fmz5/vuc/lcpnbAwYMKPE1hw4dOirg0IBGabdNwMg9aK4OWPb07wQjAAD4R6UrNHVY78iRI6Vv377Sr18/M4eIZjp0dI0aMWKEtGzZ0tR9qKFDh5oROL179zZzkmzYsMFkS/R+d1ASEArs4bxZuXadSCJn6wUAIDCDkeHDh8vu3btl4sSJkpqaKr169ZI5c+Z4ilq3bdvmkwl54IEHzJTqer1jxw5p2rSpCUQeffRRCSgFeeZqf46drWnOCfIAAPCLECug+kpKpkN74+PjTTFrXFwNTdE+8xqRNZ/JG03ukAk7+smjl3aXa/q3qZn3AgAgCGRVsP3m3DTFMiN7j9ixWRLdNAAA+AXBiJvLDkYO2lfSkNlXAQDwC4KRYpmRA3l2AWuDaIIRAAD8gWDEzZXvkxmpH8VU8AAA+APBSLHMyBGXPdy4QTTBCAAA/kAwUmyekXwJk5AQkXqcJA8AAL8gGCnWTZMnYeZsvZwkDwAA/yAYKdZNk2eF00UDAIAfEYwUG9qr3TT1CUYAAPAbghG3Anc3jWZGGNYLAIC/EIyUlBlhWC8AAH5DMFK8ZkTCqBkBAMCPCEaKjabRzAjBCAAA/kMwctQ8I9SMAADgTwQjxbppcq1wakYAAPAjghFlWSJWgfmTbhoAAPyLYMQrK1IUjNBNAwCAvxCMeA3rdY+maR4f7ejqAAAQTAhGjsqMhEuLhjGOrg4AAMGEYMRrWK8iMwIAgH8RjHgP67VCpUm9KImOCHN6jQAACBoEI17dNFq82qhepNNrAwBAUCEY8eqmyZVwaRTLSBoAAPyJYKRYZqRhLJkRAAD8iWDE54y9ZEYAAPA3gpFiZ+xtRGYEAAC/IhjxPmOvFSZxMWRGAADwJ4KRYjUj9SIZ1gsAgD8RjHjNM5In4RJDMAIAgF8RjHh102jNCBOeAQDgXwQjPt004RJDMAIAgF8RjHgN7dXMCN00AAD4F8GId2bEopsGAAB/IxjxHtqrmRGCEQAA/IpgxGfSs3AyIwAA+BnBiNfQXpMZoWYEAAC/IhjRXhqvzAjdNAAA+BfBiAYhee5Jz6gZAQCgVgQj06ZNk7Zt20p0dLT0799fli5dWupzzzzzTAkJCTnqcuGFF0qgKCgMRnQ0TWQ48RkAAP5U6ZZ31qxZMm7cOJk0aZIsX75cevbsKYMHD5b09PQSnz979mzZtWuX5/L7779LWFiYXHHFFRIoXPl2MFIQEi5hoSFOrw4AAEGl0sHIlClTZPTo0TJq1Cjp1q2bTJ8+XWJjY2XGjBklPr9x48aSlJTkucybN888P7CCkTxPMAIAAAI4GMnNzZVly5bJoEGDihYQGmpuL168uELLeOWVV+TKK6+UevXqSaAVsLoIRgAA8LtKtb4ZGRlSUFAgiYmJPvfr7TVr1pT7eq0t0W4aDUjKkpOTYy5uWVlZ4o9gxAolGAEAwN/8Wq2pQUiPHj2kX79+ZT5v8uTJEh8f77kkJyfX6Hq5CuwZWK0QRtIAABDQwUhCQoIpPk1LS/O5X29rPUhZsrOzZebMmXLjjTeW+z7jx4+XzMxMzyUlJUVqkuUJRsiMAAAQ0MFIZGSk9OnTR+bPn++5z+VymdsDBgwo87Xvvfee6Xq59tpry32fqKgoiYuL87n4JRgJIxgBAMDfKt366rDekSNHSt++fU13y9SpU03WQ0fXqBEjRkjLli1NV0vxLppLLrlEmjRpIoHGXTMidNMAABD4wcjw4cNl9+7dMnHiRElNTZVevXrJnDlzPEWt27ZtMyNsvK1du1YWLlwoX331lQQiy1VgX1PACgCA31Wp9b3tttvMpSQLFiw46r7OnTuLZVkS6CfKE4IRAAD8jrnPlcuuGQkJpZsGAAB/IxgxBazubpoIp1cFAICgQzBiakbszIgwmgYAAL8jGFF00wAA4BiCEeXOjNBNAwCA3xGMeGdG6KYBAMDvCEZU4TwjdNMAAOB/BCMahLjsGVhDw+imAQDA3whGTDBSmBmhmwYAAL8jGNEgxHLXjJAZAQDA3whGTDBiZ0ZCyYwAAOB3BCOmm4bRNAAAOIVgxCczQjcNAAD+RjBCMAIAgKMIRnQjFAYjYeF00wAA4G8EI7oRCmtGyIwAAOB/BCNmI5AZAQDAKQQjppumMDMSTmYEAAB/IxjxrhmhmwYAAL8jGPHppol0elUAAAg6BCMahBRmRsLDOWsvAAD+RjCi84yIZa4pYAUAwP8IRryCkXCmgwcAwO8IRixLwsRl/gwPY3MAAOBvtL6WnRVREXTTAADgdwQjlp0VUeHMMwIAgN8RjHgFI2HhbA4AAPyN1tcrGImggBUAAL8jGCmcY0RRMwIAgP8RjNBNAwCAo2h9vYKRSApYAQDwu6APRgoKvGpG6KYBAMDvgj4YycvP9/zNuWkAAPC/oA9G8vPzPH9HhBGMAADgbwQj+fZoGpcVIhFkRgAA8DuCkQI7GCmQUAkLDXF6dQAACDpBH4y4a0YsIRABAMAJBCOFmREXwQgAAI4I+mCkwJ0ZCQn6TQEAgCOq1AJPmzZN2rZtK9HR0dK/f39ZunRpmc/fv3+/3HrrrdK8eXOJioqS4447Tr744gsJBHkFdjBCZgQAAGdUepavWbNmybhx42T69OkmEJk6daoMHjxY1q5dK82aNTvq+bm5uXLuueeax95//31p2bKlbN26VRo2bCiBID/fnvTMRZIIAIDaEYxMmTJFRo8eLaNGjTK3NSj5/PPPZcaMGXLvvfce9Xy9f+/evbJo0SKJiLCnW9esSqAoKMyMWAQjAAA4olItsGY5li1bJoMGDSpaQGioub148eISX/PJJ5/IgAEDTDdNYmKidO/eXR577DEpKCwcLUlOTo5kZWX5XGp6aK8VQjcNAAABH4xkZGSYIEKDCm96OzU1tcTXbNq0yXTP6Ou0TmTChAny1FNPyT/+8Y9S32fy5MkSHx/vuSQnJ0tNT3pGZgQAAGfUeAvscrlMvchLL70kffr0keHDh8v9999vundKM378eMnMzPRcUlJSam796KYBAKD21IwkJCRIWFiYpKWl+dyvt5OSkkp8jY6g0VoRfZ1b165dTSZFu30iIyOPeo2OuNGLP7i7aVwM7QUAwBGVaoE1cNDsxvz5830yH3pb60JKcsopp8iGDRvM89zWrVtngpSSAhF/cwcjwtBeAAAcUel0gA7rffnll+W///2vrF69Wm655RbJzs72jK4ZMWKE6WZx08d1NM3tt99ughAdeaMFrFrQGgjchbRMegYAQC0Z2qs1H7t375aJEyearpZevXrJnDlzPEWt27ZtMyNs3LT4dO7cuTJ27Fg54YQTzDwjGpjcc889EgiYgRUAAGeFWJZlSYDTob06qkaLWePi4qp12V9++YlcsOQ62R3eXJo+sKZalw0AQDDLqmD7HfTpAJfLnRkpKrAFAAD+E/TBCDUjAAA4K+hb4IKCwlE+zMAKAIAjCEYKJz0TMiMAADgi6Ftgl2eekaDfFAAAOCLoW+CCwsnYrFAKWAEAcALBiDszQs0IAACOCPpgxOVyByNBvykAAHBE0LfArnw7GAkhGAEAwBFB3wIXWGRGAABwUtC3wC7PPCMUsAIA4ASCEXcBq9fJ/QAAgP8EfQvsKuymoWYEAABnBH0L7MmMEIwAAOCIoG+B3cFICN00AAA4IuhbYMuyC1hDmIEVAABHBH0w4iqcDp5uGgAAnBH0LbBVeNZeMiMAADgj6IMR93TwjKYBAMAZQd8CW5ZlrilgBQDAGUHfAheNpqGbBgAAJwR9MFJQ2E0TGkYwAgCAE4I+GHFnRsLIjAAA4IigD0YKCoORUGpGAABwRFC3wPl6xt7CSc/C6KYBAMARQR2MHMl3SYi4g5Fwp1cHAICgFNzBSF6BhIo9tJduGgAAnBEa7MFIWGFmhKG9AAA4I8iDEZcnMyIhIU6vDgAAQSnIg5ECCfEEI0G9KQAAcExQt8A5+Vozwll7AQBwUlC3wL7dNNSMAADghCAPRgokNITMCAAATgrqFjgn3zszEtSbAgAAxwR1C+yyLGpGAABwWFC3wJalG4DMCAAATgoN9syIZ2gvM7ACAOCI0GDPjLhnYCUzAgCAM6rUAk+bNk3atm0r0dHR0r9/f1m6dGmpz33ttdckJCTE56KvC5yaEbppAABwUqVb4FmzZsm4ceNk0qRJsnz5cunZs6cMHjxY0tPTS31NXFyc7Nq1y3PZunWrBE7NCJkRAACcVOkWeMqUKTJ69GgZNWqUdOvWTaZPny6xsbEyY8aMUl+j2ZCkpCTPJTExUQKuZoRgBAAAR1SqBc7NzZVly5bJoEGDihYQGmpuL168uNTXHTx4UNq0aSPJyckybNgw+eOPP8p8n5ycHMnKyvK51PxoGmZgBQAg4IORjIwMKSgoOCqzobdTU1NLfE3nzp1N1uTjjz+WN998U1wulwwcOFC2b99e6vtMnjxZ4uPjPRcNYmqCJRYFrAAAOKzGW+ABAwbIiBEjpFevXnLGGWfI7NmzpWnTpvLiiy+W+prx48dLZmam55KSklIj6+ayREIIRgAAcFR4ZZ6ckJAgYWFhkpaW5nO/3tZakIqIiIiQ3r17y4YNG0p9TlRUlLn4o2YkzNNNE1Lj7wcAAI5WqXRAZGSk9OnTR+bPn++5T7td9LZmQCpCu3l+++03ad68uThNMyMM7QUAoBZlRpQO6x05cqT07dtX+vXrJ1OnTpXs7GwzukZpl0zLli1N3Yd6+OGH5eSTT5aOHTvK/v375cknnzRDe2+66SZxnM4zEuKegZUCVgAAakUwMnz4cNm9e7dMnDjRFK1qLcicOXM8Ra3btm0zI2zc9u3bZ4YC63MbNWpkMiuLFi0yw4IDIzNCzQgAAE4KsSwd4BrYdGivjqrRYladQK26vPrDZmk05y9ySdgikcGPiQy4tdqWDQBAsMuqYPsd1OkAakYAAHBeULfAmhQiGAEAwFlB3QJrBxXzjAAA4KygboF95xkJ6k0BAIBjgroF1jCE0TQAADgrqFtgztoLAIDzgroF9j1rb1BvCgAAHBPULbDLZRV10zADKwAAjgjqYERzImHUjAAA4KigboGpGQEAwHlB3QIzAysAAM4L6hbYdwbWEKdXBwCAoBTkwYhIaIi7ZoQCVgAAnBAa7DUjTHoGAICzgroFpmYEAADnBXULzFl7AQBwXlC3wBqGcNZeAACcFdQtsD0Da2FmhBlYAQBwRHAHI5b3DKwM7QUAwAlBHYxYQs0IAABOCw32eUaYDh4AAGcFdQvMPCMAADgvNNiDkaKaEQpYAQBwQlAHI3TTAADgvKBugZmBFQAA5wV1C2zPwErNCAAATgrqFtgUsIaQGQEAwEmhwV4z4smMhAb1pgAAwDFB3QJTMwIAgPOCugXmrL0AADgvqFtgztoLAIDzgroFtmdgJTMCAICTgroF9j1rLzOwAgDghCAPRsiMAADgtOBugX2mgw9xem0AAAhKQR2McNZeAACcF9QtMN00AAA4L6hbYJfPDKwUsAIAUGuCkWnTpknbtm0lOjpa+vfvL0uXLq3Q62bOnCkhISFyySWXSOBMB09mBAAAJ1W6BZ41a5aMGzdOJk2aJMuXL5eePXvK4MGDJT09vczXbdmyRe666y457bTTJFBw1l4AAJxX6RZ4ypQpMnr0aBk1apR069ZNpk+fLrGxsTJjxoxSX1NQUCDXXHONPPTQQ9K+fXsJpJqRMM7aCwCAoyrVAufm5sqyZctk0KBBRQsIDTW3Fy9eXOrrHn74YWnWrJnceOONFXqfnJwcycrK8rnUVGbEg2AEAABHVKoFzsjIMFmOxMREn/v1dmpqaomvWbhwobzyyivy8ssvV/h9Jk+eLPHx8Z5LcnKy1AirsItGEYwAAOCIGm2BDxw4INddd50JRBISEir8uvHjx0tmZqbnkpKSUjMraBUU/U0wAgCAI8Ir82QNKMLCwiQtLc3nfr2dlJR01PM3btxoCleHDh3quc/lsrMR4eHhsnbtWunQocNRr4uKijKXGkdmBAAAx1WqBY6MjJQ+ffrI/PnzfYILvT1gwICjnt+lSxf57bffZOXKlZ7LxRdfLGeddZb5u8a6XyqqMDAyCEYAAAj8zIjSYb0jR46Uvn37Sr9+/WTq1KmSnZ1tRteoESNGSMuWLU3dh85D0r17d5/XN2zY0FwXv98JFpkRAABqXzAyfPhw2b17t0ycONEUrfbq1UvmzJnjKWrdtm2bGWFTK3gHI8zACgCAI0Isn/GtgUmH9uqoGi1mjYuLq7blXv/8XHkt/U/2jQkZImER1bZsAACCXVYF2+9aksKoIcwzAgCA44K7BaZmBAAAxwV1C+xbwBri5KoAABC0gjoYmTHiRHNthVC8CgCAU4I6GAkTu2YkhC4aAABqz9DeOsXdTUMwAgBH0XOR5eXlOb0aCGARERFmZvZjRTCiCEYAwENnfNB5pPbv3+/0qqAW0MlM9ZQwIcdQe0kwoghGAMDDHYg0a9ZMYmNjj6mRQd0OWg8dOiTp6enmdvPmzau8LIIRRTACAJ6uGXcg0qRJE6dXBwEuJibGXGtAot+ZqnbZBHcr7A5Gasv09QBQw9w1IpoRASrC/V05lvqi4G6FyYwAQInomoE/vyvB3QoTjAAA4LjgboUJRgAAcFxwt8KuAvuaYAQAAMcEdyvsyYwwHTwAoHoxYVzFEYwoMiMAUOvNmTNHTj31VDMJlw5Lvuiii2Tjxo2ex7dv3y5XXXWVNG7cWOrVqyd9+/aVJUuWeB7/9NNP5aSTTpLo6GhJSEiQSy+91KdI86OPPvJ5P32f1157zfy9ZcsW85xZs2bJGWecYZbx1ltvyZ49e8x7tmzZ0ow66dGjh7zzzjs+y3G5XPLEE09Ix44dJSoqSlq3bi2PPvqoeezss8+W2267zef5u3fvlsjISJk/f77UFUE+z4h9bhqCEQAoe3Krw3mF3dp+FBMRVqmRGtnZ2TJu3Dg54YQT5ODBgzJx4kQTUKxcudJMzqVBggYFn3zyiZkxdPny5SYQUJ9//rl57v333y+vv/665ObmyhdffFHpdb733nvlqaeekt69e5uA5MiRI9KnTx+55557JC4uzrzPddddJx06dJB+/fqZ14wfP15efvllefrpp00wtWvXLlmzZo157KabbjLBiC5TAxX15ptvms+hgUpdEeTBiDszwhA2ACiNBiLdJs71+/uueniwxEZWvJm6/PLLfW7PmDFDmjZtKqtWrZJFixaZjMJPP/1kMiNKMxFumom48sor5aGHHvLc17Nnz0qv8x133CGXXXaZz3133XWX5++//vWvMnfuXHn33XdNMHLgwAF55pln5LnnnpORI0ea52igokGJ0mVpMPLxxx/Ln/70J3OfZmOuv/76OjX8OrhTAhYFrABQV6xfv950ibRv395kIdq2bWvu37Ztm8mOaLbCHYgUp4+fc845x7wO2vVTfEbbRx55xHTP6HvXr1/fBCO6Tmr16tWSk5NT6ntrdkUzKRpYKc3m/P777yYYqUvIjKhQClgBoKzuEs1SOPG+lTF06FBp06aN6fJo0aKF6YLp3r276XJxT1te6nuV87hmIbS7qrwCVa1F8fbkk0+azMfUqVNNQKKPa/ZE16ki7+vuqunVq5epeXn11VdN94x+zrokuFMCFLACQLm0IdbuEn9fKtMNoYWia9eulQceeMBkGbp27Sr79u3zPK51JJr92Lt3b4mv18fLKgjV7h6t5fDOwmgdSnl++OEHGTZsmFx77bWm20ezNuvWrfM83qlTJxOQlPXeGsRoxkWDrLfffltuuOEGqWuCuxUmGAGAOqFRo0ZmBM1LL70kGzZskK+//toUs7pp940WrV5yySUmQNi0aZN88MEHsnjxYvP4pEmTzCgXvdauk99++03++c9/el6v2Qit61ixYoX8/PPPMmbMGImIiCh3vTTYmDdvnqlZ0eXefPPNkpaW5tMNc88998jdd99tCmd19M+PP/4or7zyylHZkccff9xkZ7xH+dQVwd0KM+kZANQJoaGhMnPmTFm2bJnpmhk7dqzpInHTobBfffWVObPskCFDTLZBG3f3WWbPPPNMee+998xIG+0S0eBj6dKlntfraJbk5GQ57bTT5OqrrzZFqRU5maBmak488UQZPHiweQ93QORtwoQJcuedd5rRP5rRGT58uDkLrjcNpsLDw821BjB1TYhVvBMsAGVlZUl8fLxkZmaaoqRqs2G+yJuXiSR2F7nlh+pbLgDUUjoUdfPmzdKuXbs62ejVVlu2bDGjbHQ0kAY3teU7U9H2O8gLWJlnBAAQuPLy8kw9jGZYTj755IALRKpLcLfC1IwAAALYDz/8IM2bNzcZkenTp0tdFeSZEYIRAEDgOvPMM48aUlwXBXcrzKRnAAA4LrhbYTIjAAA4LrhbYYIRAAAcF9ytcL49Ha+ERzq9JgAABK0gD0YO29fh5Z8bAAAA1IzgDkbyjtjXEUzsAwCAU4I7GCEzAgAo1LZtW3N2XfhfcAcjeYXBCJkRAAAcQzCiIso/2REAAIGqoKBAXK7CEaK1UHAHI/mFNSPhZEYAoDZ76aWXpEWLFkc1yMOGDZMbbrhBNm7caP5OTEyU+vXry0knnST/+9//qvx+U6ZMMWf+rVevnjmb71/+8hc5ePDgUVO56wyqenbfRo0amTP37tu3zzym6/nEE09Ix44dJSoqSlq3bi2PPvqoeWzBggUSEhIi+/fv9yxr5cqV5j49YZ567bXXpGHDhuYsw926dTPL2LZtm5k2/txzz5WEhARzgrozzjhDli9f7rNeutybb77ZbAs9sZ2e5fizzz6T7OxsczK7999/3+f5H330kfmcBw4ckJoS3MGIJzNCzQgAlEqnI8/N9v+lEtOgX3HFFeaEct98843nvr1798qcOXPkmmuuMYHCkCFDZP78+bJixQo5//zzZejQoaYBr4rQ0FD597//LX/88Yf897//la+//lruvvtun+DhnHPOMYHC4sWLZeHCheb9NIOhxo8fL48//rhMmDBBVq1aJW+//bYJDirj0KFD8s9//lP+85//mPVo1qyZCRhGjhxp3u/HH3+UTp06mc/tDiQ0CLrgggtMoPTmm2+a99b1CAsLMwHHlVdeKa+++qrP++jt//u//5MGDRpIQJ2bZtq0afLkk09Kamqq9OzZU5599lnp169fic+dPXu2PPbYY7JhwwZz9kHdMHfeeadcd9114jgyIwBQvrxDIo+18P/73rdTJLJehZ6qmQdtZLVR1yBA6RG+ZgjOOussEzxoe+X2yCOPyIcffmgyC7fddlulV+2OO+7wKXz9xz/+IWPGjJHnn3/e3KdZj759+3puq+OPP95ca2DwzDPPyHPPPWcCB9WhQwc59dRTpTK0TdXle3+us88++6iMkWZQvv32W7noootMNmjp0qWyevVqOe6448xz2rdv73n+TTfdJAMHDpRdu3aZE/Slp6fLF198cUxZpBrJjMyaNUvGjRsnkyZNMqkf3QiaetIVLknjxo3l/vvvN5Hhr7/+KqNGjTKXuXPniuPIjABAnaEZkA8++EBycnLM7bfeessc6WsgopmRu+66S7p27WoaZ+2q0Qa5qpkRbZw16GnZsqXJGOgBtmZmNFvhnRkpib6vrmNpj1dUZGSknHDCCT73paWlyejRo82Bv3bTaLeLfnb359T1atWqlScQKU4TCxo0abZHafakTZs2cvrpp0tNCq9KP5l+UA0olJ7S+PPPP5cZM2bIvffee9Tztb/M2+23324+pKaQNIhxFJkRACifFvlrlsKJ960E7QbRM9xqm6Q1Id9//708/fTT5jENRObNmyf/+te/TJ1GTEyM6XrIzS2cibsStG5Dswy33HKLqfPQg25t02688UazPK0R0eWXpqzHlAZPyvtsvZoFKWk5WkfiTTMtGhRp5kWDCK0lGTBggOdzlvfe7uyI9oBom65dNNreF38fRzMj+mGWLVsmgwYNKlpAaKi5rZmP8uiG1f66tWvXlhllacSYlZXlc6kRZEYAoHzaEGl3ib8vlWwAtRjzsssuMxmRd955Rzp37iwnnniieUxrJK6//nq59NJLTeFpUlKSpxi0srQd1NqLp556Sk4++WSTZdi50zdY04yFtncl0ayFBgWlPd60aVNzrV0lbprRqAj9nH/7299MnYhmODQYycjI8Fmv7du3y7p160pdxrXXXitbt241NTFaU+LuSgqYYEQ/kBbfFC+y0dtaP1KazMxMkxLTlNKFF15oaky02rc0kydPNukl90UrlWsEmREAqHNdNe5svf7tHQBoDaM26r/88otcffXVVR4Kq5kVzVRoW7Zp0yZ54403TC+BNy1Q1ZEtOspGSxTWrFkjL7zwgmlHNWi65557TMHr66+/bkb6aLHpK6+84lm+tnsPPvigrF+/3nweDXwqQj+nro92BS1ZssRsA+9siI6u0WTA5ZdfbjJFmzdvli+//NIU+nrX32hQ9/e//13OO+88061T0/wymkb70/QLoP8xmtLSmhMdulQa/U/UAMZ9SUlJqZkV63WNyKljRRJK7jsDANQuWsCp3SaagdeAw7vEQBtZLc7U7hwtE3BnTSpLayV1eTqSRYfFaiZGD6K9abbkq6++MoGP1mFoV8nHH38s4eF2dYSOotHBHBMnTjR1LMOHD/fUXkZERJjMjgYwmsnQ99EC2YrQgEaHD+tn0zoWzZLoKBtvWlej3VhXXXWVGe2jQZF7lI+bu8tJh0X7Q4jl3SlVDndfmFYoX3LJJZ77NYWj45Z1Q1eE9kdpgFHRIlbtptEMiQYmWowDAKgZR44cMUfL7dq1M0fwCE5vvPGGjB071nQ/aa9GVb8zFW2/K5UZ0RXq06ePTz+Xprn0tkZ9FaWvcVc7AwCAwKCjgbTbSOce0YnRygtEHOum0S6Wl19+2YyI0T4prSbWWdvco2tGjBhhulncNHWl/VLar6bP134vjbi0QAYAgECj3S5a51jSxT1XSF31xBNPSJcuXUyBr3dbXtMqPbRX+7V2795t+rm0aLVXr16m8MVd1Kpjmd3DkpQGKlrAo9W7WkSjH1LHLetyAAAINBdffLH079+/xMe0nqMue/DBB83F3ypVM+IUakYAwD+oGUFl+b1mBAAAoLoRjAAAjlKbT0eP2vddqdKJ8gAAdZOOntC6Px3SqTOB6u2angoctZNWeeiUH1pHqt+ZYxl5QzACAPDQRkX7/nUq8uJTnAMl0fnHWrdu7TN4pbIIRgAAPvQIVxuX/Pz8o2bmBLyFhYWZWWWPNXtGMAIAOIo2LjqMta4PZUVgoIAVAAA4imAEAAA4imAEAAA4qlbUjLgnidWZ3AAAQO3gbrfLm+y9VgQjBw4cMNfJyclOrwoAAKhCO67Twtfqc9Po7G463r1BgwbVOvmORmwa4KSkpHDOmxrGtvYPtrN/sJ39g+1c+7e1hhgaiLRo0aLMeUhqRWZEP0CrVq1qbPm64fmi+wfb2j/Yzv7BdvYPtnPt3tZlZUTcKGAFAACOIhgBAACOCupgJCoqSiZNmmSuUbPY1v7BdvYPtrN/sJ2DZ1vXigJWAABQdwV1ZgQAADiPYAQAADiKYAQAADiKYAQAADgqqIORadOmSdu2bSU6Olr69+8vS5cudXqVao3JkyfLSSedZGbFbdasmVxyySWydu1an+ccOXJEbr31VmnSpInUr19fLr/8cklLS/N5zrZt2+TCCy+U2NhYs5y///3vkp+f7+dPU3s8/vjjZhbiO+64w3Mf27n67NixQ6699lqzLWNiYqRHjx7y888/ex7Xev+JEydK8+bNzeODBg2S9evX+yxj7969cs0115iJoxo2bCg33nijHDx40IFPE5gKCgpkwoQJ0q5dO7MNO3ToII888ojPuUvYzlXz3XffydChQ81sp7qf+Oijj3wer67t+uuvv8ppp51m2k6dtfWJJ56o4hr7rlxQmjlzphUZGWnNmDHD+uOPP6zRo0dbDRs2tNLS0pxetVph8ODB1quvvmr9/vvv1sqVK60hQ4ZYrVu3tg4ePOh5zpgxY6zk5GRr/vz51s8//2ydfPLJ1sCBAz2P5+fnW927d7cGDRpkrVixwvriiy+shIQEa/z48Q59qsC2dOlSq23bttYJJ5xg3X777Z772c7VY+/evVabNm2s66+/3lqyZIm1adMma+7cudaGDRs8z3n88cet+Ph466OPPrJ++eUX6+KLL7batWtnHT582POc888/3+rZs6f1448/Wt9//73VsWNH66qrrnLoUwWeRx991GrSpIn12WefWZs3b7bee+89q379+tYzzzzjeQ7buWr0t33//fdbs2fP1sjO+vDDD30er47tmpmZaSUmJlrXXHON2f+/8847VkxMjPXiiy9axyJog5F+/fpZt956q+d2QUGB1aJFC2vy5MmOrldtlZ6ebr783377rbm9f/9+KyIiwuxo3FavXm2es3jxYs8PJzQ01EpNTfU854UXXrDi4uKsnJwcBz5F4Dpw4IDVqVMna968edYZZ5zhCUbYztXnnnvusU499dRSH3e5XFZSUpL15JNPeu7T7R8VFWV2yGrVqlVm2//000+e53z55ZdWSEiItWPHjhr+BLXDhRdeaN1www0+91122WWmcVNs5+pRPBipru36/PPPW40aNfLZd+hvp3Pnzse0vkHZTZObmyvLli0zKSrv89/o7cWLFzu6brVVZmamuW7cuLG51u2bl5fns427dOkirVu39mxjvdY0eGJiouc5gwcPNids+uOPP/z+GQKZdsNoN4v39lRs5+rzySefSN++feWKK64wXVm9e/eWl19+2fP45s2bJTU11Wdb6zk3tIvXe1traluX46bP1/3LkiVL/PyJAtPAgQNl/vz5sm7dOnP7l19+kYULF8oFF1xgbrOda0Z1bVd9zumnny6RkZE++xPtpt+3b1+V169WnCivumVkZJh+S++ds9Lba9ascWy9ais9q7LWMJxyyinSvXt3c59+6fXLql/s4ttYH3M/p6T/A/djsM2cOVOWL18uP/3001GPsZ2rz6ZNm+SFF16QcePGyX333We299/+9jezfUeOHOnZViVtS+9trYGMt/DwcBOks61t9957rwmENWgOCwsz++JHH33U1CkotnPNqK7tqtda71N8Ge7HGjVqVKX1C8pgBNV/1P7777+boxtULz2d9+233y7z5s0zxWKo2aBajwgfe+wxc1szI/q9nj59uglGUD3effddeeutt+Ttt9+W448/XlauXGkOZrToku0cvIKymyYhIcFE5MVHHOjtpKQkx9arNrrtttvks88+k2+++UZatWrluV+3o3aH7d+/v9RtrNcl/R+4H4PdDZOeni4nnniiOULRy7fffiv//ve/zd96RMJ2rh46wqBbt24+93Xt2tWMRPLeVmXtN/Ra/7+86aglHaHAtrbpSC7Njlx55ZWm+/C6666TsWPHmhF6iu1cM6pru9bU/iQogxFNu/bp08f0W3ofFentAQMGOLputYXWR2kg8uGHH8rXX399VNpOt29ERITPNtY+Rd2xu7exXv/2228+X37NAOiQsuKNQrA655xzzDbSo0f3RY/eNaXt/pvtXD20m7H48HSta2jTpo35W7/jurP13tba3aB96d7bWgNDDSLd9Peh+xftm4fIoUOHTA2CNz041G2k2M41o7q2qz5HhxBrrZr3/qRz585V7qIxrCAe2qtVxK+99pqpIP7zn/9shvZ6jzhA6W655RYzRGzBggXWrl27PJdDhw75DDnV4b5ff/21GXI6YMAAcyk+5PS8884zw4PnzJljNW3alCGn5fAeTaPYztU3dDo8PNwMPV2/fr311ltvWbGxsdabb77pMzRS9xMff/yx9euvv1rDhg0rcWhk7969zfDghQsXmlFQwT7k1NvIkSOtli1beob26jBUHWp+9913e57Ddq76qDsdvq8Xbd6nTJli/t66dWu1bVcdgaNDe6+77joztFfbUv2dMLT3GDz77LNmJ67zjehQXx1XjYrRL3pJF517xE2/4H/5y1/MMDD9sl566aUmYPG2ZcsW64ILLjDj1HWHdOedd1p5eXkOfKLaG4ywnavPp59+agI3PVDp0qWL9dJLL/k8rsMjJ0yYYHbG+pxzzjnHWrt2rc9z9uzZY3beOneGDp8eNWqUaSRgy8rKMt9f3fdGR0db7du3N3NjeA8VZTtXzTfffFPiflkDwOrcrjpHiQ6D12VoYKlBzrEK0X+qnlcBAAA4NkFZMwIAAAIHwQgAAHAUwQgAAHAUwQgAAHAUwQgAAHAUwQgAAHAUwQgAAHAUwQgAAHAUwQgAAHAUwQgAAHAUwQgAAHAUwQgAABAn/T+UDqO2BdLYVQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the validation accuracy is quite high (which is the result from the test dataset)\n",
    "# training accuracy is a bit low, but val_accuracy is usually more important to maximize\n",
    "# training accuracy being low implies there's room for improvement still in the model\n",
    "loss_df[['accuracy', 'val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model_classification_opt1.keras\n",
    "from keras.models import load_model\n",
    "model = load_model('best_model_classification1_kt.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data evaluation:\n",
      "[0.2653057277202606, 0.9657142758369446]\n",
      "\n",
      "Train data evaluation:\n",
      "[0.26472750306129456, 0.9523077011108398]\n"
     ]
    }
   ],
   "source": [
    "# compare the final model loss/accuracy/evaluation values\n",
    "# the values should again match mostly\n",
    "print(\"Test data evaluation:\")\n",
    "print(model.evaluate(X_test, y_test, verbose=0))\n",
    "print(\"\\nTrain data evaluation:\")\n",
    "print(model.evaluate(X_train, y_train, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n"
     ]
    }
   ],
   "source": [
    "# get predictions and convert with argmax() to get categories \n",
    "# instead of raw probabilities\n",
    "test_predictions = model.predict(X_test)\n",
    "test_predictions = np.argmax(test_predictions, axis=1)\n",
    "\n",
    "# convert also y-test -values with argmax\n",
    "y_test = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "sns.heatmap(confusion_matrix(y_test, test_predictions), annot=True, fmt='g', \n",
    "            xticklabels=categories, yticklabels=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    1: Cheap       0.95      1.00      0.98        83\n",
      "     2: Avg-       0.94      0.95      0.95        85\n",
      "     3: Avg+       0.99      0.93      0.96        98\n",
      "4: Expensive       0.98      0.99      0.98        84\n",
      "\n",
      "    accuracy                           0.97       350\n",
      "   macro avg       0.97      0.97      0.97       350\n",
      "weighted avg       0.97      0.97      0.97       350\n",
      "\n",
      "\n",
      "Model overall accuracy: 96.57%\n"
     ]
    }
   ],
   "source": [
    "# print the classification report based on true values and predictions\n",
    "print(classification_report(y_test, test_predictions, target_names=categories))\n",
    "\n",
    "# get overall accuracy of the model and print it\n",
    "acc = accuracy_score(y_test, test_predictions)\n",
    "print(\"\\nModel overall accuracy: {:.2f}%\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.998248"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The AUC score is a super sensitive metric\n",
    "# you often get low scores, even 0.5\n",
    "\n",
    "# in binary classification, AUC values are often interpreted as follows:\n",
    "# A binary classifier is useful only when it achieves ROC-AUC score greater than 0.5 and as near to 1 as possible. \n",
    "# If a classifier yields a score less than 0.5, it simply means that the model is performing worse \n",
    "# than a random classifier, and therefore is useless.\n",
    "\n",
    "# In multi category classification , AUC values are often interpreted as follows: \n",
    "# 0.5-0.6 (failed)\n",
    "# 0.6-0.7 (worthless)\n",
    "# 0.7-0.8 (poor)\n",
    "# 0.8-0.9 (good)\n",
    "# > 0.9 (excellent)\n",
    "\n",
    "# get ROC-AUC -score\n",
    "roc_auc_score(y, model.predict(X), multi_class=\"ovr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model in practice with new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['battery_power', 'fc', 'int_memory', 'mobile_wt', 'n_cores', 'pc',\n",
       "       'px_height', 'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>fc</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>pc</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>756</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>2: Avg-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>905</td>\n",
       "      <td>1988</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3: Avg+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1263</td>\n",
       "      <td>1716</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3: Avg+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   battery_power  fc  int_memory  mobile_wt  n_cores  pc  px_height  px_width  \\\n",
       "0            842   1           7        188        2   2         20       756   \n",
       "1           1021   0          53        136        3   6        905      1988   \n",
       "2            563   2          41        145        5   6       1263      1716   \n",
       "\n",
       "    ram  sc_h  sc_w  talk_time price_range  \n",
       "0  2549     9     7         19     2: Avg-  \n",
       "1  2631    17     3          7     3: Avg+  \n",
       "2  2603    11     2          9     3: Avg+  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Predicted price range: 4: Expensive\n",
      "\n",
      "Probabilities by class:\n",
      "['1: Cheap', '2: Avg-', '3: Avg+', '4: Expensive']\n",
      "[0.000000002 0.000112765 0.21761315  0.78227407 ]\n"
     ]
    }
   ],
   "source": [
    "# let's try with some new imaginary data\n",
    "# modify this as needed regarding your own dataset\n",
    "tester_row = {\n",
    "    'battery_power': 1021, \n",
    "    'fc': 0, \n",
    "    'int_memory': 53, \n",
    "    'mobile_wt': 136, \n",
    "    'n_cores': 3, \n",
    "    'pc': 6,\n",
    "    'px_height': 905, \n",
    "    'px_width': 1988, \n",
    "    'ram': 3031, \n",
    "    'sc_h': 17, \n",
    "    'sc_w': 3, \n",
    "    'talk_time': 7 \n",
    "}\n",
    "\n",
    "# convert to pandas-format\n",
    "tester_row = pd.DataFrame([tester_row])\n",
    "result = model.predict(tester_row)[0]\n",
    "result_text = categories[np.argmax(result)]\n",
    "\n",
    "# switch to decimal representation \n",
    "np.set_printoptions(precision=9, suppress=True)\n",
    "\n",
    "# 0 cheapest, 3 most expensive\n",
    "print(f\"Predicted price range: {result_text}\")\n",
    "print()\n",
    "print(\"Probabilities by class:\")\n",
    "print(categories)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
