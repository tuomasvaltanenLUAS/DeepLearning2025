{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN for classification, example 1, mobile phone price class classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is experimentation with Keras Tuner, see details below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "# pip install tensorflow\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# THIS IS OPTIONAL, so you can comment out the following code\n",
    "# if you don't wish to remove randomness\n",
    "# you might want to lock down the random seed throughout,\n",
    "# so you we get same results every time (given we change nothing in the data afterwards)\n",
    "\n",
    "# random seed locking code original from ChatGPT => has been tested that it works\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Set a fixed seed value\n",
    "SEED = 12345\n",
    "\n",
    "# 1. Set Python's built-in random module seed\n",
    "random.seed(SEED)\n",
    "\n",
    "# 2. Set NumPy random seed\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# 3. Set TensorFlow seed\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# 4. Set environment variables (affects some backend randomness)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "# Optional: control inter-op and intra-op parallelism for determinism\n",
    "# (can slightly slow down training, but improves reproducibility)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "df = pd.read_csv(\"mobilepricerangeclass.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>756</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>905</td>\n",
       "      <td>1988</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1263</td>\n",
       "      <td>1716</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1216</td>\n",
       "      <td>1786</td>\n",
       "      <td>2769</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1208</td>\n",
       "      <td>1212</td>\n",
       "      <td>1411</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n",
       "0            842     0          2.2         0   1       0           7    0.6   \n",
       "1           1021     1          0.5         1   0       1          53    0.7   \n",
       "2            563     1          0.5         1   2       1          41    0.9   \n",
       "3            615     1          2.5         0   0       0          10    0.8   \n",
       "4           1821     1          1.2         0  13       1          44    0.6   \n",
       "\n",
       "   mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n",
       "0        188        2  ...         20       756  2549     9     7         19   \n",
       "1        136        3  ...        905      1988  2631    17     3          7   \n",
       "2        145        5  ...       1263      1716  2603    11     2          9   \n",
       "3        131        6  ...       1216      1786  2769    16     8         11   \n",
       "4        141        2  ...       1208      1212  1411     8     2         15   \n",
       "\n",
       "   three_g  touch_screen  wifi  price_range  \n",
       "0        0             0     1            1  \n",
       "1        1             1     0            2  \n",
       "2        1             1     0            2  \n",
       "3        1             0     0            2  \n",
       "4        1             1     0            1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the column explanations here\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price_range\n",
       "1    500\n",
       "2    500\n",
       "3    500\n",
       "0    500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# even distribution along the target classes\n",
    "df['price_range'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let' remove some of the variables that are probably not extremely important in this dataset\n",
    "# NOTE! we didn't spend much time analyzing/optimizing these, this just an example\n",
    "# on how you can use correlation matrix, SelectKBest etc. to choose your variables\n",
    "removables = ['touch_screen', 'dual_sim', 'clock_speed', 'm_dep', 'three_g', 'four_g', 'wifi', 'blue']\n",
    "df = df.drop(removables, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's assign actual names for the price classes\n",
    "# so we have nicer metrics and results later (after training model)\n",
    "df['price_range'] = df['price_range'].replace({\n",
    "    0: \"1: Cheap\",\n",
    "    1: \"2: Avg-\",\n",
    "    2: \"3: Avg+\",\n",
    "    3: \"4: Expensive\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1: Cheap', '2: Avg-', '3: Avg+', '4: Expensive']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# everything else except the target variable\n",
    "X = df.drop(\"price_range\", axis=1)\n",
    "\n",
    "# have only the target variable here (dependent variable)\n",
    "y_temp = df['price_range']\n",
    "\n",
    "# since we are doing classification, we have to process our target values with an encoder\n",
    "# and convert them into a categorical TensorFlow/Keras -format \n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y_temp)\n",
    "\n",
    "# Converting the label into a matrix form\n",
    "y = tf.keras.utils.to_categorical(y_enc)\n",
    "\n",
    "# save the categories into a helper list for later purposes\n",
    "categories = list(le.classes_)\n",
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train/test/validation -split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this time, let's split the data into 65% (training data) and 35% (temporary data)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.35)\n",
    "\n",
    "# step 2, split the temporary data in HALF (0.5) => 17.5% test and 17.5% validation\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USE KERAS TUNER TO FIND OPTIMAL PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 01m 29s]\n",
      "val_accuracy: 0.9428571462631226\n",
      "\n",
      "Best val_accuracy So Far: 0.9442857205867767\n",
      "Total elapsed time: 00h 05m 38s\n"
     ]
    }
   ],
   "source": [
    "# pip install keras-tuner\n",
    "import keras_tuner\n",
    "\n",
    "def build_model(hp):\n",
    "    # iniatlize sequential test neural network\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # first layer, batch normalization + input shape, same as in typical neural network\n",
    "    model.add(layers.BatchNormalization(input_shape=(len(X.columns),)),)\n",
    "    \n",
    "    # add the first actual layer including the regularizer\n",
    "    model.add(\n",
    "        layers.Dense(\n",
    "            # Tune number of units separately.\n",
    "            units=hp.Int(f\"units_0\", min_value=4, max_value=96, step=4),\n",
    "            activation=hp.Choice(\"activation\", [\"relu\"]),\n",
    "            kernel_regularizer=keras.regularizers.l1(hp.Float(\"l1\", min_value=0.025, max_value=0.35, sampling=\"log\"))\n",
    "        )\n",
    "    )\n",
    "        \n",
    "    # automate a dropout layer\n",
    "    if hp.Boolean(\"dropout\"):\n",
    "        model.add(layers.Dropout(\n",
    "            hp.Float(\"rate\", min_value=0.1, max_value=0.5, step=0.025)\n",
    "            ))\n",
    "\n",
    "    # try additional layers, 1-3 extra layers\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 3)):\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                # Tune number of units separately.\n",
    "                units=hp.Int(f\"units_{i + 1}\", min_value=8, max_value=96, step=4),\n",
    "                activation=hp.Choice(\"activation\", [\"relu\"]),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # output layer, only one node since this is regression\n",
    "    model.add(layers.Dense(len(categories), activation=\"softmax\"))\n",
    "\n",
    "    # automate learning rate tests\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-5, max_value=1e-1, sampling=\"log\")\n",
    "\n",
    "    # compile the test neural network\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='categorical_crossentropy', metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# build the model + use RandomSearch to actually search the best options for our neural network\n",
    "build_model(keras_tuner.HyperParameters())\n",
    "\n",
    "# use val_loss as the objective, because regression tasks do not have accuracy\n",
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=5,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"optimizations1\",\n",
    "    project_name=\"classification1test\",\n",
    ")\n",
    "\n",
    "# start searching\n",
    "tuner.search(X_train, y_train, epochs=250, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fsdaafdsafsd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mfsdaafdsafsd\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'fsdaafdsafsd' is not defined"
     ]
    }
   ],
   "source": [
    "fsdaafdsafsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in optimizations1\\classification1test\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "units_0: 64\n",
      "activation: relu\n",
      "l1: 0.14404386359839785\n",
      "dropout: True\n",
      "num_layers: 2\n",
      "units_1: 92\n",
      "lr: 0.0005495772755430749\n",
      "rate: 0.1\n",
      "units_2: 8\n",
      "Score: 0.9442857205867767\n",
      "\n",
      "Trial 4 summary\n",
      "Hyperparameters:\n",
      "units_0: 84\n",
      "activation: relu\n",
      "l1: 0.09277436194925\n",
      "dropout: False\n",
      "num_layers: 2\n",
      "units_1: 48\n",
      "lr: 8.236127782483122e-05\n",
      "rate: 0.275\n",
      "units_2: 16\n",
      "units_3: 32\n",
      "Score: 0.9428571462631226\n",
      "\n",
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "units_0: 76\n",
      "activation: relu\n",
      "l1: 0.030030643841972265\n",
      "dropout: True\n",
      "num_layers: 3\n",
      "units_1: 12\n",
      "lr: 3.933578568657208e-05\n",
      "rate: 0.375\n",
      "units_2: 80\n",
      "units_3: 8\n",
      "Score: 0.9399999976158142\n",
      "\n",
      "Trial 3 summary\n",
      "Hyperparameters:\n",
      "units_0: 80\n",
      "activation: relu\n",
      "l1: 0.06506737046346531\n",
      "dropout: True\n",
      "num_layers: 1\n",
      "units_1: 72\n",
      "lr: 0.072305430326835\n",
      "rate: 0.25\n",
      "units_2: 8\n",
      "units_3: 84\n",
      "Score: 0.8885714411735535\n",
      "\n",
      "Trial 2 summary\n",
      "Hyperparameters:\n",
      "units_0: 76\n",
      "activation: relu\n",
      "l1: 0.09581597838029794\n",
      "dropout: False\n",
      "num_layers: 3\n",
      "units_1: 84\n",
      "lr: 0.07059356474578148\n",
      "rate: 0.42500000000000004\n",
      "units_2: 44\n",
      "units_3: 72\n",
      "Score: 0.22857142984867096\n"
     ]
    }
   ],
   "source": [
    "# print out the result and suggestions\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tuomas.valtanen\\DL2025lecturenotes2\\DeepLearning2025\\.venv\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:142: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "c:\\Users\\tuomas.valtanen\\DL2025lecturenotes2\\DeepLearning2025\\.venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 22 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">92</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,980</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">744</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │            \u001b[38;5;34m48\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m92\u001b[0m)             │         \u001b[38;5;34m5,980\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m744\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m36\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,640</span> (29.84 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,640\u001b[0m (29.84 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,616</span> (29.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,616\u001b[0m (29.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> (96.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m24\u001b[0m (96.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Get the top 2 models.\n",
    "models = tuner.get_best_models(num_models=1)\n",
    "best_model = models[0]\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the neural network structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: you can use all the same callback features as in regression: ModelCheckpoint, EarlyStop, ReduceLROnPlateau, Dropout-layers...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tuomas.valtanen\\DL2025lecturenotes2\\DeepLearning2025\\.venv\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:142: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">92</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,980</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">744</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │            \u001b[38;5;34m48\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m92\u001b[0m)             │         \u001b[38;5;34m5,980\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m744\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m36\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,640</span> (29.84 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,640\u001b[0m (29.84 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,616</span> (29.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,616\u001b[0m (29.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> (96.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m24\u001b[0m (96.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# needed imports for ModelCheckpoint etc. callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# for EarlyStop/ReduceLROnPlateau, see materials and Moodle\n",
    "# for examples on how to use and when to use (usually more useful with classification)\n",
    "\n",
    "# create a model checkpoint to a file, and only save the best one\n",
    "mc = ModelCheckpoint('best_model_classification1_kt.keras', monitor='val_accuracy', mode='max', save_best_only=True)\n",
    "\n",
    "# combine all active callbacks into a list\n",
    "# have only those you need, for example only ModelCheckpoint\n",
    "callback_list = [mc]\n",
    "\n",
    "# Trial 0 summary\n",
    "# Hyperparameters:\n",
    "# units_0: 64\n",
    "# activation: relu\n",
    "# l1: 0.14404386359839785\n",
    "# dropout: True\n",
    "# num_layers: 2\n",
    "# units_1: 92\n",
    "# lr: 0.0005495772755430749\n",
    "# rate: 0.1\n",
    "# units_2: 8\n",
    "# Score: 0.9442857205867767\n",
    "\n",
    "# ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "# ┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n",
    "# ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "# │ batch_normalization             │ (None, 12)             │            48 │\n",
    "# │ (BatchNormalization)            │                        │               │\n",
    "# ├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "# │ dense (Dense)                   │ (None, 64)             │           832 │\n",
    "# ├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "# │ dropout (Dropout)               │ (None, 64)             │             0 │\n",
    "# ├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "# │ dense_1 (Dense)                 │ (None, 92)             │         5,980 │\n",
    "# ├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "# │ dense_2 (Dense)                 │ (None, 8)              │           744 │\n",
    "# ├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "# │ dense_3 (Dense)                 │ (None, 4)              │            36 │\n",
    "# └─────────────────────────────────┴────────────────────────┴───────────────┘\n",
    "\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.BatchNormalization(input_shape=(len(X.columns),)),\n",
    "        layers.Dense(64, activation=\"relu\", kernel_regularizer=keras.regularizers.l1(l1=0.14404386359839785)),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Dense(92, activation=\"relu\"),\n",
    "        layers.Dense(8, activation=\"relu\"),\n",
    "        layers.Dense(len(categories), activation=\"softmax\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# save the learning rate to a variable for easier changes\n",
    "optimal_lr = 0.0005495772755430749\n",
    "\n",
    "# compile the model, this time we use categorical crossentropy for loss -function\n",
    "# and we also measure the accuracy of our model in the metrics\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=optimal_lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2846 - loss: 15.5220 - val_accuracy: 0.3257 - val_loss: 14.2904\n",
      "Epoch 2/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3854 - loss: 13.1651 - val_accuracy: 0.3914 - val_loss: 12.0066\n",
      "Epoch 3/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4746 - loss: 11.0156 - val_accuracy: 0.3857 - val_loss: 9.9653\n",
      "Epoch 4/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5769 - loss: 9.0709 - val_accuracy: 0.4714 - val_loss: 8.1175\n",
      "Epoch 5/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6446 - loss: 7.3437 - val_accuracy: 0.6800 - val_loss: 6.4858\n",
      "Epoch 6/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6985 - loss: 5.8240 - val_accuracy: 0.7429 - val_loss: 5.0718\n",
      "Epoch 7/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7238 - loss: 4.5183 - val_accuracy: 0.7743 - val_loss: 3.8603\n",
      "Epoch 8/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7608 - loss: 3.4024 - val_accuracy: 0.8171 - val_loss: 2.8473\n",
      "Epoch 9/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7769 - loss: 2.4941 - val_accuracy: 0.8429 - val_loss: 2.0366\n",
      "Epoch 10/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7769 - loss: 1.7996 - val_accuracy: 0.8629 - val_loss: 1.4305\n",
      "Epoch 11/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7854 - loss: 1.2991 - val_accuracy: 0.8657 - val_loss: 1.0205\n",
      "Epoch 12/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7808 - loss: 0.9921 - val_accuracy: 0.8600 - val_loss: 0.7985\n",
      "Epoch 13/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7815 - loss: 0.8497 - val_accuracy: 0.8743 - val_loss: 0.7222\n",
      "Epoch 14/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8008 - loss: 0.8057 - val_accuracy: 0.8886 - val_loss: 0.6830\n",
      "Epoch 15/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7962 - loss: 0.7791 - val_accuracy: 0.8886 - val_loss: 0.6545\n",
      "Epoch 16/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7885 - loss: 0.7777 - val_accuracy: 0.9114 - val_loss: 0.6261\n",
      "Epoch 17/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8015 - loss: 0.7367 - val_accuracy: 0.9086 - val_loss: 0.6060\n",
      "Epoch 18/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8054 - loss: 0.7343 - val_accuracy: 0.8914 - val_loss: 0.5912\n",
      "Epoch 19/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8100 - loss: 0.7187 - val_accuracy: 0.9057 - val_loss: 0.5767\n",
      "Epoch 20/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8046 - loss: 0.7055 - val_accuracy: 0.9114 - val_loss: 0.5546\n",
      "Epoch 21/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8115 - loss: 0.6844 - val_accuracy: 0.9114 - val_loss: 0.5451\n",
      "Epoch 22/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8100 - loss: 0.6779 - val_accuracy: 0.9029 - val_loss: 0.5307\n",
      "Epoch 23/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7985 - loss: 0.6909 - val_accuracy: 0.9114 - val_loss: 0.5240\n",
      "Epoch 24/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8062 - loss: 0.6753 - val_accuracy: 0.9114 - val_loss: 0.5185\n",
      "Epoch 25/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8062 - loss: 0.6782 - val_accuracy: 0.9143 - val_loss: 0.5090\n",
      "Epoch 26/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8100 - loss: 0.6590 - val_accuracy: 0.9086 - val_loss: 0.5038\n",
      "Epoch 27/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8138 - loss: 0.6466 - val_accuracy: 0.9114 - val_loss: 0.4918\n",
      "Epoch 28/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8154 - loss: 0.6529 - val_accuracy: 0.9171 - val_loss: 0.4865\n",
      "Epoch 29/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7985 - loss: 0.6542 - val_accuracy: 0.9171 - val_loss: 0.4813\n",
      "Epoch 30/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8146 - loss: 0.6565 - val_accuracy: 0.9257 - val_loss: 0.4758\n",
      "Epoch 31/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8138 - loss: 0.6488 - val_accuracy: 0.9257 - val_loss: 0.4730\n",
      "Epoch 32/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8192 - loss: 0.6361 - val_accuracy: 0.9086 - val_loss: 0.4674\n",
      "Epoch 33/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8000 - loss: 0.6340 - val_accuracy: 0.9086 - val_loss: 0.4640\n",
      "Epoch 34/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7992 - loss: 0.6330 - val_accuracy: 0.9171 - val_loss: 0.4624\n",
      "Epoch 35/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8262 - loss: 0.6251 - val_accuracy: 0.9171 - val_loss: 0.4570\n",
      "Epoch 36/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8115 - loss: 0.6229 - val_accuracy: 0.9171 - val_loss: 0.4471\n",
      "Epoch 37/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8238 - loss: 0.6077 - val_accuracy: 0.9257 - val_loss: 0.4452\n",
      "Epoch 38/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8223 - loss: 0.6149 - val_accuracy: 0.9200 - val_loss: 0.4430\n",
      "Epoch 39/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8123 - loss: 0.6193 - val_accuracy: 0.9171 - val_loss: 0.4395\n",
      "Epoch 40/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8285 - loss: 0.6000 - val_accuracy: 0.9114 - val_loss: 0.4409\n",
      "Epoch 41/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8192 - loss: 0.6140 - val_accuracy: 0.9171 - val_loss: 0.4340\n",
      "Epoch 42/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8115 - loss: 0.6200 - val_accuracy: 0.9229 - val_loss: 0.4326\n",
      "Epoch 43/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8108 - loss: 0.6088 - val_accuracy: 0.9257 - val_loss: 0.4280\n",
      "Epoch 44/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8269 - loss: 0.5917 - val_accuracy: 0.9229 - val_loss: 0.4278\n",
      "Epoch 45/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8169 - loss: 0.6003 - val_accuracy: 0.9114 - val_loss: 0.4270\n",
      "Epoch 46/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8285 - loss: 0.5949 - val_accuracy: 0.9143 - val_loss: 0.4223\n",
      "Epoch 47/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8008 - loss: 0.5994 - val_accuracy: 0.9200 - val_loss: 0.4185\n",
      "Epoch 48/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8192 - loss: 0.5904 - val_accuracy: 0.9286 - val_loss: 0.4147\n",
      "Epoch 49/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8146 - loss: 0.5994 - val_accuracy: 0.9400 - val_loss: 0.4137\n",
      "Epoch 50/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8238 - loss: 0.5936 - val_accuracy: 0.9371 - val_loss: 0.4134\n",
      "Epoch 51/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8185 - loss: 0.5908 - val_accuracy: 0.9314 - val_loss: 0.4099\n",
      "Epoch 52/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8238 - loss: 0.5757 - val_accuracy: 0.9371 - val_loss: 0.4053\n",
      "Epoch 53/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8238 - loss: 0.5821 - val_accuracy: 0.9314 - val_loss: 0.4083\n",
      "Epoch 54/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8292 - loss: 0.5657 - val_accuracy: 0.9314 - val_loss: 0.3995\n",
      "Epoch 55/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8169 - loss: 0.5939 - val_accuracy: 0.9257 - val_loss: 0.4044\n",
      "Epoch 56/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8138 - loss: 0.5862 - val_accuracy: 0.9286 - val_loss: 0.4008\n",
      "Epoch 57/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8285 - loss: 0.5854 - val_accuracy: 0.9314 - val_loss: 0.3961\n",
      "Epoch 58/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8246 - loss: 0.5751 - val_accuracy: 0.9229 - val_loss: 0.4000\n",
      "Epoch 59/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8254 - loss: 0.5761 - val_accuracy: 0.9257 - val_loss: 0.4001\n",
      "Epoch 60/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8223 - loss: 0.5856 - val_accuracy: 0.9314 - val_loss: 0.3975\n",
      "Epoch 61/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.5625 - val_accuracy: 0.9286 - val_loss: 0.3958\n",
      "Epoch 62/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8223 - loss: 0.5723 - val_accuracy: 0.9429 - val_loss: 0.3918\n",
      "Epoch 63/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8300 - loss: 0.5638 - val_accuracy: 0.9314 - val_loss: 0.3874\n",
      "Epoch 64/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8177 - loss: 0.5605 - val_accuracy: 0.9229 - val_loss: 0.3906\n",
      "Epoch 65/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8323 - loss: 0.5661 - val_accuracy: 0.9257 - val_loss: 0.3869\n",
      "Epoch 66/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8146 - loss: 0.5700 - val_accuracy: 0.9229 - val_loss: 0.3897\n",
      "Epoch 67/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8200 - loss: 0.5769 - val_accuracy: 0.9371 - val_loss: 0.3888\n",
      "Epoch 68/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8369 - loss: 0.5613 - val_accuracy: 0.9257 - val_loss: 0.3865\n",
      "Epoch 69/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8177 - loss: 0.5567 - val_accuracy: 0.9429 - val_loss: 0.3787\n",
      "Epoch 70/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8292 - loss: 0.5521 - val_accuracy: 0.9171 - val_loss: 0.3812\n",
      "Epoch 71/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8215 - loss: 0.5524 - val_accuracy: 0.9171 - val_loss: 0.3937\n",
      "Epoch 72/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8331 - loss: 0.5476 - val_accuracy: 0.9371 - val_loss: 0.3782\n",
      "Epoch 73/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8169 - loss: 0.5689 - val_accuracy: 0.9400 - val_loss: 0.3789\n",
      "Epoch 74/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8238 - loss: 0.5588 - val_accuracy: 0.9429 - val_loss: 0.3760\n",
      "Epoch 75/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8200 - loss: 0.5514 - val_accuracy: 0.9314 - val_loss: 0.3743\n",
      "Epoch 76/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8192 - loss: 0.5564 - val_accuracy: 0.9229 - val_loss: 0.3767\n",
      "Epoch 77/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8292 - loss: 0.5536 - val_accuracy: 0.9229 - val_loss: 0.3790\n",
      "Epoch 78/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8185 - loss: 0.5487 - val_accuracy: 0.9371 - val_loss: 0.3735\n",
      "Epoch 79/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8215 - loss: 0.5612 - val_accuracy: 0.9286 - val_loss: 0.3755\n",
      "Epoch 80/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8208 - loss: 0.5612 - val_accuracy: 0.9343 - val_loss: 0.3711\n",
      "Epoch 81/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8285 - loss: 0.5477 - val_accuracy: 0.9371 - val_loss: 0.3719\n",
      "Epoch 82/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8138 - loss: 0.5543 - val_accuracy: 0.9343 - val_loss: 0.3710\n",
      "Epoch 83/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8138 - loss: 0.5581 - val_accuracy: 0.9286 - val_loss: 0.3712\n",
      "Epoch 84/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8262 - loss: 0.5419 - val_accuracy: 0.9257 - val_loss: 0.3696\n",
      "Epoch 85/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8354 - loss: 0.5269 - val_accuracy: 0.9171 - val_loss: 0.3701\n",
      "Epoch 86/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8085 - loss: 0.5645 - val_accuracy: 0.9314 - val_loss: 0.3684\n",
      "Epoch 87/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8246 - loss: 0.5457 - val_accuracy: 0.9429 - val_loss: 0.3645\n",
      "Epoch 88/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8277 - loss: 0.5367 - val_accuracy: 0.9286 - val_loss: 0.3645\n",
      "Epoch 89/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8362 - loss: 0.5279 - val_accuracy: 0.9343 - val_loss: 0.3648\n",
      "Epoch 90/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8308 - loss: 0.5336 - val_accuracy: 0.9314 - val_loss: 0.3629\n",
      "Epoch 91/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8262 - loss: 0.5357 - val_accuracy: 0.9229 - val_loss: 0.3627\n",
      "Epoch 92/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8338 - loss: 0.5321 - val_accuracy: 0.9343 - val_loss: 0.3605\n",
      "Epoch 93/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8238 - loss: 0.5280 - val_accuracy: 0.9371 - val_loss: 0.3559\n",
      "Epoch 94/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8246 - loss: 0.5389 - val_accuracy: 0.9229 - val_loss: 0.3611\n",
      "Epoch 95/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8308 - loss: 0.5351 - val_accuracy: 0.9229 - val_loss: 0.3605\n",
      "Epoch 96/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.5281 - val_accuracy: 0.9286 - val_loss: 0.3568\n",
      "Epoch 97/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8177 - loss: 0.5312 - val_accuracy: 0.9229 - val_loss: 0.3586\n",
      "Epoch 98/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8246 - loss: 0.5451 - val_accuracy: 0.9371 - val_loss: 0.3553\n",
      "Epoch 99/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8254 - loss: 0.5296 - val_accuracy: 0.9200 - val_loss: 0.3554\n",
      "Epoch 100/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8215 - loss: 0.5297 - val_accuracy: 0.9343 - val_loss: 0.3530\n",
      "Epoch 101/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8323 - loss: 0.5343 - val_accuracy: 0.9286 - val_loss: 0.3525\n",
      "Epoch 102/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8238 - loss: 0.5277 - val_accuracy: 0.9371 - val_loss: 0.3494\n",
      "Epoch 103/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8285 - loss: 0.5365 - val_accuracy: 0.9286 - val_loss: 0.3484\n",
      "Epoch 104/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.5189 - val_accuracy: 0.9229 - val_loss: 0.3532\n",
      "Epoch 105/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8354 - loss: 0.5310 - val_accuracy: 0.9257 - val_loss: 0.3493\n",
      "Epoch 106/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8269 - loss: 0.5253 - val_accuracy: 0.9371 - val_loss: 0.3472\n",
      "Epoch 107/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8362 - loss: 0.5074 - val_accuracy: 0.9171 - val_loss: 0.3513\n",
      "Epoch 108/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8185 - loss: 0.5448 - val_accuracy: 0.9171 - val_loss: 0.3555\n",
      "Epoch 109/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8269 - loss: 0.5289 - val_accuracy: 0.9371 - val_loss: 0.3495\n",
      "Epoch 110/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.5167 - val_accuracy: 0.9229 - val_loss: 0.3486\n",
      "Epoch 111/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.5143 - val_accuracy: 0.9400 - val_loss: 0.3451\n",
      "Epoch 112/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8292 - loss: 0.5225 - val_accuracy: 0.9400 - val_loss: 0.3434\n",
      "Epoch 113/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8231 - loss: 0.5297 - val_accuracy: 0.9257 - val_loss: 0.3486\n",
      "Epoch 114/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8269 - loss: 0.5109 - val_accuracy: 0.9400 - val_loss: 0.3426\n",
      "Epoch 115/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8223 - loss: 0.5136 - val_accuracy: 0.9457 - val_loss: 0.3387\n",
      "Epoch 116/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8300 - loss: 0.5214 - val_accuracy: 0.9257 - val_loss: 0.3426\n",
      "Epoch 117/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8262 - loss: 0.5144 - val_accuracy: 0.9200 - val_loss: 0.3487\n",
      "Epoch 118/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8292 - loss: 0.5235 - val_accuracy: 0.9314 - val_loss: 0.3412\n",
      "Epoch 119/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8354 - loss: 0.5147 - val_accuracy: 0.9400 - val_loss: 0.3405\n",
      "Epoch 120/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8354 - loss: 0.5035 - val_accuracy: 0.9371 - val_loss: 0.3378\n",
      "Epoch 121/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8315 - loss: 0.5217 - val_accuracy: 0.9343 - val_loss: 0.3445\n",
      "Epoch 122/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8338 - loss: 0.5150 - val_accuracy: 0.9200 - val_loss: 0.3465\n",
      "Epoch 123/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8215 - loss: 0.5188 - val_accuracy: 0.9229 - val_loss: 0.3424\n",
      "Epoch 124/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8285 - loss: 0.5114 - val_accuracy: 0.9229 - val_loss: 0.3396\n",
      "Epoch 125/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8323 - loss: 0.5153 - val_accuracy: 0.9200 - val_loss: 0.3414\n",
      "Epoch 126/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8369 - loss: 0.5110 - val_accuracy: 0.9314 - val_loss: 0.3382\n",
      "Epoch 127/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8254 - loss: 0.5126 - val_accuracy: 0.9143 - val_loss: 0.3392\n",
      "Epoch 128/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8369 - loss: 0.5105 - val_accuracy: 0.9257 - val_loss: 0.3393\n",
      "Epoch 129/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8400 - loss: 0.5000 - val_accuracy: 0.9171 - val_loss: 0.3423\n",
      "Epoch 130/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8331 - loss: 0.4987 - val_accuracy: 0.9371 - val_loss: 0.3341\n",
      "Epoch 131/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8323 - loss: 0.5033 - val_accuracy: 0.9200 - val_loss: 0.3341\n",
      "Epoch 132/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8354 - loss: 0.5009 - val_accuracy: 0.9314 - val_loss: 0.3344\n",
      "Epoch 133/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8254 - loss: 0.5156 - val_accuracy: 0.9257 - val_loss: 0.3343\n",
      "Epoch 134/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8354 - loss: 0.5112 - val_accuracy: 0.9343 - val_loss: 0.3337\n",
      "Epoch 135/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8315 - loss: 0.5034 - val_accuracy: 0.9314 - val_loss: 0.3310\n",
      "Epoch 136/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8262 - loss: 0.5135 - val_accuracy: 0.9171 - val_loss: 0.3329\n",
      "Epoch 137/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8346 - loss: 0.5034 - val_accuracy: 0.9171 - val_loss: 0.3366\n",
      "Epoch 138/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8362 - loss: 0.4907 - val_accuracy: 0.9229 - val_loss: 0.3321\n",
      "Epoch 139/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8400 - loss: 0.4937 - val_accuracy: 0.9200 - val_loss: 0.3345\n",
      "Epoch 140/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8354 - loss: 0.5097 - val_accuracy: 0.9314 - val_loss: 0.3336\n",
      "Epoch 141/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4923 - val_accuracy: 0.9200 - val_loss: 0.3295\n",
      "Epoch 142/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8246 - loss: 0.5097 - val_accuracy: 0.9286 - val_loss: 0.3306\n",
      "Epoch 143/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8400 - loss: 0.4897 - val_accuracy: 0.9314 - val_loss: 0.3258\n",
      "Epoch 144/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.4904 - val_accuracy: 0.9171 - val_loss: 0.3305\n",
      "Epoch 145/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8292 - loss: 0.5143 - val_accuracy: 0.9286 - val_loss: 0.3266\n",
      "Epoch 146/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8400 - loss: 0.4857 - val_accuracy: 0.9257 - val_loss: 0.3263\n",
      "Epoch 147/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8385 - loss: 0.4952 - val_accuracy: 0.9343 - val_loss: 0.3243\n",
      "Epoch 148/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8492 - loss: 0.4888 - val_accuracy: 0.9171 - val_loss: 0.3251\n",
      "Epoch 149/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8246 - loss: 0.5048 - val_accuracy: 0.9257 - val_loss: 0.3288\n",
      "Epoch 150/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8292 - loss: 0.5063 - val_accuracy: 0.9400 - val_loss: 0.3183\n",
      "Epoch 151/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8323 - loss: 0.4951 - val_accuracy: 0.9200 - val_loss: 0.3249\n",
      "Epoch 152/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8162 - loss: 0.5020 - val_accuracy: 0.9314 - val_loss: 0.3284\n",
      "Epoch 153/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8331 - loss: 0.5084 - val_accuracy: 0.9286 - val_loss: 0.3270\n",
      "Epoch 154/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8254 - loss: 0.4980 - val_accuracy: 0.9257 - val_loss: 0.3233\n",
      "Epoch 155/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8369 - loss: 0.4896 - val_accuracy: 0.9229 - val_loss: 0.3263\n",
      "Epoch 156/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8315 - loss: 0.4922 - val_accuracy: 0.9314 - val_loss: 0.3220\n",
      "Epoch 157/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8369 - loss: 0.4912 - val_accuracy: 0.9314 - val_loss: 0.3199\n",
      "Epoch 158/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.4894 - val_accuracy: 0.9314 - val_loss: 0.3242\n",
      "Epoch 159/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8377 - loss: 0.4940 - val_accuracy: 0.9171 - val_loss: 0.3248\n",
      "Epoch 160/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8269 - loss: 0.5059 - val_accuracy: 0.9314 - val_loss: 0.3199\n",
      "Epoch 161/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8400 - loss: 0.4940 - val_accuracy: 0.9343 - val_loss: 0.3173\n",
      "Epoch 162/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.4840 - val_accuracy: 0.9457 - val_loss: 0.3135\n",
      "Epoch 163/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8331 - loss: 0.4854 - val_accuracy: 0.9314 - val_loss: 0.3186\n",
      "Epoch 164/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8346 - loss: 0.4992 - val_accuracy: 0.9314 - val_loss: 0.3204\n",
      "Epoch 165/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8292 - loss: 0.4992 - val_accuracy: 0.9171 - val_loss: 0.3228\n",
      "Epoch 166/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8338 - loss: 0.4895 - val_accuracy: 0.9229 - val_loss: 0.3181\n",
      "Epoch 167/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8323 - loss: 0.4986 - val_accuracy: 0.9457 - val_loss: 0.3172\n",
      "Epoch 168/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8400 - loss: 0.4861 - val_accuracy: 0.9457 - val_loss: 0.3170\n",
      "Epoch 169/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8400 - loss: 0.4969 - val_accuracy: 0.9257 - val_loss: 0.3170\n",
      "Epoch 170/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8338 - loss: 0.4983 - val_accuracy: 0.9400 - val_loss: 0.3199\n",
      "Epoch 171/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8331 - loss: 0.4860 - val_accuracy: 0.9171 - val_loss: 0.3204\n",
      "Epoch 172/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8377 - loss: 0.4955 - val_accuracy: 0.9371 - val_loss: 0.3172\n",
      "Epoch 173/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4773 - val_accuracy: 0.9314 - val_loss: 0.3160\n",
      "Epoch 174/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8262 - loss: 0.5006 - val_accuracy: 0.9114 - val_loss: 0.3221\n",
      "Epoch 175/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8392 - loss: 0.4866 - val_accuracy: 0.9200 - val_loss: 0.3202\n",
      "Epoch 176/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8315 - loss: 0.5032 - val_accuracy: 0.9314 - val_loss: 0.3180\n",
      "Epoch 177/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4863 - val_accuracy: 0.9229 - val_loss: 0.3194\n",
      "Epoch 178/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8308 - loss: 0.4895 - val_accuracy: 0.9457 - val_loss: 0.3142\n",
      "Epoch 179/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8323 - loss: 0.4887 - val_accuracy: 0.9200 - val_loss: 0.3158\n",
      "Epoch 180/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8308 - loss: 0.4940 - val_accuracy: 0.9343 - val_loss: 0.3175\n",
      "Epoch 181/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.4742 - val_accuracy: 0.9257 - val_loss: 0.3169\n",
      "Epoch 182/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4737 - val_accuracy: 0.9257 - val_loss: 0.3119\n",
      "Epoch 183/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4727 - val_accuracy: 0.9229 - val_loss: 0.3159\n",
      "Epoch 184/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8377 - loss: 0.4884 - val_accuracy: 0.9257 - val_loss: 0.3117\n",
      "Epoch 185/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8208 - loss: 0.5017 - val_accuracy: 0.9314 - val_loss: 0.3113\n",
      "Epoch 186/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8346 - loss: 0.4792 - val_accuracy: 0.9229 - val_loss: 0.3152\n",
      "Epoch 187/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.4841 - val_accuracy: 0.9257 - val_loss: 0.3103\n",
      "Epoch 188/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8315 - loss: 0.4912 - val_accuracy: 0.9257 - val_loss: 0.3141\n",
      "Epoch 189/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8377 - loss: 0.4768 - val_accuracy: 0.9229 - val_loss: 0.3165\n",
      "Epoch 190/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.4872 - val_accuracy: 0.9314 - val_loss: 0.3164\n",
      "Epoch 191/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8285 - loss: 0.4828 - val_accuracy: 0.9371 - val_loss: 0.3127\n",
      "Epoch 192/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4730 - val_accuracy: 0.9314 - val_loss: 0.3062\n",
      "Epoch 193/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.4769 - val_accuracy: 0.9171 - val_loss: 0.3121\n",
      "Epoch 194/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8285 - loss: 0.4804 - val_accuracy: 0.9400 - val_loss: 0.3058\n",
      "Epoch 195/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8354 - loss: 0.4753 - val_accuracy: 0.9371 - val_loss: 0.3078\n",
      "Epoch 196/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8285 - loss: 0.4840 - val_accuracy: 0.9286 - val_loss: 0.3062\n",
      "Epoch 197/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8362 - loss: 0.4767 - val_accuracy: 0.9314 - val_loss: 0.3072\n",
      "Epoch 198/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8269 - loss: 0.4875 - val_accuracy: 0.9229 - val_loss: 0.3150\n",
      "Epoch 199/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8369 - loss: 0.4838 - val_accuracy: 0.9314 - val_loss: 0.3133\n",
      "Epoch 200/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.4895 - val_accuracy: 0.9343 - val_loss: 0.3067\n",
      "Epoch 201/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8215 - loss: 0.5014 - val_accuracy: 0.9314 - val_loss: 0.3085\n",
      "Epoch 202/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8515 - loss: 0.4687 - val_accuracy: 0.9286 - val_loss: 0.3093\n",
      "Epoch 203/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8354 - loss: 0.4814 - val_accuracy: 0.9343 - val_loss: 0.3054\n",
      "Epoch 204/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.4691 - val_accuracy: 0.9429 - val_loss: 0.3027\n",
      "Epoch 205/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8262 - loss: 0.4966 - val_accuracy: 0.9429 - val_loss: 0.3049\n",
      "Epoch 206/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8377 - loss: 0.4804 - val_accuracy: 0.9229 - val_loss: 0.3098\n",
      "Epoch 207/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4735 - val_accuracy: 0.9171 - val_loss: 0.3081\n",
      "Epoch 208/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.4760 - val_accuracy: 0.9200 - val_loss: 0.3114\n",
      "Epoch 209/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4709 - val_accuracy: 0.9171 - val_loss: 0.3103\n",
      "Epoch 210/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8346 - loss: 0.4861 - val_accuracy: 0.9171 - val_loss: 0.3116\n",
      "Epoch 211/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8492 - loss: 0.4694 - val_accuracy: 0.9257 - val_loss: 0.3048\n",
      "Epoch 212/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8338 - loss: 0.4734 - val_accuracy: 0.9229 - val_loss: 0.3022\n",
      "Epoch 213/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8277 - loss: 0.4764 - val_accuracy: 0.9371 - val_loss: 0.3006\n",
      "Epoch 214/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8369 - loss: 0.4760 - val_accuracy: 0.9343 - val_loss: 0.3042\n",
      "Epoch 215/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.4691 - val_accuracy: 0.9171 - val_loss: 0.3079\n",
      "Epoch 216/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.4786 - val_accuracy: 0.9371 - val_loss: 0.3045\n",
      "Epoch 217/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8369 - loss: 0.4805 - val_accuracy: 0.9229 - val_loss: 0.3038\n",
      "Epoch 218/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8300 - loss: 0.4818 - val_accuracy: 0.9257 - val_loss: 0.3058\n",
      "Epoch 219/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8362 - loss: 0.4761 - val_accuracy: 0.9286 - val_loss: 0.3025\n",
      "Epoch 220/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8238 - loss: 0.4799 - val_accuracy: 0.9171 - val_loss: 0.3044\n",
      "Epoch 221/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.4653 - val_accuracy: 0.9286 - val_loss: 0.3038\n",
      "Epoch 222/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8338 - loss: 0.4783 - val_accuracy: 0.9286 - val_loss: 0.3013\n",
      "Epoch 223/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8400 - loss: 0.4690 - val_accuracy: 0.9171 - val_loss: 0.3028\n",
      "Epoch 224/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4641 - val_accuracy: 0.9229 - val_loss: 0.3088\n",
      "Epoch 225/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8323 - loss: 0.4855 - val_accuracy: 0.9286 - val_loss: 0.3018\n",
      "Epoch 226/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8369 - loss: 0.4672 - val_accuracy: 0.9286 - val_loss: 0.3029\n",
      "Epoch 227/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8292 - loss: 0.4787 - val_accuracy: 0.9314 - val_loss: 0.3033\n",
      "Epoch 228/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8362 - loss: 0.4689 - val_accuracy: 0.9257 - val_loss: 0.3024\n",
      "Epoch 229/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.4728 - val_accuracy: 0.9143 - val_loss: 0.3053\n",
      "Epoch 230/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8300 - loss: 0.4768 - val_accuracy: 0.9343 - val_loss: 0.3006\n",
      "Epoch 231/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8385 - loss: 0.4725 - val_accuracy: 0.9286 - val_loss: 0.3006\n",
      "Epoch 232/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8369 - loss: 0.4814 - val_accuracy: 0.9286 - val_loss: 0.3005\n",
      "Epoch 233/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8331 - loss: 0.4631 - val_accuracy: 0.9314 - val_loss: 0.2985\n",
      "Epoch 234/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.4713 - val_accuracy: 0.9371 - val_loss: 0.2972\n",
      "Epoch 235/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8323 - loss: 0.4741 - val_accuracy: 0.9229 - val_loss: 0.3020\n",
      "Epoch 236/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.4589 - val_accuracy: 0.9229 - val_loss: 0.3078\n",
      "Epoch 237/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8385 - loss: 0.4827 - val_accuracy: 0.9314 - val_loss: 0.2991\n",
      "Epoch 238/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8323 - loss: 0.4737 - val_accuracy: 0.9343 - val_loss: 0.2975\n",
      "Epoch 239/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.4671 - val_accuracy: 0.9257 - val_loss: 0.2993\n",
      "Epoch 240/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8362 - loss: 0.4686 - val_accuracy: 0.9286 - val_loss: 0.3002\n",
      "Epoch 241/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8531 - loss: 0.4583 - val_accuracy: 0.9400 - val_loss: 0.2983\n",
      "Epoch 242/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8346 - loss: 0.4790 - val_accuracy: 0.9457 - val_loss: 0.2944\n",
      "Epoch 243/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8362 - loss: 0.4676 - val_accuracy: 0.9286 - val_loss: 0.2983\n",
      "Epoch 244/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8377 - loss: 0.4577 - val_accuracy: 0.9371 - val_loss: 0.2914\n",
      "Epoch 245/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8369 - loss: 0.4761 - val_accuracy: 0.9343 - val_loss: 0.2967\n",
      "Epoch 246/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4643 - val_accuracy: 0.9429 - val_loss: 0.2938\n",
      "Epoch 247/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8323 - loss: 0.4858 - val_accuracy: 0.9400 - val_loss: 0.2954\n",
      "Epoch 248/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8292 - loss: 0.4773 - val_accuracy: 0.9371 - val_loss: 0.3003\n",
      "Epoch 249/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8238 - loss: 0.4782 - val_accuracy: 0.9371 - val_loss: 0.2941\n",
      "Epoch 250/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4791 - val_accuracy: 0.9371 - val_loss: 0.2959\n",
      "Epoch 251/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8300 - loss: 0.4778 - val_accuracy: 0.9429 - val_loss: 0.2986\n",
      "Epoch 252/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.4829 - val_accuracy: 0.9371 - val_loss: 0.2998\n",
      "Epoch 253/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8377 - loss: 0.4657 - val_accuracy: 0.9486 - val_loss: 0.2972\n",
      "Epoch 254/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.4618 - val_accuracy: 0.9171 - val_loss: 0.3051\n",
      "Epoch 255/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8331 - loss: 0.4704 - val_accuracy: 0.9543 - val_loss: 0.2915\n",
      "Epoch 256/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8377 - loss: 0.4696 - val_accuracy: 0.9257 - val_loss: 0.3000\n",
      "Epoch 257/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.4664 - val_accuracy: 0.9343 - val_loss: 0.2955\n",
      "Epoch 258/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.4509 - val_accuracy: 0.9371 - val_loss: 0.2882\n",
      "Epoch 259/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8400 - loss: 0.4606 - val_accuracy: 0.9200 - val_loss: 0.2980\n",
      "Epoch 260/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8354 - loss: 0.4681 - val_accuracy: 0.9229 - val_loss: 0.2978\n",
      "Epoch 261/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8400 - loss: 0.4715 - val_accuracy: 0.9314 - val_loss: 0.2943\n",
      "Epoch 262/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.4618 - val_accuracy: 0.9229 - val_loss: 0.2967\n",
      "Epoch 263/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8400 - loss: 0.4632 - val_accuracy: 0.9229 - val_loss: 0.2930\n",
      "Epoch 264/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8323 - loss: 0.4587 - val_accuracy: 0.9143 - val_loss: 0.2983\n",
      "Epoch 265/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.4661 - val_accuracy: 0.9314 - val_loss: 0.2931\n",
      "Epoch 266/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8369 - loss: 0.4730 - val_accuracy: 0.9286 - val_loss: 0.2928\n",
      "Epoch 267/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4641 - val_accuracy: 0.9400 - val_loss: 0.2913\n",
      "Epoch 268/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8377 - loss: 0.4760 - val_accuracy: 0.9171 - val_loss: 0.2958\n",
      "Epoch 269/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8400 - loss: 0.4638 - val_accuracy: 0.9429 - val_loss: 0.2918\n",
      "Epoch 270/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8369 - loss: 0.4630 - val_accuracy: 0.9286 - val_loss: 0.2941\n",
      "Epoch 271/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4632 - val_accuracy: 0.9371 - val_loss: 0.2922\n",
      "Epoch 272/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.4610 - val_accuracy: 0.9400 - val_loss: 0.2884\n",
      "Epoch 273/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8400 - loss: 0.4570 - val_accuracy: 0.9486 - val_loss: 0.2880\n",
      "Epoch 274/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8346 - loss: 0.4680 - val_accuracy: 0.9371 - val_loss: 0.2898\n",
      "Epoch 275/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8369 - loss: 0.4607 - val_accuracy: 0.9229 - val_loss: 0.2975\n",
      "Epoch 276/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8400 - loss: 0.4620 - val_accuracy: 0.9343 - val_loss: 0.2926\n",
      "Epoch 277/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8392 - loss: 0.4654 - val_accuracy: 0.9314 - val_loss: 0.2925\n",
      "Epoch 278/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8315 - loss: 0.4699 - val_accuracy: 0.9314 - val_loss: 0.2938\n",
      "Epoch 279/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8315 - loss: 0.4687 - val_accuracy: 0.9314 - val_loss: 0.2942\n",
      "Epoch 280/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8354 - loss: 0.4796 - val_accuracy: 0.9286 - val_loss: 0.2958\n",
      "Epoch 281/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8338 - loss: 0.4667 - val_accuracy: 0.9229 - val_loss: 0.2987\n",
      "Epoch 282/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.4637 - val_accuracy: 0.9286 - val_loss: 0.2937\n",
      "Epoch 283/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8400 - loss: 0.4620 - val_accuracy: 0.9343 - val_loss: 0.2923\n",
      "Epoch 284/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8292 - loss: 0.4696 - val_accuracy: 0.9229 - val_loss: 0.2967\n",
      "Epoch 285/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4677 - val_accuracy: 0.9114 - val_loss: 0.3027\n",
      "Epoch 286/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8485 - loss: 0.4624 - val_accuracy: 0.9229 - val_loss: 0.2958\n",
      "Epoch 287/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8285 - loss: 0.4715 - val_accuracy: 0.9429 - val_loss: 0.2909\n",
      "Epoch 288/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4667 - val_accuracy: 0.9371 - val_loss: 0.2959\n",
      "Epoch 289/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.4580 - val_accuracy: 0.9400 - val_loss: 0.2939\n",
      "Epoch 290/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.4523 - val_accuracy: 0.9343 - val_loss: 0.2913\n",
      "Epoch 291/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.4540 - val_accuracy: 0.9457 - val_loss: 0.2873\n",
      "Epoch 292/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.4566 - val_accuracy: 0.9229 - val_loss: 0.2911\n",
      "Epoch 293/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8362 - loss: 0.4731 - val_accuracy: 0.9314 - val_loss: 0.2919\n",
      "Epoch 294/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8492 - loss: 0.4550 - val_accuracy: 0.9286 - val_loss: 0.2928\n",
      "Epoch 295/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8323 - loss: 0.4653 - val_accuracy: 0.9343 - val_loss: 0.2907\n",
      "Epoch 296/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4551 - val_accuracy: 0.9314 - val_loss: 0.2910\n",
      "Epoch 297/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.4670 - val_accuracy: 0.9400 - val_loss: 0.2881\n",
      "Epoch 298/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8269 - loss: 0.4740 - val_accuracy: 0.9314 - val_loss: 0.2903\n",
      "Epoch 299/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8362 - loss: 0.4622 - val_accuracy: 0.9229 - val_loss: 0.2970\n",
      "Epoch 300/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.4669 - val_accuracy: 0.9343 - val_loss: 0.2906\n",
      "Epoch 301/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.4543 - val_accuracy: 0.9257 - val_loss: 0.2883\n",
      "Epoch 302/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8362 - loss: 0.4566 - val_accuracy: 0.9229 - val_loss: 0.2896\n",
      "Epoch 303/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8515 - loss: 0.4512 - val_accuracy: 0.9371 - val_loss: 0.2886\n",
      "Epoch 304/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.4588 - val_accuracy: 0.9314 - val_loss: 0.2931\n",
      "Epoch 305/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8315 - loss: 0.4548 - val_accuracy: 0.9286 - val_loss: 0.2915\n",
      "Epoch 306/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8400 - loss: 0.4633 - val_accuracy: 0.9171 - val_loss: 0.2951\n",
      "Epoch 307/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.4596 - val_accuracy: 0.9257 - val_loss: 0.2913\n",
      "Epoch 308/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8385 - loss: 0.4543 - val_accuracy: 0.9343 - val_loss: 0.2884\n",
      "Epoch 309/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8231 - loss: 0.4678 - val_accuracy: 0.9400 - val_loss: 0.2875\n",
      "Epoch 310/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8338 - loss: 0.4521 - val_accuracy: 0.9400 - val_loss: 0.2866\n",
      "Epoch 311/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8377 - loss: 0.4484 - val_accuracy: 0.9200 - val_loss: 0.2916\n",
      "Epoch 312/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.4478 - val_accuracy: 0.9286 - val_loss: 0.2868\n",
      "Epoch 313/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8400 - loss: 0.4567 - val_accuracy: 0.9200 - val_loss: 0.2962\n",
      "Epoch 314/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4667 - val_accuracy: 0.9229 - val_loss: 0.2897\n",
      "Epoch 315/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4618 - val_accuracy: 0.9343 - val_loss: 0.2941\n",
      "Epoch 316/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.4535 - val_accuracy: 0.9314 - val_loss: 0.2917\n",
      "Epoch 317/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8369 - loss: 0.4666 - val_accuracy: 0.9286 - val_loss: 0.2895\n",
      "Epoch 318/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4462 - val_accuracy: 0.9171 - val_loss: 0.2918\n",
      "Epoch 319/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.4498 - val_accuracy: 0.9286 - val_loss: 0.2878\n",
      "Epoch 320/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.4531 - val_accuracy: 0.9371 - val_loss: 0.2830\n",
      "Epoch 321/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8362 - loss: 0.4544 - val_accuracy: 0.9143 - val_loss: 0.2928\n",
      "Epoch 322/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8362 - loss: 0.4718 - val_accuracy: 0.9286 - val_loss: 0.2864\n",
      "Epoch 323/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8354 - loss: 0.4597 - val_accuracy: 0.9171 - val_loss: 0.2975\n",
      "Epoch 324/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8331 - loss: 0.4609 - val_accuracy: 0.9343 - val_loss: 0.2882\n",
      "Epoch 325/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8354 - loss: 0.4586 - val_accuracy: 0.9229 - val_loss: 0.2889\n",
      "Epoch 326/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8362 - loss: 0.4535 - val_accuracy: 0.9143 - val_loss: 0.2950\n",
      "Epoch 327/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4528 - val_accuracy: 0.9429 - val_loss: 0.2819\n",
      "Epoch 328/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8508 - loss: 0.4420 - val_accuracy: 0.9314 - val_loss: 0.2841\n",
      "Epoch 329/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8385 - loss: 0.4529 - val_accuracy: 0.9171 - val_loss: 0.2914\n",
      "Epoch 330/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8362 - loss: 0.4583 - val_accuracy: 0.9286 - val_loss: 0.2885\n",
      "Epoch 331/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8400 - loss: 0.4585 - val_accuracy: 0.9343 - val_loss: 0.2817\n",
      "Epoch 332/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8400 - loss: 0.4528 - val_accuracy: 0.9257 - val_loss: 0.2889\n",
      "Epoch 333/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4567 - val_accuracy: 0.9257 - val_loss: 0.2881\n",
      "Epoch 334/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8369 - loss: 0.4492 - val_accuracy: 0.9343 - val_loss: 0.2837\n",
      "Epoch 335/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8385 - loss: 0.4579 - val_accuracy: 0.9314 - val_loss: 0.2835\n",
      "Epoch 336/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.4507 - val_accuracy: 0.9143 - val_loss: 0.2885\n",
      "Epoch 337/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.4485 - val_accuracy: 0.9286 - val_loss: 0.2877\n",
      "Epoch 338/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8485 - loss: 0.4437 - val_accuracy: 0.9371 - val_loss: 0.2780\n",
      "Epoch 339/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8338 - loss: 0.4587 - val_accuracy: 0.9457 - val_loss: 0.2798\n",
      "Epoch 340/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8308 - loss: 0.4644 - val_accuracy: 0.9229 - val_loss: 0.2866\n",
      "Epoch 341/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8562 - loss: 0.4500 - val_accuracy: 0.9257 - val_loss: 0.2859\n",
      "Epoch 342/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8346 - loss: 0.4568 - val_accuracy: 0.9286 - val_loss: 0.2866\n",
      "Epoch 343/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8400 - loss: 0.4606 - val_accuracy: 0.9400 - val_loss: 0.2852\n",
      "Epoch 344/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8346 - loss: 0.4634 - val_accuracy: 0.9400 - val_loss: 0.2810\n",
      "Epoch 345/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.4554 - val_accuracy: 0.9429 - val_loss: 0.2807\n",
      "Epoch 346/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8369 - loss: 0.4647 - val_accuracy: 0.9286 - val_loss: 0.2902\n",
      "Epoch 347/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8400 - loss: 0.4483 - val_accuracy: 0.9314 - val_loss: 0.2825\n",
      "Epoch 348/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8238 - loss: 0.4669 - val_accuracy: 0.9371 - val_loss: 0.2807\n",
      "Epoch 349/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8400 - loss: 0.4459 - val_accuracy: 0.9343 - val_loss: 0.2820\n",
      "Epoch 350/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4497 - val_accuracy: 0.9314 - val_loss: 0.2863\n",
      "Epoch 351/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8346 - loss: 0.4722 - val_accuracy: 0.9514 - val_loss: 0.2803\n",
      "Epoch 352/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8338 - loss: 0.4464 - val_accuracy: 0.9371 - val_loss: 0.2821\n",
      "Epoch 353/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.4595 - val_accuracy: 0.9371 - val_loss: 0.2827\n",
      "Epoch 354/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8385 - loss: 0.4530 - val_accuracy: 0.9286 - val_loss: 0.2860\n",
      "Epoch 355/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8269 - loss: 0.4600 - val_accuracy: 0.9143 - val_loss: 0.2902\n",
      "Epoch 356/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.4424 - val_accuracy: 0.9314 - val_loss: 0.2814\n",
      "Epoch 357/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8385 - loss: 0.4602 - val_accuracy: 0.9257 - val_loss: 0.2834\n",
      "Epoch 358/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8331 - loss: 0.4557 - val_accuracy: 0.9229 - val_loss: 0.2900\n",
      "Epoch 359/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8338 - loss: 0.4644 - val_accuracy: 0.9543 - val_loss: 0.2797\n",
      "Epoch 360/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4586 - val_accuracy: 0.9457 - val_loss: 0.2836\n",
      "Epoch 361/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8369 - loss: 0.4621 - val_accuracy: 0.9286 - val_loss: 0.2884\n",
      "Epoch 362/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8400 - loss: 0.4613 - val_accuracy: 0.9200 - val_loss: 0.2946\n",
      "Epoch 363/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.4421 - val_accuracy: 0.9343 - val_loss: 0.2839\n",
      "Epoch 364/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8546 - loss: 0.4383 - val_accuracy: 0.9257 - val_loss: 0.2865\n",
      "Epoch 365/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8400 - loss: 0.4563 - val_accuracy: 0.9314 - val_loss: 0.2825\n",
      "Epoch 366/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8346 - loss: 0.4643 - val_accuracy: 0.9200 - val_loss: 0.2945\n",
      "Epoch 367/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8362 - loss: 0.4543 - val_accuracy: 0.9286 - val_loss: 0.2867\n",
      "Epoch 368/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8323 - loss: 0.4541 - val_accuracy: 0.9343 - val_loss: 0.2848\n",
      "Epoch 369/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8354 - loss: 0.4579 - val_accuracy: 0.9400 - val_loss: 0.2818\n",
      "Epoch 370/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8377 - loss: 0.4504 - val_accuracy: 0.9371 - val_loss: 0.2825\n",
      "Epoch 371/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8377 - loss: 0.4520 - val_accuracy: 0.9314 - val_loss: 0.2872\n",
      "Epoch 372/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.4519 - val_accuracy: 0.9343 - val_loss: 0.2859\n",
      "Epoch 373/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.4447 - val_accuracy: 0.9343 - val_loss: 0.2832\n",
      "Epoch 374/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8400 - loss: 0.4515 - val_accuracy: 0.9457 - val_loss: 0.2746\n",
      "Epoch 375/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.4449 - val_accuracy: 0.9400 - val_loss: 0.2809\n",
      "Epoch 376/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4534 - val_accuracy: 0.9229 - val_loss: 0.2898\n",
      "Epoch 377/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8338 - loss: 0.4443 - val_accuracy: 0.9229 - val_loss: 0.2914\n",
      "Epoch 378/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8362 - loss: 0.4580 - val_accuracy: 0.9286 - val_loss: 0.2877\n",
      "Epoch 379/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8338 - loss: 0.4569 - val_accuracy: 0.9371 - val_loss: 0.2871\n",
      "Epoch 380/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.4626 - val_accuracy: 0.9371 - val_loss: 0.2844\n",
      "Epoch 381/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8408 - loss: 0.4514 - val_accuracy: 0.9371 - val_loss: 0.2824\n",
      "Epoch 382/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8400 - loss: 0.4571 - val_accuracy: 0.9200 - val_loss: 0.2920\n",
      "Epoch 383/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8369 - loss: 0.4613 - val_accuracy: 0.9343 - val_loss: 0.2830\n",
      "Epoch 384/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8385 - loss: 0.4576 - val_accuracy: 0.9286 - val_loss: 0.2882\n",
      "Epoch 385/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8400 - loss: 0.4432 - val_accuracy: 0.9286 - val_loss: 0.2859\n",
      "Epoch 386/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.4523 - val_accuracy: 0.9171 - val_loss: 0.2888\n",
      "Epoch 387/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8362 - loss: 0.4621 - val_accuracy: 0.9200 - val_loss: 0.2909\n",
      "Epoch 388/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.4559 - val_accuracy: 0.9171 - val_loss: 0.2947\n",
      "Epoch 389/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.4478 - val_accuracy: 0.9200 - val_loss: 0.2901\n",
      "Epoch 390/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8400 - loss: 0.4492 - val_accuracy: 0.9171 - val_loss: 0.2936\n",
      "Epoch 391/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.4496 - val_accuracy: 0.9343 - val_loss: 0.2838\n",
      "Epoch 392/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8515 - loss: 0.4467 - val_accuracy: 0.9114 - val_loss: 0.2932\n",
      "Epoch 393/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8400 - loss: 0.4494 - val_accuracy: 0.9229 - val_loss: 0.2887\n",
      "Epoch 394/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8369 - loss: 0.4542 - val_accuracy: 0.9343 - val_loss: 0.2880\n",
      "Epoch 395/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8377 - loss: 0.4512 - val_accuracy: 0.9314 - val_loss: 0.2840\n",
      "Epoch 396/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8369 - loss: 0.4500 - val_accuracy: 0.9429 - val_loss: 0.2833\n",
      "Epoch 397/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4389 - val_accuracy: 0.9286 - val_loss: 0.2868\n",
      "Epoch 398/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8362 - loss: 0.4482 - val_accuracy: 0.9371 - val_loss: 0.2819\n",
      "Epoch 399/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.4448 - val_accuracy: 0.9314 - val_loss: 0.2825\n",
      "Epoch 400/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8338 - loss: 0.4426 - val_accuracy: 0.9257 - val_loss: 0.2830\n",
      "Epoch 401/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8362 - loss: 0.4483 - val_accuracy: 0.9486 - val_loss: 0.2744\n",
      "Epoch 402/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.4534 - val_accuracy: 0.9257 - val_loss: 0.2856\n",
      "Epoch 403/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8285 - loss: 0.4678 - val_accuracy: 0.9200 - val_loss: 0.2883\n",
      "Epoch 404/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8346 - loss: 0.4673 - val_accuracy: 0.9257 - val_loss: 0.2881\n",
      "Epoch 405/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.4426 - val_accuracy: 0.9229 - val_loss: 0.2888\n",
      "Epoch 406/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8500 - loss: 0.4332 - val_accuracy: 0.9371 - val_loss: 0.2829\n",
      "Epoch 407/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8346 - loss: 0.4555 - val_accuracy: 0.9343 - val_loss: 0.2797\n",
      "Epoch 408/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8308 - loss: 0.4522 - val_accuracy: 0.9343 - val_loss: 0.2851\n",
      "Epoch 409/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8400 - loss: 0.4530 - val_accuracy: 0.9486 - val_loss: 0.2805\n",
      "Epoch 410/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8338 - loss: 0.4571 - val_accuracy: 0.9200 - val_loss: 0.2906\n",
      "Epoch 411/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.4439 - val_accuracy: 0.9257 - val_loss: 0.2874\n",
      "Epoch 412/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.4417 - val_accuracy: 0.9286 - val_loss: 0.2846\n",
      "Epoch 413/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8408 - loss: 0.4500 - val_accuracy: 0.9257 - val_loss: 0.2823\n",
      "Epoch 414/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8400 - loss: 0.4439 - val_accuracy: 0.9457 - val_loss: 0.2776\n",
      "Epoch 415/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.4438 - val_accuracy: 0.9114 - val_loss: 0.2958\n",
      "Epoch 416/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.4431 - val_accuracy: 0.9200 - val_loss: 0.2865\n",
      "Epoch 417/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8369 - loss: 0.4565 - val_accuracy: 0.9343 - val_loss: 0.2802\n",
      "Epoch 418/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.4392 - val_accuracy: 0.9286 - val_loss: 0.2826\n",
      "Epoch 419/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8385 - loss: 0.4502 - val_accuracy: 0.9429 - val_loss: 0.2825\n",
      "Epoch 420/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8523 - loss: 0.4279 - val_accuracy: 0.9371 - val_loss: 0.2818\n",
      "Epoch 421/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8300 - loss: 0.4532 - val_accuracy: 0.9200 - val_loss: 0.2961\n",
      "Epoch 422/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.4502 - val_accuracy: 0.9314 - val_loss: 0.2871\n",
      "Epoch 423/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.4525 - val_accuracy: 0.9400 - val_loss: 0.2821\n",
      "Epoch 424/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.4517 - val_accuracy: 0.9371 - val_loss: 0.2819\n",
      "Epoch 425/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8400 - loss: 0.4553 - val_accuracy: 0.9400 - val_loss: 0.2810\n",
      "Epoch 426/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8400 - loss: 0.4601 - val_accuracy: 0.9371 - val_loss: 0.2858\n",
      "Epoch 427/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8400 - loss: 0.4324 - val_accuracy: 0.9371 - val_loss: 0.2834\n",
      "Epoch 428/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8400 - loss: 0.4317 - val_accuracy: 0.9371 - val_loss: 0.2755\n",
      "Epoch 429/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.4449 - val_accuracy: 0.9171 - val_loss: 0.2836\n",
      "Epoch 430/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8500 - loss: 0.4573 - val_accuracy: 0.9400 - val_loss: 0.2798\n",
      "Epoch 431/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.4456 - val_accuracy: 0.9429 - val_loss: 0.2759\n",
      "Epoch 432/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8331 - loss: 0.4450 - val_accuracy: 0.9343 - val_loss: 0.2800\n",
      "Epoch 433/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.4402 - val_accuracy: 0.9400 - val_loss: 0.2805\n",
      "Epoch 434/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8269 - loss: 0.4575 - val_accuracy: 0.9171 - val_loss: 0.2916\n",
      "Epoch 435/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8331 - loss: 0.4587 - val_accuracy: 0.9400 - val_loss: 0.2836\n",
      "Epoch 436/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8362 - loss: 0.4539 - val_accuracy: 0.9257 - val_loss: 0.2917\n",
      "Epoch 437/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.4476 - val_accuracy: 0.9314 - val_loss: 0.2865\n",
      "Epoch 438/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8331 - loss: 0.4624 - val_accuracy: 0.9343 - val_loss: 0.2823\n",
      "Epoch 439/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8385 - loss: 0.4464 - val_accuracy: 0.9314 - val_loss: 0.2878\n",
      "Epoch 440/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4468 - val_accuracy: 0.9086 - val_loss: 0.2979\n",
      "Epoch 441/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8323 - loss: 0.4527 - val_accuracy: 0.9286 - val_loss: 0.2900\n",
      "Epoch 442/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8354 - loss: 0.4577 - val_accuracy: 0.9429 - val_loss: 0.2808\n",
      "Epoch 443/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8362 - loss: 0.4455 - val_accuracy: 0.9314 - val_loss: 0.2874\n",
      "Epoch 444/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.4404 - val_accuracy: 0.9400 - val_loss: 0.2844\n",
      "Epoch 445/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8292 - loss: 0.4551 - val_accuracy: 0.9286 - val_loss: 0.2887\n",
      "Epoch 446/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8338 - loss: 0.4503 - val_accuracy: 0.9257 - val_loss: 0.2888\n",
      "Epoch 447/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8315 - loss: 0.4482 - val_accuracy: 0.9257 - val_loss: 0.2878\n",
      "Epoch 448/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.4427 - val_accuracy: 0.9400 - val_loss: 0.2802\n",
      "Epoch 449/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8500 - loss: 0.4376 - val_accuracy: 0.9114 - val_loss: 0.2917\n",
      "Epoch 450/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8354 - loss: 0.4589 - val_accuracy: 0.9229 - val_loss: 0.2901\n",
      "Epoch 451/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8354 - loss: 0.4442 - val_accuracy: 0.9257 - val_loss: 0.2867\n",
      "Epoch 452/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.4446 - val_accuracy: 0.9314 - val_loss: 0.2845\n",
      "Epoch 453/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.4583 - val_accuracy: 0.9229 - val_loss: 0.2859\n",
      "Epoch 454/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4521 - val_accuracy: 0.9343 - val_loss: 0.2816\n",
      "Epoch 455/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8400 - loss: 0.4440 - val_accuracy: 0.9314 - val_loss: 0.2879\n",
      "Epoch 456/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8308 - loss: 0.4469 - val_accuracy: 0.9400 - val_loss: 0.2822\n",
      "Epoch 457/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.4559 - val_accuracy: 0.9371 - val_loss: 0.2842\n",
      "Epoch 458/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.4554 - val_accuracy: 0.9314 - val_loss: 0.2839\n",
      "Epoch 459/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.4380 - val_accuracy: 0.9543 - val_loss: 0.2777\n",
      "Epoch 460/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8354 - loss: 0.4514 - val_accuracy: 0.9343 - val_loss: 0.2783\n",
      "Epoch 461/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8508 - loss: 0.4331 - val_accuracy: 0.9514 - val_loss: 0.2747\n",
      "Epoch 462/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8369 - loss: 0.4407 - val_accuracy: 0.9286 - val_loss: 0.2831\n",
      "Epoch 463/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.4447 - val_accuracy: 0.9457 - val_loss: 0.2798\n",
      "Epoch 464/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8508 - loss: 0.4434 - val_accuracy: 0.9171 - val_loss: 0.2851\n",
      "Epoch 465/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8331 - loss: 0.4505 - val_accuracy: 0.9400 - val_loss: 0.2762\n",
      "Epoch 466/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.4407 - val_accuracy: 0.9200 - val_loss: 0.2872\n",
      "Epoch 467/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8369 - loss: 0.4437 - val_accuracy: 0.9371 - val_loss: 0.2781\n",
      "Epoch 468/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8508 - loss: 0.4367 - val_accuracy: 0.9343 - val_loss: 0.2779\n",
      "Epoch 469/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8400 - loss: 0.4535 - val_accuracy: 0.9371 - val_loss: 0.2812\n",
      "Epoch 470/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.4472 - val_accuracy: 0.9200 - val_loss: 0.2838\n",
      "Epoch 471/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8492 - loss: 0.4343 - val_accuracy: 0.9371 - val_loss: 0.2812\n",
      "Epoch 472/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8338 - loss: 0.4464 - val_accuracy: 0.9457 - val_loss: 0.2775\n",
      "Epoch 473/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.4433 - val_accuracy: 0.9571 - val_loss: 0.2778\n",
      "Epoch 474/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8369 - loss: 0.4440 - val_accuracy: 0.9486 - val_loss: 0.2868\n",
      "Epoch 475/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4400 - val_accuracy: 0.9457 - val_loss: 0.2816\n",
      "Epoch 476/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4398 - val_accuracy: 0.9400 - val_loss: 0.2773\n",
      "Epoch 477/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4411 - val_accuracy: 0.9200 - val_loss: 0.2858\n",
      "Epoch 478/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8385 - loss: 0.4486 - val_accuracy: 0.9371 - val_loss: 0.2817\n",
      "Epoch 479/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4453 - val_accuracy: 0.9371 - val_loss: 0.2777\n",
      "Epoch 480/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8323 - loss: 0.4399 - val_accuracy: 0.9286 - val_loss: 0.2859\n",
      "Epoch 481/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.4391 - val_accuracy: 0.9543 - val_loss: 0.2749\n",
      "Epoch 482/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8285 - loss: 0.4561 - val_accuracy: 0.9543 - val_loss: 0.2771\n",
      "Epoch 483/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8385 - loss: 0.4460 - val_accuracy: 0.9371 - val_loss: 0.2810\n",
      "Epoch 484/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4432 - val_accuracy: 0.9343 - val_loss: 0.2832\n",
      "Epoch 485/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4445 - val_accuracy: 0.9314 - val_loss: 0.2775\n",
      "Epoch 486/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.4437 - val_accuracy: 0.9257 - val_loss: 0.2843\n",
      "Epoch 487/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8369 - loss: 0.4397 - val_accuracy: 0.9400 - val_loss: 0.2792\n",
      "Epoch 488/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8338 - loss: 0.4494 - val_accuracy: 0.9286 - val_loss: 0.2820\n",
      "Epoch 489/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8369 - loss: 0.4526 - val_accuracy: 0.9371 - val_loss: 0.2805\n",
      "Epoch 490/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8385 - loss: 0.4403 - val_accuracy: 0.9343 - val_loss: 0.2735\n",
      "Epoch 491/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8554 - loss: 0.4332 - val_accuracy: 0.9429 - val_loss: 0.2780\n",
      "Epoch 492/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.4377 - val_accuracy: 0.9457 - val_loss: 0.2763\n",
      "Epoch 493/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8385 - loss: 0.4427 - val_accuracy: 0.9286 - val_loss: 0.2796\n",
      "Epoch 494/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8323 - loss: 0.4446 - val_accuracy: 0.9343 - val_loss: 0.2833\n",
      "Epoch 495/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4512 - val_accuracy: 0.9486 - val_loss: 0.2740\n",
      "Epoch 496/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4519 - val_accuracy: 0.9371 - val_loss: 0.2809\n",
      "Epoch 497/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8354 - loss: 0.4437 - val_accuracy: 0.9371 - val_loss: 0.2844\n",
      "Epoch 498/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.4464 - val_accuracy: 0.9314 - val_loss: 0.2831\n",
      "Epoch 499/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4392 - val_accuracy: 0.9257 - val_loss: 0.2866\n",
      "Epoch 500/500\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8500 - loss: 0.4453 - val_accuracy: 0.9429 - val_loss: 0.2773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1eac70780b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train/fit neural network with validation data\n",
    "# see the instructions on the train/test -split above on how to split the data correctly\n",
    "model.fit(x=X_train, y=y_train, epochs=500, validation_data=(X_val, y_val), callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error and performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df = pd.DataFrame(model.history.history)\n",
    "loss_df[['loss', 'val_loss']].plot()\n",
    "\n",
    "# the model seems to learn fairly well according to loss, not overfitting\n",
    "# slight room for improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAdNBJREFUeJztnQeUFMUahf/NsIQl55xBMkgygIqCKIoRI4iCkWfABCJgxsjDgKIoZgUDhieIIgpKRhCVnKPkzCIb551bPTVT09szG9idnmXvd87ATuzu6u6qW3+qKI/H4xFCCCGEEJeIdmvDhBBCCCGAYoQQQgghrkIxQgghhBBXoRghhBBCiKtQjBBCCCHEVShGCCGEEOIqFCOEEEIIcRWKEUIIIYS4SqwUAjIzM+Wff/6RUqVKSVRUlNu7QwghhJAcgLqqR48elWrVqkl0dHThFiMQIjVr1nR7NwghhBCSB7Zt2yY1atQo3GIEFhF9MKVLl3Z7dwghhBCSA44cOaKMCXocL9RiRLtmIEQoRgghhJDCRXYhFgxgJYQQQoirUIwQQgghxFUoRgghhBDiKhQjhBBCCHEVihFCCCGEuArFCCGEEEJchWKEEEIIIa5CMUIIIYQQV6EYIYQQQoirUIwQQgghxFUoRgghhBDiKhQjhBBCCHEVihFCCCEkUvF4RJa8L7LzLzmVoRghhEQWKcesDpiEF7Z7eMjMEEk9nvPPr/qfyP/uFnnzLOf301NFDmwUyUiXwgzFCCEkcji0TWR0DZHPbnR7T4oWBzeLvFBfZMogt/fk1OfDy0ReaiLy76GcfX7nMv/f/x4MfC8zU2T8GSKvtBF590IpzFCMEEIihz8+hF3amg2S/Bcc39wlsmd11vdWfC2SfkLk78+tmTspGGB52jRbJOWwyNvdRRa/k/13ju/3//3PH4Hv/XtAZN9a6+/ti0TSU6SwQjFCCIkMDu8QSd578r9zbK/IkZ35sUenFlNuE/njI5H3L876XmJ5/9/71klEsWdVcLcGLGnH9oR7j/JOarL/7/3rRKYOsawbodjrFRtgx5LA9+zWlaM7cyaIdi0XSftXIgmKEUJIZMQr/LeZyO8T/a9l10k7gVn9uNMts/WJI/m6i4We7Yut/50EnzlI2gc8N9nwi8jrnUQ+7JP1PbgsxjYXebFh4Yl1Ma0cmhPZuGu05QOs/SHwWO1um5yI8NVTLdfOlFslkqAYIZHJX5+JfHSlyInDEtFgZvJ+b5El7/lf++NjkVfbW/sfymy6aILlPzYHglORHx8V+W5I6AFjr4PrIPVo7reFjhsddPq/IrtXSJ74+wuR9y4uHNaVo7tF3r3I2ufsiCse/L0UQ7jt+D3n21/5rciHl4sc3SUFwtIPrP+3Lcz63q6//X/rWf6W+SITL4zczBMnMTL+LJGlHwb5/AGR4/sCBeWfnwYXI0f/CR7kCvHx02Mi816xXlv1rUQSFCOnKriIV3xlXYQmGBBWfSdyxLhoD28XWftjzn9726KCnT1hdotAuvUzAgf5SGTeqyKbfhX53z3+1xa9aZlgsf96NurEtAdENvzs73DzE1gVln8p8vu71rXgFjAxo41+f0fk0FZrv1Z+E7hPyARwaoOcClEIQlzrGJDM63L/+px9H/cEZpxw74AvbxHZ/JvIry+Ia6yfmTN3Cc7xljkii9/O2u6b5wa+FlvM/7c9LsRsa9MtkB0INN4wM/D6PxlwLeBc+AghYM1rSO//uz1Fts4LDID+Z1mgcMnOErN/Q/bXy+ppIge35Ow3g+2z5sh2kW8HO39e73eZWiLnjbT+Nq2HObWMzBot8tdkkTn/DXxdZ+Dg/sPvuijAKUZOVT7rJ/L5TSJzxwa+/uckkcnXi7zVzXqeclTknR4in1xliYzswMX/zvkiE87NKnTyC3MA9+TBVB/uoECNnvknG7OfnPizC8KdsPZ7kS9uFvnuXpGfnxTXWG0EomL2vGKKdW3C7I6OEG329vkiS9/Puxj56nbrWp8xSmT7787m7VCsmyHyydUir3cMtN64ZbHavVLko8tFXmuf/We1+DJn3JhowFX13kXWREMTHRM8tgD9QHazaztmWwUIiJMA7jWciy3zQm8PQNwGu1b0oAr331tdRcafmX32CvpGXJeTrsteKE661nIf5YdlJCfnt3o7kVbX+ftHfXxZLCMOYgLW2QVv+J+bE9FDXkH120si390X2J+FGYqRwgKCuJAOhllmTsDMTrsCTFZ+bf1/bLf1/89PW8rcKVLbCXO2dnib5Bt714g8X0/kyUoinw/wv46bDcFrb3YVmXR9eCL9cfOi8/riluw/aw5YWniYHc4XAywztr0jNYVcdC5vQ8zcxjQT+W1M8M+YnXl2M72CBP5pc5DT1+XOP0UWjreuOdMMnRsxAlP8i40s4aUtUlsX5F6M6H3CeXu8jP/1Ykn+v9H5w/U2OwfWElgknqkh8nQ1kfU/Sa6BVc1JJOREjMx9WWRMU++bHr/7C9efOSs3B3K1nSOBx+rkUsP1/Wo7kW//Y70f4JrxnPx1lpHm/9tJjJj7mJ0Y0S6pg5v8r6370WqvFxqKjOto9TewhOh7/n/3Wn+jzZ6pbrlZ8Vm7hWmj9ztpx0VeamplIoHpw0Rebu0sev6cbPXfyFYKxgsN/b/lJEZKVxWp7hWoa6aGFiN/fW79HtoRwapwWzr12+h3cS61uME2XIJipLCw7BPrQoP/HWbuua/kzDKBdD0N/JJrpwde6BgQ7BcmBMym36zOa9ZzVsS6UwdvdgYwWUJdYyZixk5g1qln/zARJnsHHvw+toPtwcQ88wmrQ81ICZyZoQPctsDKtV/9XaCJ0o7ed3vnkVuwbzCPLv8ie/FjdnZoDwgn88YHMGPDQmWKPVOw5DRQE64IuNOQ9npkh8jMx0V2LHX+rOmuCJahgrZEW8GS8+uLgbPovFSI3G5z3cHyYfruZz0b6Hb75WmRH4aHFr4QXNp9Yuer2/yiWrN3Ve7FSEy88+umEMC1C5Hwy1OBA/XWhVaGivna4glWvEtacmiLAe4FiBu7aTzK6JZDuWpwf+rrD4MSrlXM7k1wX+L+gijMNAb7r+8MzFAxrXO4fp2CKhHHBdcXTPqIN9i3JvD9PSutdlj4psi0h6xzm5vMnAPGvYR7Hftsin19z+A+wjYObAghRhKz9lG4b/C95D2W4MDvwQqCfUUshXnfph6z3Kz4LKwgJlFR/r/RV33e3/p7wevW+YD1z86MEVb/jd8MRvIe67fQt6/7yXKx6vsbYgTU9RY+Wz5FZPojIrOftZ6Xq2f9r6+lKQOt30PtkVC1YzBZwjlCvwtKuSdGYl3bMskdpvkNZm49Uzj30ayfNVO2tBhBbQG7XxIXO2Y0iRWs2Sk6b8wsEcsAGvW0xMuaaSKDfrbMvGYHD2tNnbMsV8rLLa3X4kqIdLrd8jt/c6f12vDdVn0DdGAQJwOm+dMLsa+4UYMBMWIOrD89LtK4l0hS9ayf3TjLv++PHfYPKAmlJEdAFKATMjtidPglKzp/HoOtORuEybNUZefPorMDow5ZnZkpRjCgpp0QiTN8+nb2rbdcEaDDbf7XISYvf8s/u8tMF4lJsPzkoVxFsEzALAuqtbE6eMQf3DlfcgQGHVxbmIFikEKFSHu7Y+ZsDoBmkGrl5iK7l1v+/WDAxaQHmvMfz/p+MJNyxztEFr5hvY9ZKs6/6aIAEPI4DzFxVqfthLbY4NxoczaAaCtRwTr2iRdYr2EbzS61zoEW4Pa2x8wf50fP2nEfb5lrie0bvrSuJ7SpObBioKje1hqU40tY1yhm5AklA4Uo7kFcUzpOpm5Xq54F3F841xJla7tNIn9NEml/s7PVAYMaRJFpHTKtXIinqX9e1u/AhfD9Q/7XIAYue1Mk3isO7EAEoe1wLv4xjgfXIyyhpav5X4NoxqALIQXhE/A7hwIFIdoYbYUJlgaxXeUbBH4PbQmLWihwPnC9YMDGvjrFVZjCFfef/ft6EpYTZjj0h1VbWf+XrGL9j+sGD9/7ra14G0zazMkjMEWbHVxvSC/W6d2xtn0PI7SMFBbMm8q0ljhhXowZqdbNYDfLmjMRdKIAQsPsdLUVBRe4KkZlC277YZgVa2JaK3S8hzlQPF3ZH7mNG8g0FztFyZtgoNjhtShEx1ozzl+ecf6sedNhlrjwLZHRNXMeBIugN5j9zbiDYAMV2PVX4GCLtsvOJ6w7XPNzCO587fTQli4z9mLZx/6/9b5C1CEOaGwLyxxtzvKUxclWKtqcsWqLjb2DDwVmWy81ts4zAuM02M7PT1lVVHXUvhM3TBE551GRsx8U6fWiyM0/BAZYmpidrn0gceLM+6zfwgD9XG1r9msOVPgb8RRoK1jytOUFAskE7YbB8uVWgRZFiKSnq1iWKo3+G1Y1CFq7VQrtghiDcR38178+Lu3K+fhKy/2GQUUD6wPur2eqWZkrOBZ8BplC9iByiBPc7zj2Bl6hoISIOmjrP4iLeK8437Y4eNwShOqztfxuDLTRVkOownJoj0eDlUDHnWFSAnDfP1PV2nc7sKQ9W9MafGFVhaUrALgPdgSeD5w7p+sUfZw5iYAYgZUB1kPfZw75M4U63Cpy848iXYeKlAgy2TB5r5fV7uiHzT7S6X7yGNbUjbOtdjRfyy0lKlpCFASbGNU/V6RmJ+uemHq/82cqNjF+s5JI3bMD3ZSlDOHnAhQjhQEofKfMANyoCFJU1oWRlokWqh03jv1G0XEhAa97BU7tLv4ZupPoATp10G76RjbI9If9z/UMK1TxnYDyxtkElaET1B3IGd6IfbMTRmYQOk77QI5Z1fcPWh0aIv1RUEu3JczHcCFBtH0z2HIlYEYL0zAGccyqfb9znX+wwMzq46utGBD4h/EwgasJnwkF9hc+XHu588Nb/QMHZt6wJMEaYn5PYw52EGCfXicyfajVSaPDRjYIaHC+1+TvySqSnDrU7IAlDMGiGCzh+8YAALeh6X5C/IbOQtEZMlE2q0T3xy0LUtcHLcteh0EitTqJNL/CebsQoWumW9vCoI5zaG97DY4Xv43sA98+TbfM1bgmcH2jnVGtEtcoBKUWnOc8InKNIfBxnUFAHLOlrerrQVuqACyK2C89YJepHWgZgWjDPYxJgT4OTeka1iCLWARU5jTFM+43bcFCaibaF5/BdWlPwdXbLt9QpGxd5/aB4LryHf/xwb0GV5i+b2ElBbDWAAR0om/BvYHrCDP0Ki38vwfR0ayPPzBS35sNzw/crlN5f/wuQBxcTmJxcA2bMRKmBQJCw3Tn4X4OlrparIzIhc+L1Ooocs4wkQqN/e/BHWJag8xJFtoIfYlTFg36Qd++HLasYDjP6J9PllJVA0WEE7Bq9H5ZJDpOZJ2Da7BWF5EWV/mf1zlT5LrP/KLR5XgRQDFSGICQgOLFhQZFbwLT+sdXWYFr6LSQOWGPEYA53Mkyoj9Xvr5fFa/xBgNq+nhjShAIhY41u2hrbAcmyc1zgn/GrImAfQsFBgKIJAwyp13m34ae6SIzCDNHmJxNi4sOarSbmDfNEpn/muVCQjAeLD4Y2MzZvQmO97P+lkCY+aR1oyMGBP5hdNg4Jz2fCxQkQM8+7cAShIHRKThTi7RPrrHiEPRgh8+GSqVGMJs5gGmLQbNL/JU17RYep+tBm5shOlC/AvEpGGDQ1jj/GJhR48CM84AfHiWpNQiItlOva6BF5Eyv+8VOQmnn17EPn/a1Bq1lH1ntjvZ3Qs9ytRgwB2oMqF8O9Adx68FeCwZ09E0uEhlstLU5Mw8FhM2Sif7zBFeidodgMmCKeFi2FnldawDuOR0UCUzhaLp8TGsXrktYwNT3vS4QHbxbAWKkduDge/ZD/tlxtbbeY19juddgPdCTB3P2rFF9i/ecNekt0t4rduudI/LIDv+xmmKkae+svwMrgYmOUwgVt2OCdtEiumRlkRF7RDoP9t8jZrBwKLFdrXVg3IdpbajUVOSeEDVKcB05WUvNbWNf0CfhejWDs7s9Yp0LcMc8kUteC76d5lf6/zZdVThuJ4qXEanUxPneKldf5ObvrX5e0/Riy3qkLWgux4sAipHCgLZW4GI6/0mRG78WuX+NSFKtQDMbBiHThG+ab0PlxOMCh1/aHgAIWl4tUrmFZWac/Xz25kZ0khN7iPz9WfDPmPuYXfVBDQaXCo2svxEYiI7JjI2BYAmVRqs7pwAXlrczRJ0GZAgEA5YIFO3CLNo+OylbxxKILa+xniMmAKBjcAL7aPfPa9CRY8a821tbQP+vLA/e2J5QQBid6fX/QrxhkND7ag/0DHY9wNUD0fFSI8sFhywmxAyZi3DheTDs1w9AXJEG8SnBKBZEjJgDC4SStnI5AQsLMC0jDS8QufR1ayDAOTRrLcDtqK8bPSgllsv6uxeNEbk+m8JiEKvaDde4p/96QIquFovaSgQXpwYWExS/yy4APdg518est437xDx+WJ9g9blpqkj3UdZx6r7DTkXDSuAEBrG2/a0YF1iRMKjrGTUsTvpcYZDDvpl8cEmgqIZLSQNrD7g2yKQAYGDXIlofHwZhgIHfbFPzt+2DeEWdbSRZ72eIdyfLiNqWcV1gsjFgul90mS4sJYxmBn73rPsty+7g3634u8qnhY5lq9LcWSSYwgkWQ42OQ9IxQCY12mct+Q+rqV00mqLHBShGwgGsBK93FnnrnEB/MILSPr1WZIGR0QLQWX5wqb+T1MGIVVpas6j654iUqiJymeFOsIPgMh3ciiA2pwhvczapxYgGgVJXTrQC/zre6s8SAAgiwwBsWgTMztPJpYTBUcem5JTiZQM7SQRX6RsTnZ4ZPIo4Bb1/TuhO0mz/3ACLCI4NHZU500eniNTc0wcGft5phmnP8bcDq4PdxfZ8fetaAPDxmh0KzLJmG6ED6zZUpG0/ke6PWUGWuvMyTdjfPxw4EzexnzvMApFpEwyICxx7mxCr7LYfYH2m2zDngV6Tk0BjZbUJ0oaNLhS50GvuNy0DXe4WaXO9fxZtAleHFqV6UNKzVw2+h04efnnTrK2BpQBxGhDWGIjgPoBZ3ByMtem8lVe05hfl6vqtmhiAIXZwn+G6QDxEp7us/YNogGleD7TBREfNDsG3hQEd1zWu9wbd/UGpevtaZMPygu07Ba2atYzsrlUIJIi485+wrqeuhvtXW1R18L62fNnPlRM4f7DiaCo2sh2XMcDj/jKtJhpYn8zBGgKsdmeRdkYZAvMet1uGEXSOvhvb0pkxTS4WadnXeZ9LGwH65nbN440v6W2rG0SqtHIWFKddLnKht5+ufYZ1HUNYa+EPoa6vU1pGigBIrYM/HzMXM5ALWQiYZSLmQs/ykSqIzAuVGfJgYHlmu2Co1dkywSUk+f22AL7BG6eItL4++31Dp4GMAn2DaG6e7vfht77BitY2rQG9XrCyZswo/VABULfOEukxOvv9OW+U9T+CGk2/N0zPZieErBr4ZLNDz8phCUBsSF6qnWJg0aCdTBeAHvTMmShIquHcHrDqhMIe0GuaedW2je1gcLzPCObD9iDYLnnVH1+jB1htWkZHaaZz27MsnNAz7lt+Eml1beAME+f1opesa8Ls0JU4ixK54h3rGsNnIJRCYXfTYNZmtwYhQwRpjUAfo+a6Sf5spoCZcOOss0DdAev2xkxXD55m3RdklPV42hqgIMxh4reDawBxGhrEVcTGBwY3a2AxCBaoGwqdRQG0hRDgejAF3hl3i1RuZv2NeIiezzjXsbFfr2afEgzUuHAaqO2xBrCeADMuRlvsTHeVPQVe3+M4r5e+Zg3UpvgzXWaYjIFgVgyzL8T5M/fRbL8slhEn62OUSN8PA9tZfwfns8XVgR+HO9B+n5d0iPWIibUy4XQgqYkpDMy/zfaHZUS11bjAc3yxN7AY99xV7/onLLh+L/6vyOlG/SRYlppfbk0Wa5wubkIxEg5M06QZ2GnOQnUAFOoYaODbxuzfLHxjgovr1l9E7v5DpIXhY9Rlg6GSY23rUdy5MNBCoW8q03yOixyDqe95dKBv0ezITvOKoKSa/lx3J/AdpONqi4E9qNHMhLjnT2sww0Cg0UFmetsYlILN7jV3LRbp+azf1YX1Rsz4Bjv6JrbTZ5w/JRAdsjnr1vuDzsYcZDAgD17knHrtxDnDLXEB8DtOHQPMrWZnib/N2afTrFYPzjrWxx57UqZm4HOnmb8eDHH9wafuNKM0zz3aCO1+34rA6zI7dOwDuO03kSvftaw7wWJrQolfc2ap40hMawCCZk1CZSk4mby1mVsfux5Ine5Tk0rNAoVLTrn+M0v43b1MpLHhMoMw1oMVxLvdmhAM8xo2Me9t9B3XGOug2CdDGmR6mBY7xJUAU4zpttdZJ6poms11aLfWwC19718iQxzWLdL3oylGYKnFNWfWadETB9PFYgas2oWCeRya+1dbliDzPfN66fO65XqBC93EnMA5iTiNUy2j0jYrjBOmm8ZuicQkpV0Og2cxeYHbX4tYl2CdkYIG5nEzWNA005t1AhCIitQsbd7DzYOBE5kACDTFhWdGsWv0zYj4AASpwXRodijXfmKl8GmzKWIZAnyQ2jSdZClspPIhEh7WEhOzgzUtA7iQMSuGWRUBpLACYdaC2QeC9PTAodX5ZeOtNEgIDTMOoWEPkS6DrZtWz7IRTDjLm8arg6+CxRU4AXOsLsIGU7wZMOcEzJhOoJNHpwy/f8fb/bEcqi28bY39RmelZ2/IUILbIdjAgwEMZlqd/orj63yXyOznrI4PgymC4Lr8x4rkRydes6M/xQ9oITJwphXoiO87HZNaG2aiFWyKwVADNxwKkWmwLcyMncph41xAlJoduWl9wPUHcziugc53WtePUy2YUJizO4hW/IZZRA9iUQdSZhf9D5cEUochnvRAgP9vmWEFfiKlGG4xnZ1hF9KIy0JmlA7W1Jzh3T7EMuKPEMyMa9lclC+YGMF9g+OCADSvoWDgntSBzrifdFyAKcJw/cH1A9cVLJihFsML2Bejj8A1jXsWli5z0IR1B+2YnetRnxsUY4SI1m4QuKt07IYWa4hvQ/q8qt1hi4cxBZ3GSYzC7abdG2ZdDFyjmETBwqZj0fRxmrFu9t/MToxoK4z5nmlN0ZZls9YIBPDAnywXZ6MeEhIdZ2Za7cw+Olhgd6hznZt7D23oZLkJMxQjBQlcLwgCNEEhKKQpIvraTImEGMHFhdoICBhFgBMyROa/7rdchLr4YCU5d7jzzM4+uzPjDMyLEL5HPJwwO1jzpsSAi/gEPaDWNGb06KRRV8G0quA48LAXAYIQss9O0Qbw9WKA17MMmESRaXL2AyLHD4osGOe8v528BddQHAr7a2YooINCIStk55gFj8zBDfENqNaIjgQdNDpYmLzV903LSG1nM7Ie9M1iW5VOE9njHbQQ1wErEMzWGMggxiA04APWwLxsdy/AT2wHs3U9Y7dj+sohamFRAr1fsdxwZjzIBU8FdqgQP9qNoU3v5oBhWmngD9f7m1fMGS0GQnDWEJEfR4hc8bZIk16WWEdl3OwsIzhnSB22A+uRtiBBWOkUVvtsGXFZeNiBqV6fI1xHdc7IavrXFgTM1JG+ilkugqCv/9zaL/M4Q6EsbV4xYt775nUKCwf2CecuN5jXLQZwCFENipR9e7c36Le0dR+jJpFTe2iQuYWHCcTu5BtELh4T2D72YGqN/RyYIFgW8SLI7mt5VVa3qfq/pr9P0mJEX69wL84Za91LditFgJsmREyTeb07WdLMeA4cC0QKXGXZYYqR2GIiV39oTTTgYlZ9nzceRIO0ZKzDBIvMKQTFSEGAwFRYMlDhVAsODE6IG4GVBCV4dfolhEHji6yURQyyuuPXJjhdHwSqP78wTdj2FMhg6NlBdjMkkxLlLfOfvfqltvzgxsPsCGl9Tp0AOo0bvwrsPFAb4JF//L+JweoFI2UNjNgXaNlBx6Arfd40zbJa6N9Eyi5SY5teEhhAifY+6wHLr2vHdGGZM0x0eJhtmx2eOePGbEWLEb3GxLWTLDOt03acwICAayWnQCQgiM0ewAyhAbCvuC7hZgNmG8DaBTGCc6Vjb8zrJTtLU26x+/IB/NvtbvKfbwhZLUYwKOtjMzN2cry9hoYYyYPrxATB5YgtgLVIn3PEVMGCgnOLc6yPAZZHxBXALWUv3Ibj0NlxsHggrdaMF3GyjOQF8zyaLgy9XaSW6mvyuhAZLqFodIGV+qvvRVg8Q5UGcDr/5v040qGgIK5XuHLMonamoNYDOfqvBzc432dm0TM90cLx4zqrbViGAtw0Dim2pssoN9cTgkh3LLH2Y8gqf3v1/59z39DxNisQ1W69LuRQjOQ3sHwgHRKBQdq8hs4JAVlY6VYXUMJ7ne6wsl5wEZsDDMz35pon6jWHvP28Aj8+BBOEAGboOeXW2VbsBQRBTgk2yMIkj/RAmMLRATsJlmC+VvOzZgeB9Nq2N2a9SZF1AtcQZpF6JqvBeVlxrj9YF5VAMXNzcon5jinO6ihg+TItSz2esdwcSIc2rTtXvW8JwF+f97+uAyFVSfJc3IbYT5w3LWZyAuI3YG7HvsANByuPTj1GYCFMwnANaRCbgIJrmIHCpI33dZua+2pP3TxZdFuZYs9+vs24AgwIvcdax5bbTC37b2WX0podFRpYgzb2ybxmdXuZx6AzjzDQvdYu0DqI60SLEcR/YAC3l103lxzI6WTCjin+nUqA5+aaDIV5L2LGjzg5WAAx2VJu3QlewVvW2SWTU8w2N8sFmG7NYMcEwd7vGyvgVqcKw5qDSYt5XTkFsAYTI8hyyilw/ZWsbN2DZnuF6htOMSECKEZyi6rg+YhlisWgA8sH/O646JHSBrMs/JNm1cZ+33otC7hhvAoeZnXk/gP7CpnolM2LDQMcOrv8AiZflQmTSzCAOmUT5BUMIqZPOi/ghoVLBunPEB1O67tg8O0WJLAPHYyZlqtrNmSHUwQ8fqudd9EsEx3ka9Y4yel6OU7HG8yVFgwMXjqC3n58aC8EvJloVxowgyU1yHSC1c+ezZIf6LYKRr1u1gODMO6RmKTA7IDcoK1B2c3Kc0p2sQEaCBNYewBikVB0DLFUaHMMiAiO1SXAnepGYL8xYYGIcIpxyOl1hPO3ZX7+Wl1DUbWl9TCBpRBiBO0fKsgzL9jXiAkFrim7sLBfV8ECWJ1iO+zWrFA43YNFEIqR3IIy0rpcONwVqG+hq+8h7sOO6cvELFr7S80YDNyEqM6HYE0E1uE5rCk61gF54SQ4PXOQMhwJoHPDQn5mllBhBJko9myUcAEBgllsfmDegyczKz8ZEAeDhwYz4RuyKa6G/uEah+KGucWMT3ILM0stv4DLFaXgdVZhfpGdZcS0YiCRgOQKipHcYpZaRxlxp4XeYPqeMybrDQ8TrJMY0RX64P7QGR3odBH5j+CmkzUhk8gABZLgS87PjpfkHUwS4JIyA7pJeIFrFW65/LwnENgJixJWLs5PTMtHsMX1UJYAmUJ5jeUpwuSpzsi4ceOkTp06UqxYMenYsaMsWmRU1bORlpYmTzzxhNSvX199vlWrVjJ9urECZmHDzAJBGXF7YSP4gZGJAb/wBU8HuiGQPVGjg+X3t2e4QFXDVGi6Z5CdQiFy6qDPMTJ8SGQA14hZsI0U/nsCLlAEejsVezsZEAeCirawYju5gwGuJXv2CykYy8jkyZNlyJAhMn78eCVExo4dKz169JA1a9ZIpUpZTVePPvqofPTRRzJhwgRp0qSJ/PDDD3LZZZfJvHnzpE2bEOtURCpOS8Qjv18HoOJiRFoiAiNzkv5GCCGkcKDT+0m+k2vpOGbMGBk0aJAMGDBAmjVrpkRJYmKiTJw40fHzH374oTzyyCPSq1cvqVevntxxxx3q75deekkKJebKsBozqLNGiOqLhBBCCDk5y0hqaqosWbJEhg3zF3KJjo6W7t27y/z5xqqFBikpKco9Y1K8eHGZMyf4EvP4Dh6aI0eCrHLqBuZaIRpE9iMlFAWZsKIlIYQQQgrGMrJv3z7JyMiQypUDC77g+a5dRiqrAVw4sKasW7dOMjMzZcaMGTJlyhTZudNYo8XG6NGjJSkpyfeoWdO2fkakuWlQvwIpk6gKGqxeBiGEEELcWSjv5ZdfloYNG6p4kfj4eBk8eLBy8cCiEgxYXg4fPux7bNtm1GeIRDFi1isghBBCSMGJkQoVKkhMTIzs3h24tgCeV6niXOSlYsWK8vXXX0tycrJs2bJFVq9eLSVLllTxI8FISEiQ0qVLBzwihmQHMWKunEoIIYSQghMjsGy0a9dOZs6c6XsNrhc879w5dJEXxI1Ur15d0tPT5csvv5RLL81D+eZIsoyYy8UTQgghJHxuGqT1Ik33/fffl1WrVqnsGFg94HoB/fr1CwhwXbhwoYoR2bhxo/z222/Ss2dPJWAeeughKXRgvY60ZOtv1BIB9nUjCCGEEFKwdUb69u0re/fulZEjR6qg1datW6siZjqodevWrQHxICdOnFC1RiBG4J5BWi/SfcuUMZZbLgxkpIm80dm/QBiW3EYV1fxcq4UQQggpgkR5PPZV2iIPpPYiqwbBrK7FjxzYKPKKt0jb+U+KnHG3O/tBCCGEFBJyOn4XeDbNKcOhrdb/WF2SQoQQQgjJNyhGcitGUOCMEEIIIfkGxUhOObjF+p+rMRJCCCH5CsVIri0jFCOEEEJIfkIxklsxgtLvhBBCCMk3KEZyyiG6aQghhJCCgGIkJ6SniBz1LuzHAFZCCCEkX6EYyQmHvAv1xZUQSSzv9t4QQgghpxQUI7l10URFub03hBBCyCkFxUh2LH5H5KPLrb8ZL0IIIYTkOxQjodi9QmTqEP9zZtIQQggh+Q7FSCgWvBH4nJYRQgghJN+hGAnFYW/gqqZYklt7QgghhJyyxLq9AxHNsT3W/+XqiWSkiTTu5fYeEUKIIyfSMqRYXIzbu0FInqBlJCdi5OoPRO5bLlKigtt7RAghWfj2z3/ktFE/yDfLduTbbx7+N03+3n44336PuMc7czbJ2J/WSiRDMRKMjHSR4/utv0tWdntvCCmUzFu/Tz5a4E2NJwXG3Z/+IRmZHrln0rJ8+82HvvhTer82R5ZsOSiFncPH05TlqChyIi1DnvxupYz9aZ1s2HtMIhWKkWAoIeIRiYpmoTNSaMjM9MgDn/8p42dvkEjgurcXyqNfL5clWw7IqcikRVtl6Jd/SVpGZoEIuV2HT4gbpKRnyKw1e9Xff20/VGDb2XHoXxn0we+ydGvBCZ4DyanS+skf5arx80N+zuPxSDhZvPmArPzniNruL2v2qP0E/xz6V2as3J1v+7PnSIrv7837koOeB5xzN6EYCUay10UDIRJNP2xR4bu//pE3ZkXGQJ4X0Kl/sWS7PPv96qCd2WeLt8kH8zcX+L6Yndu2A/9KpIKO+FhKuuN7n/0euq2GTvlbJi3epto8P5m5arcScleOn5fnfT8Z/tx2WFLSLYG1/WDBnbvbP1yiBt4b3l6Y4+889u0K6Tx6puw5mjOh9uvavYJb4e8dh4PeE4eOp0qPsb8qYZRX8Ns3v7dYer38W7ZWmD1HTihx1OuV3+SN2RtkwLuLlagFl78+T+3H9OW75OOFW+SrP07u2tp52H/+1u52towM/mSptHzsRyWK3IIBrME4ttv6v0Qlt/eEFDAwb8dER6n/B3/yh3rtnCYVpUmV0lLYSMvwd7avz9ogF7WoKnUqlPC99m9qhjzk7fR6nlZFKpUuVmD7Ys7IUr0DW6SBWf8lr82Vc5tUkok3ne57HebsZVsPyUNfeNuqeRWpVKpYwMCTnOofcFb84xxbgc/huoqNic5V0OlXf+zwCQH8RpRD5WfMqjGYYd/zm4Ub9/sFTzZiZP2eY7J61xF1rTntp2m1AyfSM5Q7qWnV0koggONGW4be1lF5b54lDmG5ubp9TcfPbdmfLIs3H5Qr2laXo4ZYO/JvuiQlxqnrMT7Wf06embZKDdR4IFYmqXhcjvbHPH8YyH9ebQ3ma3cflZY1ygT93ub9x31/Pz99jfr/x5W7lUtz1xFLZI34ZrnsO2ZZS3qeVlWKxztPitMzMmHDlzjjGsNEICHW+rz+PbBu99Es30efsHzHYdV3NKhYUtyClpFgHLNMlFKyott7ckpx9ESazN+wP+wm0WAg4K/B8Gnyw4pdsvWAv4M4eiLns03cyAe9JtaCYvvB47IpiInVxJyRvfDDGunz+tyA93cc8h/jzhAugHfnbpIXf1jjeJ4wi4SJObtzaP5+Tmex9mOZs25fgZqP0UZADyKa816aLfd//qejsAKvzFwvzUf94Hu+ZlfWTh7AQtX8sR/UYG0CgYIZfrOR05Wlyo55/WnzvVNQotO+5wcLNvnFyHbjmnHiijfmKRE/7e9dIT9358dLpf3TP8mLP6xV1pBXZq4LeD8nrq6Jc/1WKn3PQViM/Ga5sibpwbXrC7OUu/K2D5fIiK+X+75z4HiqTFm6XRo9+r0v2BfiY8rSHUEHbGwH97idn1fvVufvfa840ucjOwEH19ucdd7xxcajxr5qIWK3btivowtf/k16jv1V/Q1wPTUdMd1nrdttiJG1ewKPDVa1d+ZsVEKkcukEqVG2uLgFxUh2bhpaRvKVx/+3Uq6dsEB+WOG1PLkMZmgYU9GZYTZjBrwFY8HG/cp8D35auVsufnVOwMAVDHRqusNYtfOIvD5rvW+gxezmwwVb5PH/rfBlMHz++za54L+zZePeY8p0e8lrc1RHdjzVWSjhdbPjAYeOp6kZKV5Hp61noto37QT2EefptV/Wy8qdgYMouOGdhcrEPGutc4cKsM+YbWr2HE0JGFxxvKFA+/d9c77alh60MLhg4IOg1WIFLrWt3lkmjm//sUDR4MQLP6yWS1+bI3uPpsjCTQcCOnwILKffgGiZt2Gfb9D8ry0zAW4NJ9P8m79ulBNpGCxXqAENQg6MnrZKzfBxOUxb7l0R3GZt0GgRijYzRV2w8+c0qCenpKu2wm/h3Ez4daOjyMO5wXGYQavB3DTI4Gk0/Hs1mIMvl24P6ZaYvmKX+v2Jc/2Dtsk272QAYuKI9xzb+WProQAXFYCo+GD+Frnl/d/VMb3160bfZ2BtMMG5HfKZda/eO3mZzwqU7r0vnVwZcJfhHkebTP1rp/ziFX+DPliizt+ob1eo52bm0Yp/jiiB8OjXf6vj8lmF0jLkwpd/lVd+Xi+54dyXZsur3vsAwhaZMTgW/L1uzzHZsDdZWUD+2HpQWT6xudd+XpdlUrDOa/kZ98t6dT0+PXWlvPijdS23r1MupGWroKGbJhjJ2jJS+MQIbooXf1wjQy9sokyhkYSeIWJAh+kbYABAp7HvWIpc0KyKVCyVkKffDmbOdhq0h3+1XFrV8BexK1ciIWB2e9A7aNjBgHfNWwvU31WTiskT3630zU7t20fHEx8TLdHRUarDu/7thXJj59oyqvdpajYDYqKi5Lau9eWlGWt9sSq/rdsnM+47Wx70ugiuHD/fNzvuNHqmJMbHyKMXNZPrOvorAqOzg2BZ7TBDx8D5qkPnpztzDFRz1++TsxtVVCZnPWCCeev3qyj885tWlqtPr6m2s3yHdQ7/9+c/ck7jSr7zWb1McalZLlE9h+DcbVgTtGUBQZkQGIPOrifDLmyqBrRvl+2Ql65urUzjizYdkHIl4tUA86e3c/9owVY5o34F30wPz+/oVl9enrlOtRlM23MePkfunfyH/LRyj3x4SwfpWM856Bz7P+4Xq50Hvr84wH3UefTP0rpmGTVDtDN77V71+OrOLo5Ws9SMTCXcIBabV0uSWuUTA2azOC4MaBVKxsvTl7WQt41ZtD3DAaJVnxsAAdGsWmm56d3FakCcckcXaVE9KYu1xfz+kRPp6hpuX7usuiaRbTNz9R6Zv3G/Ega4TrYdPC4VSybI7qMn5LHep8mf2w+paw37DwFVKiFWuTggaDGDLpkQG9CO+E0TXOO45jGwP/zlX+q3b+hUWxpUKpmjWAQIsLoVSsjVb85Xx//cFS2lTvlEqV+xpLq/2tYuq4SUXYxtM8TS9RMWyu8hsn+GTfnb9zcmIWgL3G8mmJTAytK2VlkpkRCrJg7guemr1XkEq5/s6ZtYAIgntLnmo4VbVLuhnXG9Xtq6mozt21oJtoMhJjqhQB+Bc7hsmyXIcF+aTP3rH3nO6/IB2o1oTlAQBzT8q7/lu792+qyCmna1yoqbUIwE47j3gk4sJ4UNdPZQvzA3zht2Xti3j9nD5v3Jcme3+lnEwc5DJ7JE6CPoEuZUMG/Dfhl3XdtcbxMz6avenCdVk4rLewNOdxQlmHEhIBCzFtMvD9Dh6E5H/Z53tmfn983+mfQnC7cGuHb2J6dKhZLWQHb/Z3+qjqdexRIy9T9nKRMuOmkM4LHR/n3DIH5p6+oB2S/olPWA72Smh399wm8bA8QI2tBJiAAnIQL+OXRCWQf6TVykjv3yttVlzNWt1XFonvZaN5ZuOajEyMZ9/sEAAzlmfejsINBwXDefWVcaVS4VIESAntHf/pE1m3xz9kYlRvSABrdIvQolZNHmA1KldDEpFhcdcC4wO9XArKxn+gADV91h03zv931rgZxWrbQazAa8t1idkycuPU1Or1MuYJavxY6J7uiDAf9+tTLOpmyIQYDtTb37TBVzYgemd32tn9ekkhpcENwLa0+pYlacwpz1gYMjBhgtTAFmxdhGsEGtwzMzA57Xr1hCzZx1MKcG1gRN7XJW2+tAT3BGgwpKvKD9cZ7Nic1sBzcDBj9cJ1sOHFd9AID155FeTWRqCBdOh7rl1CAPMYeJiN4+gjhLF4uV6zrWVvdHp3rlfEG1Ou6iz7i5AecslBABsCIEayvE3kD0YJ/x6Na4otzXvZHvfS1E7JYrJ7cMhIjJN8v+UTEd0/7OagXLDctCXJ/PTFsdcL5xb+O+0xlZaEsIpqkO+wAR2LtVNXETummC8a/3oi7urlrMC3og/ccWE4CZOyKzEfiWH2BmoM2Ppon4rk+WKtW9amfg4IhZkx7oIAhgUsXD/NwKB99sKNApYHb9wo+rlXkVs9ctRnCYyedLtvmESHbYLSMwiSKNE7Elmu+XB3awG7wdFESP9kdv3JssU/7YrgYdPRhN+M0/K46OilLmUgwCTaqUku5NrZo2djeAHQwOKnDNGyCJmU5ugZDCudIiDH5zBP7tM1wqvuNPTlWm3Zmr/DNcbLPbi7NUBgGA2IKJHO4UOxg4er86J2D2aLo1YBXDYAhgbsbnE2KjpX/nrItTog3hQgoFzjMsEeiQcXzPfW911KuCWBNMEMwcDIi+qX//E/L7OBZszxw4KpVKkCf7NA/4HIQbhBdYuPFAQEYXKO4NjMTvmfyyZq98novsHS1EQjFu1nrVViYXnFZZmnkFyG/r9irxCSsOXGXI/tCUSYxT166eTOhBW1uYMEj+aRtEcV5hWezXubZc1qa6b6Z/mVfQaXC9aKG+wNtGep6Be99sYwiZ0+uUVe32/JUtgx4r9nXExc3EPM2IlRh4Zt2AzyFANtjgb94HAPeNE3edU18dI4BlL6eBugBWoQFn1BE7wy5sIsHAhOCDWzoqQQI+mr/FN0mBqAP2UC+cv18e6JZni3R+QcvIKShGgvHrun1y32RroNj87EW5/j6EDMzEj1/SXM2Ge/z3V+nerLL8t29r32dMV8ehfwMHdLu5sNnIH1RnjE7PHCDtGQYQPE9OXan8nZi9X962hnodg3D3MbOz7OfXy3aomUqbWmXl9y0H1OwGnUAwC4ET9lknItuzC9DDTBMR9OjATB80XELBgIlcm9sx88Ts/adVu7MNSsTvw+0D1wiO16YJs4B2K5cYH+AewHYAzO9wkcDCgMC/YNjNuvocmAIjGLDu2C08wSw55kwVA/b73hk8Otja5UuEbJu+7WvKwk37A7IVwF/bD6tBUlslgvHmje2kZY0kJQ50TIGJnpk3rFQyyywblC8Rr4QbXB7anfPyNa3lklbVlLUOghWzbrhrOtYtJ02qllLia+AHvyshWq1MMV88Fb53q7G/fz12gXR7YZZqR1wrIy5qqkSuGTiZVzCTX3bcP/DivoTFDtYOWEcgKOBuwPnWLqTO9crL+BvbqWvnw/mbZcQ3KwJE4rNXtFTxPojzwED34lWtpP/EReq9C06rIo9f2tw3gUHAdLC0UztnNqiQxbUCJt3aSbl0NDoTqnHlUrLGiAdDBg6uq+s71vK5WnR/UzYxLuDeh+XSCftkQceyNKpcMuA4sC30RaYV6tVr28h/bC6uxPiYAKECEfNgjyYq2NYulG89u55UL1vcl/lngv4DfQL6IYhQHZvSplYZ5drUwaqhrDhuQTESjBOHThkxgsEdD7vZGLPrr//YoeIYyiTGh/wNzMC1kMEgsWbXMeVPhqsDz1/6cY3qfEzz5cFk/0WODtQeCKc7NtN0jL4Blo3G3pkWQJDhu94oepiwETD2VJ/mQfdZ+1L17BFxD+gw7TM/Jx7r3Uwe+99KFTcB3ztmYR/O3xIgRDBjx0zKPuOE+RNZAogfMM2ioVi986gvjRAzttxEs5vBl9lxdsOKcmGLKgFiRNOrRRUVvKY7bzuYwYbKvAmF2Tmjk4Tw/OL37era+c0WAItZLVw8Hy/cqp7DLQTxAXM5ZqkPXNBYNu1P9okR7YpBjAnigFCXYeBZ9ZTIgfkejLy4mQoUhjUFsQjZUatconL19WlTXVlq4IpzoleLqio19Msl25W77KmpljsLpm6IDX1tYFC/sLk/5fXRi5qquBrEfCDd98p2NZRrA9eJFoegx2mV5fxmleWd/u1VNsjDFzaR0sXi5LXr2ihLWv8udVTqpjnIOg3adpdPTrj7vIZydfsaauBD+rfORtEuSQiuV69ro8SIPi5cP3YQrzL+hnbKXQnrB9r1qnY1VDAzBk0N3Bdv3dheDbwJcTFKHENsmO1hgrgeWFrs9xbOncmXd3RRqcB9T6+lrCvIbAK4xoBTSnXDSqV8Fjon62cwEKgMOtYtr9yfiLHB9Y59KlM8sJ8yJ1+jejdT18K1E6w4NHD/+Y2UWAJmnA7OyyWtrGvp4pbVlGsNFXJNtCsNsTraDQ0h+PHAjpIYH6v2T18TOMef/b5dWYkiAYqRU8wy4pRuedErv6mO5HqvmQ6g877u7QXKX433XriqVcjfNYUEzLVmIJlW+bd+8Lua8Wj2J1uDP1J5cbPVLOc80NoHdZiCTTGCFDoTzDhf+3m98nOawOzqZCHAzFPn2i8afp4SRohxcJoRlC1hdRy/rt0nXZ79Wf51yJDAdk+rluTb71bezlG1jZHJMPjcBjJ58Tb1OQQDliwWm2VQh4Vj7npr9tWkammpkuRc9wMiJTfFp67tUEvFt+jZO4IIMXiNubqVikdBIS9tvWlePUnFBzjRvLplrdFi0E61pGJZ3IGaMxqUl48HdlKZG/Bd339BY98AgN+zu5YwyCCIVosRCCjw8jVtVPwTBjxcS5p3B5weUPtj8LnWNYPA5LvPbaDEAszcSEO2DyowyWthBneCjnHRAbjgmctayI2davuCjWE21xYXWE/Oa1pZ7jqnQUD804XNq/jqYIBrOtQMqGcBAXKL4Q7AoIIHzhUsXbC8PNSzsdzR1Yq3wjbw0HSpX0E9NLj2TDDAtKhRRtbvPirDL2omN727SLlOwG1d68lva/ep2AzUBNGxA2gvHT8DC86Q8/1xEhjIINAf/26lz7w/+vIWAfugrQ8Q09ra1b1pJRUDg8ed3Rr4Phesn0EtnCEXNPY9h9hCAPAFY36V06qXls37jvvuYVwHsDZMMWK+LmhWOaDOBmhXu6x6AASimgI5GFe0s0So3aqoU39hXdCxSuNvaKv+NmOPcBxf33WGqjuDAFicQ9Q1Md0ouA/hFoFFSAujy9pUV8IAgvw/5zX0fR6B2BDbcJeZ5wU0dDgOWNr0sePanbR4q7rnIUTAOU0qKTGCvhiB1LAym8LQTShGIkSMwBWBGxk3ilkgCZaDYrHRUt4bGGmCQRoWitu71lODXIn4WFW93qTJiO9VZDwwZ0kIsNRVMc0UTVT8w0wdHSSEDYQBZqdmUSeYE518qZipmCmB+7158lgXAejtlSoW65iRgIEPA6WOvUDkO3zVup7A5W2q+zogDLLrbVkIV7StoW7CiUFMvjDzY/DCA7MRu6kXlgxtbQlV1RKz1LWGi+E/5zSQfw7/q9I3Nfj9y9rUUKIAM/aGlUvJfQ5mf5OmVUv5ChVpYDZGW918Rl1f5o7Z6Qeja6MKqjaJFiNauKHzubytldWkBymIEczi7GBAx2wM4g0ZWk7BgZe1re7tdEXFi+D3qyUVV9lccOcBZM6YYMYPMWKf1eO8nNWworxybRtpWqWUL3YD16OeeaOzxoAJ0WYKERMMAObAhg5Yi5EHLrBmnXAnajGCAVeLEXMmqgdZWCkwq0dQthYjaDNzNo1rByDjw7SIQbTmBBwfZvI4Zz1Oq5LjFEu0vbZcQQA8f2XgYI/91iAjaWjPJsoiCTeSFiO41+/o1kCJeacCajedUVeu6VBLVenEdYLzZwcZY1PvPkvSMxHHZFkPTxbs++JHu6uMNDPQFO4tWJx0XzD7wW5ZrCJ2zKypULERcKvgHoQ1SBdLg5UBAhICqGvjiureb1C5pPRsXjXLWkBta5VRwh8PJ9GurSL2idSIi5spEQkxa4Jrf97Qc1Ub2IGwh8vmvbmbfZOgpkahRgRtD+vVxCdEdB86a80elckI8dYpSNaZG1CMOJH2r0j6iQIVI7g50N9oNQ+/LzIX/nNuAzWDRKAcgvBwU5SIj5EVT/QM+D7cLje/Z5UuhspF0GD5EgkBVSStzxnR50bRLHOmiN8HEB46vgH+a9S5gB8YM7XjKYGlve1CQGMW5tKWkbiYwI4VHR6iy+2c26SyEiMzVu2WxIRY+XSR30SO3xh1yWlqsEO2EECnh45Fu1/qVyqpOk086gydmuX3zVmk2dnD3Ay/OAYpDP6h+GlIV9XRmBYoPEfsDGJaUCsEHcQjvZr63r/KWyXS7BBn3t9VWTqQ6orKimUT49Xgit9FR65jEybf1lkF5MGKocUILAjZiRGY9I8YGUHmzBC0qJHkEyO6A4NLQ28DQABDGKNK6xd3dFHXIo7vpi51VOcHl9RNXer6OnecP82ZDYOvcI1ZNWayZg0IZB1d1d6KBYLYCAb2B2IlN1zZtoY6RxiEMXhD5JiDRZuaZQOyl+yD7Js3tld/X22sbYKAVA3O38z7u6nBHPczBtEjJ45mOwu3A4Fjipyc8t1/zlRCULefCYSKBvEouO5jY6KkXoWSAdZAnWYfDAx8b/cP7FvsoF1j8nnpDG1Jg1UKgby4bfEaLKeIQUE/iMlSdiC1Fq4aDPahhB7eg4tu9PerfGKkVY0y6ti0sHzH6GNxryMWDe6sB3o0kgaV/BZdk48HdVL9GaylTpQqFqcsGaHawAn0M71bVvO5a0xrCY7FFCL6XH94S0eJRChGQllFomNF4vO/PC46xZ4v/6oyKX6492x1oesUSlzYECM6TRAgiMxevlgvYqWFBUQHrChYXyEYZlCliRZE5mwfwgRCRKczwm9vD95CEB86iGAphj+v2iMPpP2ZJYUSfnK7GEFAHwYoBLwh2BAPkwFn1FWzBJj+MXvVlgtElusiRjozIRg1y/pnT6aYeP36tkqMQIBltzCZHsQaVPR3OggmU/vSq4maaTjNHHXUug7+Q6AdHl0bBVb4RQeC60KDz+D6wP7e0KmWEi2YpcHF1LJmkizedEBlVwAdW6E7N7uVxQQd3ycLtkqb2mV9ZaYhxrDvZz3/i29/TYZf1FS61C8v5zatpH77qUubq8E6L8AMr8UIAglhMi4osI8QISZoH9QMQXvXLpeoalbgugxFx3rllAkfwYb2Ac2cbcM64HTNFRQQjcMM8WtSuri/i69iWEm0OxJkZ1WIBJAdg7gcxA1psjtfJkiFXjjsvBxfr6ifgzWHICZDZVfd3rW+EinnNa2UxU1kAkuIOUHJT06rVlrF4tQunxhSuEQ6FCPZuWgKoCIdBnCkfIKWj/2gZtUBm3dI/0JRHcR23DPpDzWrQQqrBrPrkwGmfFQLhB9cY1YjdcqrByiqhk4YpkrTIqJjKGCWdFpADObiz2/vrKqN6hlps2pJ6qZyAq4XWIwABgElyryxqBg8YTVBhLj2D4OHezZRRYoQM4COCPU9ru9UK2CQ124adMwISATlSgYP5IXbQoOiVpiZQSDpTgizkItaWr/jxLOXt1SptPdfEOj7tWPGneiOEMf9VB//gI0sBkU3K4Np/oZ9qt21GMEgNOqSZnLHR0uz+JpBjbKJMmfouVnM6WYNjXRb1D06ugu97QTyKkS0qT0vpffzE2RbaczZbjAQL4A2gBslFMmGFfFk2ig/MIWt3QX1yaCOypoH11ekU69iySxW39ySm3MBcYd7HNlZoYDFMTurUkETHR2VbcxfYYBixIV4EV3OWls97FYCp3gM1A55ZApKC/+bZQXUvFb0M4HZ3zT968wZgP7MrAip4z7gbsEgiWCsiXM2KRM/Zuc3dKytUhWdQPAbbh4ETSGwDetVaNcDfuvaDjXl00XbAgSA6f8HZoooZrizHzxHvWYGH952dj1pX6esEliYxSPQ0ATpvrCuwIdqgg4b/lvU8ECMjRYsCAKDb90kNzMz7Rr59aFzsv2cWdkxJ8BkjYdZ6wDtAvN1qO05LQYG8QOBhzTYgliAzXS3PNijsYyZsTYgoDOSgdi0X0dO9G5VVdWSCSauwwlcDqhUi8waO/ZgWBJ4b5iBt6TgoRgJoxhBcCeCThGkFwqnlDasnWKPE3jhypYBlRnhskBWBFJfEX3948pdWSph5gWn9dAQpGiaqmHiR3EfDDJmrRF0yIjeh18TlgTT1VTZcKu08cZzDO3ZVJk94ZbC/sOcbwdZDo989beKZVH7UqZ4lqqYWvAEAxHu2B8n9OBoBuPC4mHue0ECVwjiOeAnzw1me+qAyrzw1o3tVMxKQZt8UaEXojHYiraFlfvOb6SyKlBC321gFVw8vHu+BJQSUpBQjIRJjMDnj8qFwVweJsi+sKPTP81sDXtuP0zvCIBDVL6OpjbLZDsFYzoVDdPAfItluJ2oWiZrfIYeVJCKZrpL4MtEcKZ9MDeDAHVwKUQCoteBzrW3c83pNaVD3bIBBY4KAtNDFyr+Ir956epWMuHXTb7KjTkF4mHRI+eJRPnPRV6AyAyH71kHU55qwIJiptG7TWGOIyBFB4oRJ/71ukmK5T6y3QS1OBCQeknrar501ZyUZ7a7ROwg6HFk72aq9gRSvnSMgQ6kNDt71G0wi4ohSBOWlz6tq6lgTJ1yhqhwBG1hTRBUWkSaKQpIXTpurq+Ghpm5YqYM2oEYQRotgmqx7kSwzhD7r4MyTQGTHbB6BItaz0+wX26AtsX5zQvIfCGEkMIGxYgTad5S0vHZp4wFA9VNseyzfUG2UEt/23GqJ4HU0/dv7uB7fkW7Gr4UWKfqnajgiPx4rCEC4KdH3IYe/D8a2FEFPWoXiz2wr0aZ4j4xghQ37UIyUwad4g5QcwCxD6FmZfagzEjjnu4NVeyEuSAdIYSQ/IdixIlUr+UiLmc+e7hVUCwMAz3WBABvGKuw2rEvloS0L52NYq6NgHoOWPNg8u/+gE57rv/DPRvLvA37VF0JlGm2g0wP+K9RQwLiwKxsqqPU8QjGWQ0rqOJIqBx4ccuqORIjp4ppGBaKnx/o5vZuEELIKQ/FyElYRmau2q0WK9Ilw5F5MXfouRIXHaXW33Byr5gpubq+xoR+7eX+z/9UlTyxAi0eOv8f9T7MXHszfRWgYuiM+7qq9NZQxXyCxV9kBwqIocS73befG7cKIYQQEgqKESdSvWIkLvSiZbe8nzV9FfEZWOkRcRxYtEgvzw5QeMkUI3CNoAYEBMU3d52hXuvSoLwqKYyUXxTQQiVWp4BPk4LO8tDCwywU5lSenhBCCMkLeRrFxo0bJ3Xq1JFixYpJx44dZdEia1noYIwdO1YaN24sxYsXl5o1a8p9990nJ07kbRXQsJCm3TTBLSOmyDDBeiq6bghWX0S1Rg0qZpog/da+8iwi8bEWBOoZIFDTrAURbC2OcAHLC9b2QAwFFtcihBBCXLGMTJ48WYYMGSLjx49XQgRCo0ePHrJmzRqpVClrkaRPPvlEhg4dKhMnTpQuXbrI2rVr5aabblID25gxYyRi16YB8cFjRrCWTCjOa1JJFY0yKyCaixgFKzplx1xboFJp960Rg8/1ryhJCCGEuGIZgYAYNGiQDBgwQJo1a6ZESWJiohIbTsybN0/OOOMMue6665Q15YILLpBrr702W2tKZLhpAsXI8h1YM+WQWtr6a2+GzPNXtFSVOFGhU9OpXjlVXhqWDdO1gfgQM6zDXFo6GFhmWlPOpVRTQgghJGLESGpqqixZskS6d+/u/4HoaPV8/nz/ipYmsIbgO1p8bNy4UaZNmya9evUKup2UlBQ5cuRIwMMVN40RwJqSniEXvzpHLnltrny5ZLtadA6Fuq4+vaaq5GmWVTZXhzWLlyJ11sx4yYllpLKRteL2OheEEEKI62Jk3759kpGRIZUrB5Y5xvNdu7JWDQWwiDzxxBNy5plnSlxcnNSvX1+6desmjzzySNDtjB49WpKSknwPxJm4HcC675h/PZSXZqz1xXxoKhsuFNMdY0+l7drIcmVBV2S3yizo1qiiWkfl3ZNcJIoQQgiJVAp8wYJZs2bJM888I6+//rosXbpUpkyZIlOnTpUnn3wy6HeGDRsmhw8f9j22bfPX2Qhraq8RwLrniD/gVnteUOZcgxgYrJmC5dBRj0Mz5urWKnbkyzs6q+cvXtVSPruts3w6qFOOMlLwuyi+dU4BLlpGCCGEFJoA1goVKkhMTIzs3h24kBueV6nivIzyiBEj5MYbb5SBAweq5y1atJDk5GS59dZbZfjw4crNYychIUE9XC96ZgSw6jLoJrWNVWKBU6VOFDQzl76GuECJdEIIIYTkwTISHx8v7dq1k5kzZ/pey8zMVM87d7Zm/naOHz+eRXBA0AAzuDMis2mMANa9xxzESPm8l4snhBBCSB5Te5HW279/f2nfvr106NBBpfbC0oHsGtCvXz+pXr26ivsAvXv3Vhk4bdq0UanA69evV9YSvK5FSUSRmSmSrlN7S4S0jNTK5RLvhBBCCMkHMdK3b1/Zu3evjBw5UgWttm7dWqZPn+4Lat26dWuAJeTRRx9Vrgn8v2PHDqlYsaISIk8//bREJDpexBbAqsUIsmH2J1vBrCUTWMCWEEIIOVmiPBHrK/GD1F5k1SCYtXTpwMJh+c6xPSIvegt7jTwov67fr9aKwSq8CzcdUAvOrdtzVNrVLqfqixBCCCHk5MZvTu1DrdgbHS39JgYWZ6tWpnieF50jhBBCiAupvYUOX1pvovybaq3Ga1IxyGJ1hBBCCMkbFCMh1qVZ/s/hgLdQyr0Og1YJIYSQfIVumiBumvSY4nLnx0t9gar9OteWy9pUz1GhMkIIIYTkHIqRIG6avSdifBk0/zm3gdzWtb7LO0YIIYScmtBNE8QycjTTWtCubGKcY2VVQgghhOQPFCN2Uo+p/w5lWO6Y0Ze3kFLFsl9dlxBCCCF5g2LEzokj6r/96daKulWS/IXPCCGEEJL/UIzYSbHEyN40y01TLckSJYQQQggpGChGglhGjnqKS2x0FLNnCCGEkAKGYsROylH131FPolQuXUxioqPc3iNCCCHklIZiJIib5qgkSrUydNEQQgghBQ3FiJ0Th31uGlhGCCGEEFKwUIwEc9NIoiQVZ0ovIYQQUtBQjARz03iKS4kEFqglhBBCChqKkWDZNJIoJeIpRgghhJCChmIkiJvmmLKMxLi9N4QQQsgpD8WISXqKSEaK3zJCNw0hhBBS4FCMOLhowDEpLonxtIwQQgghBQ3FiEPw6vGo4pIp0VKSlhFCCCGkwKEYcRAjyZKo/k9kACshhBBS4FCMBAleBbSMEEIIIQUPxYg9gFVE/hWr2Fkis2kIIYSQAodixCT9hPrv30zLIkLLCCGEEFLwUIw4WEZSPJZlhKm9hBBCSMFDMWKSkar+S9Vumji6aQghhJCChmLEwU2TInGqxkh0dJTbe0QIIYSc8lCMmKRry0gs03oJIYSQMEEx4mAZgZumJDNpCCGEkLBAMeIQM4IAVlpGCCGEkPBAMeKUTaMsIxQjhBBCSDigGAkSwFqyGMUIIYQQEg4oRhxTe2OlTKKV3ksIIYSQgoVixMFNk+qJkzLF493eG0IIIaRIQDESJGaElhFCCCEkPFCMmGR4LSMSJ2UpRgghhJCwQDHi5KaRWElKpJuGEEIICQcUI0EWyitTnJYRQgghJBxQjARZKI8xI4QQQkgEi5Fx48ZJnTp1pFixYtKxY0dZtGhR0M9269ZNoqKisjwuuugiieQ6I2XppiGEEEIiU4xMnjxZhgwZIqNGjZKlS5dKq1atpEePHrJnzx7Hz0+ZMkV27tzpeyxfvlxiYmLkqquukkgjM80fwJpEywghhBASmWJkzJgxMmjQIBkwYIA0a9ZMxo8fL4mJiTJx4kTHz5crV06qVKnie8yYMUN9PiLFiDdmJD0qTkqxHDwhhBASeWIkNTVVlixZIt27d/f/QHS0ej5//vwc/cY777wj11xzjZQoUSLoZ1JSUuTIkSMBj3CQmWa5aeISiitXEiGEEEIiTIzs27dPMjIypHLlygGv4/muXbuy/T5iS+CmGThwYMjPjR49WpKSknyPmjVrSljwWkbiE4qHZ3uEEEIICW82DawiLVq0kA4dOoT83LBhw+Tw4cO+x7Zt28IqRqLji4Vne4QQQgiRXAVGVKhQQQWf7t69O+B1PEc8SCiSk5Nl0qRJ8sQTT2S7nYSEBPUIN9GZXjESG/5tE0IIIUWVXFlG4uPjpV27djJz5kzfa5mZmep5586dQ373888/V7EgN9xwg0Qq0d46IzFxFCOEEEJIuMh1ygjSevv37y/t27dX7paxY8cqqweya0C/fv2kevXqKu7D7qLp06ePlC9fXiKSzEyJ9qSrP6PiGDNCCCGERKwY6du3r+zdu1dGjhypglZbt24t06dP9wW1bt26VWXYmKxZs0bmzJkjP/74o0T6InkgJp6WEUIIISRc5KmYxuDBg9XDiVmzZmV5rXHjxuLxeCSi8VZfBTG0jBBCCCFhg2vTaNKteJFMT5TExbH6KiGEEBIuKEZsbppUiZWEOFZfJYQQQsIFxYitxgjWpSkWF+P23hBCCCFFBooRTWa63zISy2YhhBBCwgVHXY0n0/pPomgZIYQQQsIIxYhNjGRKFC0jhBBCSBjhqKvJzLD+k2haRgghhJAwQjHiYBkpFsdmIYQQQsIFR12NtyhbpidaEmJpGSGEEELCBcWIhpYRQgghxBU46jqKEVpGCCGEkHBBMaLx+ANYmU1DCCGEhA+OulksI8ymIYQQQsIJxYiGdUYIIYQQV+Coq2HMCCGEEOIKFCNePJm6HHy0JDCbhhBCCAkbHHW9pGWkGW4aWkYIIYSQcEEx4iU93cqmyVABrGwWQgghJFxw1PWSmpbuW7U3PobNQgghhIQLjrpe0ryWEYmKlqioKLd3hxBCCCkyUIx4SU+3YkY8UWwSQgghJJxw5LVZRqIoRgghhJCwwpHXS0aGJUZoGSGEEELCC0deWzYNYkYIIYQQEj448nrJyKQYIYQQQtyAI6+XjAwrtZdihBBCCAkvHHltMSMSxeqrhBBCSDihGPHCmBFCCCHEHTjy2iwjUdFsEkIIISSccOT1kpHJmBFCCCHEDTjyesnMyLT+oBghhBBCwgpH3ixuGgawEkIIIeGEYsRLprfOCGNGCCGEkPDCkdduGaGbhhBCCAkrHHm9ZDKbhhBCCHEFjry2cvCMGSGEEELCC8WI3TLCCqyEEEJIWKEY8ZKZaaX20k1DCCGEhBeOvLZsmmiKEUIIISSs5GnkHTdunNSpU0eKFSsmHTt2lEWLFoX8/KFDh+Suu+6SqlWrSkJCgjRq1EimTZsmkYTHJ0bopiGEEELCSWxuvzB58mQZMmSIjB8/XgmRsWPHSo8ePWTNmjVSqVKlLJ9PTU2V888/X733xRdfSPXq1WXLli1SpkwZicQKrAxgJYQQQiJcjIwZM0YGDRokAwYMUM8hSqZOnSoTJ06UoUOHZvk8Xj9w4IDMmzdP4uLi1GuwqkSsmyaGbhpCCCEknORq5IWVY8mSJdK9e3f/D0RHq+fz5893/M63334rnTt3Vm6aypUrS/PmzeWZZ57xFRlzIiUlRY4cORLwCF8AKy0jhBBCSMSKkX379ikRAVFhgue7du1y/M7GjRuVewbfQ5zIiBEj5KWXXpKnnnoq6HZGjx4tSUlJvkfNmjWloPF4V+1lzAghhBASXqLDYXFAvMhbb70l7dq1k759+8rw4cOVeycYw4YNk8OHD/se27ZtK+jdFI/Hsowwm4YQQgiJ4JiRChUqSExMjOzevTvgdTyvUqWK43eQQYNYEXxP07RpU2VJgdsnPj4+y3eQcYNHONFumpiYXIfREEIIIeQkyJUZAMIB1o2ZM2cGDOJ4jrgQJ8444wxZv369b7AHa9euVSLFSYi4n9pLywghhBASTnI98iKtd8KECfL+++/LqlWr5I477pDk5GRfdk2/fv2Um0WD95FNc8899ygRgswbBLAioDWS8HjFUrRhwSGEEEJIwZNrnwRiPvbu3SsjR45UrpbWrVvL9OnTfUGtW7duDbAuIPj0hx9+kPvuu09atmyp6oxAmDz88MMSUbDoGSGEEOIKeQqQGDx4sHo4MWvWrCyvwYWzYMECiWR0AKsZ20IIIYSQgocBEl7opiGEEELcgWLEZhmJpZuGEEIICSsUIyKSnpEp0brOCC0jhBBCSFihGEGZ+4xMiRIdM8ImIYQQQsIJR14RSUv3SLR41N8sekYIIYSEF4oRiJHMTJ8YYWovIYQQEl4oRlTMiEeioywxEsUKrIQQQkhY4cgLywgCWL0xIxLFJiGEEELCCUdeEcnI9BhihG4aQgghJJxQjMBNY8SM0DJCCCGEhBeOvMpN48+moRghhBBCwgtHXm8Aq64zIlFRbu8OIYQQUqSgGPG6aWJoGSGEEEJcgSOvEiNGACvrjBBCCCFhhWLEm9obRcsIIYQQ4goceXXRM4oRQgghxBU48nrrjMSw6BkhhBDiChx5WYGVEEIIcRWOvN4AVn/MCANYCSGEkHBCMeKzjGgxwjojhBBCSDihGPGtTcMAVkIIIcQNOPLqbJooxowQQgghbsCRF24atVAei54RQgghbkAxwjojhBBCiKtw5PWVg6cYIYQQQtyAI6+yjKAcPGNGCCGEEDfgyOu1jLACKyGEEOIOHHmz1BlhkxBCCCHhhCMv64wQQgghrsKRV1lGzHLwbBJCCCEknHDk9QawMmaEEEIIcQeOvL7UXhY9I4QQQtyAYkSJEaT20k1DCCGEuAFHXlZgJYQQQlyFI683gNXnpqEYIYQQQsIKR16vmyY6SltGotzeHUIIIaRIQTFiD2CNYgArIYQQEk4oRrypvYwZIYQQQtyBIy8DWAkhhBBXydPIO27cOKlTp44UK1ZMOnbsKIsWLQr62ffee0+ioqICHvheJJEW4KahGCGEEELCSa5H3smTJ8uQIUNk1KhRsnTpUmnVqpX06NFD9uzZE/Q7pUuXlp07d/oeW7ZskUgiAwGsFCOEEEKIK+R65B0zZowMGjRIBgwYIM2aNZPx48dLYmKiTJw4Meh3YA2pUqWK71G5cmWJvNRer5uGFVgJIYSQyBUjqampsmTJEunevbv/B6Kj1fP58+cH/d6xY8ekdu3aUrNmTbn00ktlxYoVIbeTkpIiR44cCXgUJAxgJYQQQtwjVyPvvn37JCMjI4tlA8937drl+J3GjRsrq8k333wjH330kWRmZkqXLl1k+/btQbczevRoSUpK8j0gYgo6tddfDp51RgghhJBwUuBmgM6dO0u/fv2kdevW0rVrV5kyZYpUrFhR3nzzzaDfGTZsmBw+fNj32LZtW4Fn03DVXkIIIcQdYnPz4QoVKkhMTIzs3r074HU8RyxIToiLi5M2bdrI+vXrg34mISFBPcJagZVFzwghhBBXyJUZID4+Xtq1ayczZ870vQa3C57DApIT4Ob5+++/pWrVqhIpwDLCVXsJIYSQQmAZAUjr7d+/v7Rv3146dOggY8eOleTkZJVdA+CSqV69uor7AE888YR06tRJGjRoIIcOHZIXXnhBpfYOHDhQIoU0ZRmhGCGEEEIKhRjp27ev7N27V0aOHKmCVhELMn36dF9Q69atW1WGjebgwYMqFRifLVu2rLKszJs3T6UFRwoZXLWXEEIIcY0oj8fjNQlELkjtRVYNgllRQC2/Of2pGbI4/UrryQPrRUpWzPdtEEIIIUWNIzkcv2kG8Max+GDRM0IIISSsUIx4g3B9sM4IIYQQElYoRrKIETYJIYQQEk448ioxku5/QjFCCCGEhJUiP/IifjcgZoRihBBCCAkrRX7kzcg0VuwFrMBKCCGEhJUiL0bSs4iRIt8khBBCSFgp8iMvxEiMMLWXEEIIcQuKkYxMifOKEaxQQzFCCCGEhJciL0bSMjwSJ95smph4t3eHEEIIKXIUeTGCANbYKMsyEhUT5/buEEIIIUWOIi9G0pSbRltGKEYIIYSQcFPkxQgCWHXMiERTjBBCCCHhhmIkI1NiaRkhhBBCXINiJNMj8RQjhBBCiGtQjGR4JJZuGkIIIcQ1irwYScvM9GXTMLWXEEIICT9FXozAMuJ308S6vTuEEEJIkYNiBJYRumkIIYQQ16AYYQVWQgghxFUoRjL9a9PQTUMIIYSEnyIvRrA2jb/OCC0jhBBCSLgp8mIEa9PE6WwaxowQQgghYafIi5HAtWnopiGEEELCTZEXIwxgJYQQQtyFYoSpvYQQQoirUIyYq/ZybRpCCCEk7FCMBLhpKEYIIYSQcFPkxQgCWH1r09BNQwghhISdIi9G6KYhhBBC3KXIixFVZ4RuGkIIIcQ1irwYUW4aLUbopiGEEELCTpEXI6wzQgghhLhLkRcjaVwojxBCCHGVIi9GMrBQns6moWWEEEIICTtFXoxY2TSMGSGEEELcosiLEWuhPLppCCGEELco8mKEAayEEEKIu1CMZHq4UB4hhBBS2MTIuHHjpE6dOlKsWDHp2LGjLFq0KEffmzRpkkRFRUmfPn0kklbtZQVWQgghpBCJkcmTJ8uQIUNk1KhRsnTpUmnVqpX06NFD9uzZE/J7mzdvlgceeEDOOussiTg3TRQrsBJCCCGFRoyMGTNGBg0aJAMGDJBmzZrJ+PHjJTExUSZOnBj0OxkZGXL99dfL448/LvXq1ZNIghVYCSGEkEIkRlJTU2XJkiXSvXt3/w9ER6vn8+fPD/q9J554QipVqiS33HJLjraTkpIiR44cCXgU5No08XTTEEIIIYVDjOzbt09ZOSpXrhzwOp7v2rXL8Ttz5syRd955RyZMmJDj7YwePVqSkpJ8j5o1a0pBkaYCWOmmIYQQQk7JbJqjR4/KjTfeqIRIhQoVcvy9YcOGyeHDh32Pbdu2Fdg+pis3DSuwEkIIIW6RqypfEBQxMTGye/fugNfxvEqVKlk+v2HDBhW42rt3b99rmZmZ1oZjY2XNmjVSv379LN9LSEhQj3AFsMbrAFbGjBBCCCGRbRmJj4+Xdu3aycyZMwPEBZ537tw5y+ebNGkif//9tyxbtsz3uOSSS+Scc85Rfxek+yWnXH3kXakRtc96wgqshBBCSNjJ9eiLtN7+/ftL+/btpUOHDjJ27FhJTk5W2TWgX79+Ur16dRX3gTokzZs3D/h+mTJl1P/2193iyuOT/U/opiGEEEIiX4z07dtX9u7dKyNHjlRBq61bt5bp06f7glq3bt2qMmwKJXTTEEIIIWEnyuPxeCTCQWovsmoQzFq6dOn8/fHHkvx/3/2HSLnIqoNCCCGEFFZyOn4XUhNG/pEqljUkPaGMSFItt3eHEEIIKXIUbTHiQcGzNPXnystnMICVEEIIcYGiLUYyLCECYmKLuborhBBCSFGliIuRFN+fMfHhqWtCCCGEkECKthhJT/X9GRtPywghhBDiBkVbjHgtI2meGIlhvAghhBDiCkVbjKRbYiRVYiU2OsrtvSGEEEKKJEVbjGSk+tJ742KKdlMQQgghblGkR2BP+gm/ZSSGlhFCCCHEDYq0GMlI87ppPHF00xBCCCEuQTHis4wU6aYghBBCXKNIj8AZqdpNQ8sIIYQQ4hZFWoxkei0jKRLLAFZCCCHEJYp0cY2MNL9lhIYRQggJJCMjQ9LS/MtmEGInLi5OYmJi5GQp0mIk01tnJE3iJCqKaoQQQoDH45Fdu3bJoUOH3N4VUggoU6aMVKlS5aTG0SItRjxeN016VJzbu0IIIRGDFiKVKlWSxMRETtZIUNF6/Phx2bNnj3petWpVyStFWoxoN00axQghhPhcM1qIlC9f3u3dIRFO8eLF1f8QJLhm8uqyKdpRm143TbpQjBBCCNAxIrCIEJIT9LVyMvFFRVqMZKZZ5eDppiGEkEDomiHhvFaKtBjxZFhuGooRQgghxD2KthjRAazR8W7vCiGEEFJkKdJiRMeMZNAyQgghhLhG0RYjGV4xQssIIYSQfIYF43JOkRYjnnQrgJWWEUIIKfxMnz5dzjzzTFWEC2nJF198sWzYsMH3/vbt2+Xaa6+VcuXKSYkSJaR9+/aycOFC3/v/+9//5PTTT5dixYpJhQoV5LLLLgsI0vz6668DtoftvPfee+rvzZs3q89MnjxZunbtqn7j448/lv3796ttVq9eXWWdtGjRQj799NOA38nMzJTnn39eGjRoIAkJCVKrVi15+umn1XvnnnuuDB48OODze/fulfj4eJk5c6acKhTpOiNRtIwQQkiOilv9m5YR9u0Wj4vJVaZGcnKyDBkyRFq2bCnHjh2TkSNHKkGxbNkyVZwLIgGi4Ntvv1UVQ5cuXaqEAJg6dar67PDhw+WDDz6Q1NRUmTZtWq73eejQofLSSy9JmzZtlCA5ceKEtGvXTh5++GEpXbq02s6NN94o9evXlw4dOqjvDBs2TCZMmCD//e9/lZjauXOnrF69Wr03cOBAJUbwmxAq4KOPPlLHAaFyqlCkxYhkeC0j0bSMEEJIMCBEmo38IezbXflED0mMz/kwdcUVVwQ8nzhxolSsWFFWrlwp8+bNUxaFxYsXK8sIgCVCA0vENddcI48//rjvtVatWuV6n++99165/PLLA1574IEHfH//5z//kR9++EE+++wzJUaOHj0qL7/8srz22mvSv39/9RkIFYgSgN+CGPnmm2/k6quvVq/BGnPTTTedUunXRdpNE+V102RGW2qTEEJI4WXdunXKJVKvXj1lhahTp456fevWrco6AmuFFiJ28P5555130vsA14+9ou2TTz6p3DPYdsmSJZUYwT6BVatWSUpKStBtw7oCSwqEFYA1Z/ny5UqMnEoUactIVKblpsmMoWWEEEJCuUtgpXBju7mhd+/eUrt2beXyqFatmnLBNG/eXLlcdNnyoNvK5n1YIeCuyi5AFbEoJi+88IKyfIwdO1YJErwP6wn2KSfb1a6a1q1bq5iXd999V7lncJynEkXbMuJ109AyQgghoQdiuEvC/ciNGwKBomvWrJFHH31UWRmaNm0qBw8e9L2POBJYPw4cOOD4fbwfKiAU7h7EcphWGMShZMfcuXPl0ksvlRtuuEG5fWC1Wbt2re/9hg0bKkESatsQMbC4QGR98skncvPNN8upBsUIgrMYM0IIIYWasmXLqgyat956S9avXy8///yzCmbVwH2DoNU+ffoogbBx40b58ssvZf78+er9UaNGqSwX/A/Xyd9//y3PPfec7/uwRiCu448//pDff/9dbr/9domLy37sgNiYMWOGilnB7952222ye/fuADfMww8/LA899JAKnEX2z4IFC+Sdd97JYh159tlnlXXGzPI5VSjSYgQWt0xPlGTGMJuGEEIKM9HR0TJp0iRZsmSJcs3cd999ykWiQSrsjz/+qFaW7dWrl7I2YHDXq8x269ZNPv/8c5VpA5cIxMeiRYt830c2S82aNeWss86S6667TgWl5mQxQVhq2rZtKz169FDb0ILIZMSIEXL//fer7B9YdPr27atWwTWBmIqNjVX/Q8CcakR57E6wCOTIkSOSlJQkhw8fVkFJ+cV7czfJY/9bIRe1qCrjrm+Xb79LCCGFFaSibtq0SerWrXtKDnqFlc2bN6ssG2QDQdwUlmsmp+N3kQ5gTc+EDouSuJgibSAihBASoaSlpal4GFhYOnXqFHFCJL8o0qOwJUZEYqKLdDMQQgiJUObOnStVq1ZVFpHx48fLqUrRtoxkWJX34mJOncIxhBBCTh26deuWJaX4VKRImwTSMqwTHEsxQgghhLhGkRYj6d41CWLppiGEEEJco0iPwjpmJDaalhFCCCHELYq2GPG5aYp0MxBCCCGukqdReNy4cWoBIuQTd+zYMaAwjJ0pU6aoMrZlypRRNflRTObDDz+USIABrIQQQkghFCOTJ09WJXZRMherB6LWPirL2avFabBK4fDhw1XJ3b/++ksGDBigHli10G3SfG4aWkYIIYQQt8j1KDxmzBgZNGiQEhTNmjVTec8oiauXN3ZKS0IdfZS4RfW4e+65Ry1INGfOHHGbDGbTEEII8QKLP1bXJREuRrDkMer+d+/e3f8D0dHquV5sKBTIlcbKhFhZ8eyzzw76uZSUFFVC1nwUBGm+bBqKEUIIIaRQiJF9+/ZJRkaGVK5cOeB1PN+1a1fQ76EmfcmSJdVCRRdddJG8+uqrcv755wf9/OjRo1Ute/3A4kQFAQNYCSGEnApkZGRIpneCXRgJyyhcqlQpWbZsmSpn+/TTT6uYk1mzZgX9/LBhw5SA0Y9t27YVaJ0RBrASQkjh5q233pJq1aplGZAvvfRSufnmm2XDhg3qb0yeMTk+/fTT5aeffsrz9hCygJV/kZiBCfOdd94px44dy1LKHaEKCGUoW7asiq88ePCgeg/7+fzzz0uDBg0kISFBatWqpcZHgPExKipKDh065PstjKF4DQvmgffee08lhmCVYYRM4De2bt2qxllM9itUqKAm8127dlXxnSb43dtuu021BRJRsMrxd999J8nJyWoxuy+++CLg819//bU6zqNHj0pEiBEcHJZb3r17d8DreI5lkYNuJDpaNTgyabBM8pVXXqmsH8FAo6JBzEdBWkZi6KYhhJDgoBx5anL4H7kog37VVVepBeV++eUX32sHDhyQ6dOny/XXX6+EQq9evVSowB9//CE9e/aU3r17qwE8L2Bce+WVV2TFihXy/vvvy88//ywPPfRQgHg477zzlFBAGAPiJLE9WDD0pPvZZ5+VESNGyMqVK+WTTz7J4nXIjuPHj8tzzz0nb7/9ttqPSpUqKcHQv39/tb0FCxZIw4YN1XFrIQERdOGFFyqh9NFHH6ltYz8wtkNwXHPNNfLuu+8GbAfPMW7DsBARa9PAzdKuXTt1Mvv06eM7MDwfPHhwjn8H30FcSKQUPYtjNg0hhAQn7bjIM9XCv91H/hGJL5Gjj8LygEEWgzpEAMAMH5Poc845R4kHZH9qnnzySfnqq6+UZSE345fm3nvvDQh8feqpp+T222+X119/Xb0GqwfKWujn4LTTTlP/Qxi8/PLL8tprrynhAJDgceaZZ0puV/TF75vHde6552axGMGCMnv2bLn44ouVNQjlOFatWiWNGjVSn6lXr57v8wMHDpQuXbrIzp071QJ9yJSdNm3aSVmRckKuR2G4WCZMmKCUIA7mjjvuUKYdZNeAfv36KcWngQVkxowZsnHjRvX5l156SdUZueGGG8Rt0rx1RphNQwghhR9YQL788kvfZPfjjz9WM30IEVhGHnjgAZXZicEZrhqMSXm1jGBwhuipXr26shjceOONyjIDa4VpGXEC28U+Bns/NwYCZKfaPRXIeIVFBG4aeBZw7Po4sV81atTwCRE7HTp0UKIJYzyA9aR27dohk05cWbW3b9++snfvXhk5cqQKWoXrBWYwbV7CAePEayBU4Evbvn27FC9eXJo0aaIODr/jNgxgJYSQHBCXaFkp3NhuLoAbBFmbU6dOVTEhv/32m/z3v/9V70GIYGL84osvqrABjEdwPSBLNLcgbgNWBkzGEeeBelpwi9xyyy3q9xAjgt8PRqj3gB5DzdV6YQVx+h3EkZjA0gJRBMsLRATCHjp37uw7zuy2ra0jKG46dOhQ5aKBscG+HdfFCIBJK5hZyx6YCtMVHpFIBtemIYSQ7MFAlEN3iZsgGPPyyy9XFpH169dL48aNpW3btuo9xEjcdNNNqu4VgLVAB4PmFpS4QLgBLP1aOHz22WcBn4HFAiEMjz/+eJbvw2oBUYD3MfDbqVixovofrhK4n7RFIyfgOOG6QZwIQAIIMmHN/YJxYO3atUGtI/BcIP4FMTGIKdGupIKkSJsEWGeEEEJOPVcNLCMoxIm/TQGA5UkwqP/5559y3XXX5TkVFpYVWCpQpgIhCAg9QAFQE4QrILMFngFUH1+9erW88cYbShhAND388MNqwP/ggw9Upg+CTd955x3f7yND57HHHpN169ap44HwyQk4TuwPXEELFy5UbWBaQ5BdA5fLFVdcoSxFmzZtku+//155ODQQQBB1Dz74oFxwwQXKrVPQFGkxcmW7GnJnt/pSr2LkK35CCCHZgwBOuE1QXBOCw0zFxSCL4Ey4c5Bmq60muQUBo/g9ZLIgLRaWGHuGKKwOP/74oxI+iMOAq+Sbb76R2FjLIYEsGmSXIuShadOmKnRBL6sSFxcnn376qRIwsGRgOzn1MEDQIH0Yx4Y4lrvvvltl2ZggrgZurGuvvVZl+0AU6SwfjXY5IS06HER5TKdUhIIKrAjEQc2RgkrzJYQQInLixAk1W65bt66awZOiyYcffij33Xef/PPPPypQNq/XTE7H7zzFjBBCCCHk1OP48eMqVgW1R1AYLTshkl8UaTcNIYQQYgduF6T+Oj10rZBTleeff15lvaKQqVmmo6Chm4YQQogPummsomT2SuMaxHMgZZb4oZuGEEIIyWdQxKwgS5+TrNBNQwghhBBXoRghhBCShcK8HD0pfNcK3TSEEEJ8IHsCVUWR0olKoHhe0KXASeEEIaeoRYIlYnDNnEzmDcUIIYQQHxhUEIiI9E4IEkKyA2vx1KpVK2BdutxCMUIIISQAzHAxuKSnp2epzEmISUxMjKoqe7LWM4oRQgghWcDggjRWPAgpaBjASgghhBBXoRghhBBCiKtQjBBCCCHEVQpFzIiuWI+ysoQQQggpHOhxO7uVZ2ILyzoBoGbNmm7vCiGEEELyMI5jjZpCvVAeqrsh3x1rBeRn8R0oNgicbdu2cQG+AoZtHR7YzuGB7Rw+2NaFu50hMSBEqlWrFrIOSaGwjOAAatSoUWC/j4bnRR4e2Nbhge0cHtjO4YNtXXjbOZRFRMMAVkIIIYS4CsUIIYQQQlylSIuRhIQEGTVqlPqfFCxs6/DAdg4PbOfwwbYuGu1cKAJYCSGEEHLqUqQtI4QQQghxH4oRQgghhLgKxQghhBBCXIVihBBCCCGuUqTFyLhx46ROnTpSrFgx6dixoyxatMjtXSpU/Prrr9K7d29VWQ+Vcb/++uuA9xEbPXLkSKlataoUL15cunfvLuvWrQv4zIEDB+T6669XRXbKlCkjt9xyixw7dizMRxLZjB49Wk4//XRVgbhSpUrSp08fWbNmTcBnTpw4IXfddZeUL19eSpYsKVdccYXs3r074DNbt26Viy66SBITE9XvPPjgg5Kenh7mo4lc3njjDWnZsqWv6FPnzp3l+++/973PNi4Ynn32WdV/3Hvvvb7X2Nb5w2OPPaba1nw0adIkMtvZU0SZNGmSJz4+3jNx4kTPihUrPIMGDfKUKVPGs3v3brd3rdAwbdo0z/Dhwz1TpkxBRpbnq6++Cnj/2Wef9SQlJXm+/vprz59//um55JJLPHXr1vX8+++/vs/07NnT06pVK8+CBQs8v/32m6dBgwaea6+91oWjiVx69Ojheffddz3Lly/3LFu2zNOrVy9PrVq1PMeOHfN95vbbb/fUrFnTM3PmTM/vv//u6dSpk6dLly6+99PT0z3Nmzf3dO/e3fPHH3+oc1ehQgXPsGHDXDqqyOPbb7/1TJ061bN27VrPmjVrPI888ognLi5OtTtgG+c/ixYt8tSpU8fTsmVLzz333ON7nW2dP4waNcpz2mmneXbu3Ol77N27NyLbuciKkQ4dOnjuuusu3/OMjAxPtWrVPKNHj3Z1vwordjGSmZnpqVKliueFF17wvXbo0CFPQkKC59NPP1XPV65cqb63ePFi32e+//57T1RUlGfHjh1hPoLCw549e1S7zZ4929euGDQ///xz32dWrVqlPjN//nz1HJ1IdHS0Z9euXb7PvPHGG57SpUt7UlJSXDiKwkHZsmU9b7/9Ntu4ADh69KinYcOGnhkzZni6du3qEyNs6/wVI5jsORFp7Vwk3TSpqamyZMkS5TYw17/B8/nz57u6b6cKmzZtkl27dgW0MdYngDtMtzH+h2umffv2vs/g8zgXCxcudGW/CwOHDx9W/5crV079j2s5LS0toK1hiq1Vq1ZAW7do0UIqV67s+0yPHj3U4lgrVqwI+zFEOhkZGTJp0iRJTk5W7hq2cf4D9wDM/2abArZ1/gLXOFzp9erVUy5xuF0isZ0LxUJ5+c2+fftUZ2M2MMDz1atXu7ZfpxIQIsCpjfV7+B8+SJPY2Fg1yOrPkKwrWMO3fsYZZ0jz5s3Va2ir+Ph4JexCtbXTudDvEYu///5biQ/40uFD/+qrr6RZs2aybNkytnE+AqG3dOlSWbx4cZb3eD3nH5j8vffee9K4cWPZuXOnPP7443LWWWfJ8uXLI66di6QYIaQwzybRkcyZM8ftXTklQacN4QHr0xdffCH9+/eX2bNnu71bpxRYov6ee+6RGTNmqOQBUnBceOGFvr8RnA1xUrt2bfnss89UUkEkUSTdNBUqVJCYmJgsUcN4XqVKFdf261RCt2OoNsb/e/bsCXgfUdrIsOF5yMrgwYPlu+++k19++UVq1Kjhex1tBdfjoUOHQra107nQ7xELzBQbNGgg7dq1U1lMrVq1kpdffpltnI/APYD7vm3btsoSigcE3yuvvKL+xsybbV0wwArSqFEjWb9+fcRd09FFtcNBZzNz5swA8zeew0RLTp66deuqi9VsY/gZEQui2xj/40ZA56T5+eef1bmAgicWiA+GEIHLAO2DtjXBtRwXFxfQ1kj9hW/YbGu4IEzxh5kpUljhhiDO4FpMSUlhG+cj5513nmonWKD0A3FjiGfQf7OtCwaUTdiwYYMqtxBx17SnCKf2IrPjvffeU1kdt956q0rtNaOGSfbR8Ej3wgOX0pgxY9TfW7Zs8aX2ok2/+eYbz19//eW59NJLHVN727Rp41m4cKFnzpw5Krqeqb2B3HHHHSpFetasWQEpesePHw9I0UO6788//6xS9Dp37qwe9hS9Cy64QKUHT58+3VOxYkWmQhoMHTpUZSht2rRJXa94jsyuH3/8Ub3PNi44zGwawLbOH+6//37Vb+Canjt3rkrRRWouMvIirZ2LrBgBr776qjoRqDeCVF/UuiA555dfflEixP7o37+/L713xIgRnsqVKyvhd95556n6DSb79+9X4qNkyZIqXWzAgAFK5BA/Tm2MB2qPaCDw7rzzTpWKmpiY6LnsssuUYDHZvHmz58ILL/QUL15cdUjoqNLS0lw4osjk5ptv9tSuXVv1B+hwcb1qIQLYxuETI2zr/KFv376eqlWrqmu6evXq6vn69esjsp2j8E/+2loIIYQQQnJOkYwZIYQQQkjkQDFCCCGEEFehGCGEEEKIq1CMEEIIIcRVKEYIIYQQ4ioUI4QQQghxFYoRQgghhLgKxQghhBBCXIVihBBCCCGuQjFCCCGEEFehGCGEEEKIq1CMEEIIIUTc5P9vE8/8WmLxqwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the validation accuracy is quite high (which is the result from the test dataset)\n",
    "# training accuracy is a bit low, but val_accuracy is usually more important to maximize\n",
    "# training accuracy being low implies there's room for improvement still in the model\n",
    "loss_df[['accuracy', 'val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model_classification_opt1.keras\n",
    "from keras.models import load_model\n",
    "model = load_model('best_model_classification1_kt.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data evaluation:\n",
      "[0.2645626962184906, 0.9571428298950195]\n",
      "\n",
      "Train data evaluation:\n",
      "[0.2692701816558838, 0.9453846216201782]\n"
     ]
    }
   ],
   "source": [
    "# compare the final model loss/accuracy/evaluation values\n",
    "# the values should again match mostly\n",
    "print(\"Test data evaluation:\")\n",
    "print(model.evaluate(X_test, y_test, verbose=0))\n",
    "print(\"\\nTrain data evaluation:\")\n",
    "print(model.evaluate(X_train, y_train, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
     ]
    }
   ],
   "source": [
    "# get predictions and convert with argmax() to get categories \n",
    "# instead of raw probabilities\n",
    "test_predictions = model.predict(X_test)\n",
    "test_predictions = np.argmax(test_predictions, axis=1)\n",
    "\n",
    "# convert also y-test -values with argmax\n",
    "y_test = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "sns.heatmap(confusion_matrix(y_test, test_predictions), annot=True, fmt='g', \n",
    "            xticklabels=categories, yticklabels=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    1: Cheap       0.92      0.99      0.95        95\n",
      "     2: Avg-       0.95      0.90      0.92        87\n",
      "     3: Avg+       0.99      0.94      0.96        77\n",
      "4: Expensive       0.98      1.00      0.99        91\n",
      "\n",
      "    accuracy                           0.96       350\n",
      "   macro avg       0.96      0.96      0.96       350\n",
      "weighted avg       0.96      0.96      0.96       350\n",
      "\n",
      "\n",
      "Model overall accuracy: 95.71%\n"
     ]
    }
   ],
   "source": [
    "# print the classification report based on true values and predictions\n",
    "print(classification_report(y_test, test_predictions, target_names=categories))\n",
    "\n",
    "# get overall accuracy of the model and print it\n",
    "acc = accuracy_score(y_test, test_predictions)\n",
    "print(\"\\nModel overall accuracy: {:.2f}%\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9988023333333333"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The AUC score is a super sensitive metric\n",
    "# you often get low scores, even 0.5\n",
    "\n",
    "# in binary classification, AUC values are often interpreted as follows:\n",
    "# A binary classifier is useful only when it achieves ROC-AUC score greater than 0.5 and as near to 1 as possible. \n",
    "# If a classifier yields a score less than 0.5, it simply means that the model is performing worse \n",
    "# than a random classifier, and therefore is useless.\n",
    "\n",
    "# In multi category classification , AUC values are often interpreted as follows: \n",
    "# 0.5-0.6 (failed)\n",
    "# 0.6-0.7 (worthless)\n",
    "# 0.7-0.8 (poor)\n",
    "# 0.8-0.9 (good)\n",
    "# > 0.9 (excellent)\n",
    "\n",
    "# get ROC-AUC -score\n",
    "roc_auc_score(y, model.predict(X), multi_class=\"ovr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model in practice with new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['battery_power', 'fc', 'int_memory', 'mobile_wt', 'n_cores', 'pc',\n",
       "       'px_height', 'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>fc</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>pc</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>756</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>2: Avg-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>905</td>\n",
       "      <td>1988</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3: Avg+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1263</td>\n",
       "      <td>1716</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3: Avg+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   battery_power  fc  int_memory  mobile_wt  n_cores  pc  px_height  px_width  \\\n",
       "0            842   1           7        188        2   2         20       756   \n",
       "1           1021   0          53        136        3   6        905      1988   \n",
       "2            563   2          41        145        5   6       1263      1716   \n",
       "\n",
       "    ram  sc_h  sc_w  talk_time price_range  \n",
       "0  2549     9     7         19     2: Avg-  \n",
       "1  2631    17     3          7     3: Avg+  \n",
       "2  2603    11     2          9     3: Avg+  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Predicted price range: 4: Expensive\n",
      "\n",
      "Probabilities by class:\n",
      "['1: Cheap', '2: Avg-', '3: Avg+', '4: Expensive']\n",
      "[0.          0.000056774 0.11943996  0.88050324 ]\n"
     ]
    }
   ],
   "source": [
    "# let's try with some new imaginary data\n",
    "# modify this as needed regarding your own dataset\n",
    "tester_row = {\n",
    "    'battery_power': 1021, \n",
    "    'fc': 0, \n",
    "    'int_memory': 53, \n",
    "    'mobile_wt': 136, \n",
    "    'n_cores': 3, \n",
    "    'pc': 6,\n",
    "    'px_height': 905, \n",
    "    'px_width': 1988, \n",
    "    'ram': 3031, \n",
    "    'sc_h': 17, \n",
    "    'sc_w': 3, \n",
    "    'talk_time': 7 \n",
    "}\n",
    "\n",
    "# convert to pandas-format\n",
    "tester_row = pd.DataFrame([tester_row])\n",
    "result = model.predict(tester_row)[0]\n",
    "result_text = categories[np.argmax(result)]\n",
    "\n",
    "# switch to decimal representation \n",
    "np.set_printoptions(precision=9, suppress=True)\n",
    "\n",
    "# 0 cheapest, 3 most expensive\n",
    "print(f\"Predicted price range: {result_text}\")\n",
    "print()\n",
    "print(\"Probabilities by class:\")\n",
    "print(categories)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
